{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the HDF5 files of the MSS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` module contains the `HDFStore` function which reads data from one of the 10,000 HDF5 files which make up the Million Song Subset (MSS) dataset. The function requires code from the `PyTables` package. To load this package into Python from a console:\n",
    "\n",
    "> `$ conda install --name python3 PyTables`\n",
    "\n",
    "Or you can run the Docker container `dataspace/datalab-notebook`\n",
    "\n",
    "> `$ docker run -v /Users/david:/home/jovyan/work -it --rm -p 8888:8888 dataspace/datalab-notebook`\n",
    "\n",
    "Make sure to replace `/Users/david` with your home folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "\n",
    "- `pandas`: dataframes\n",
    "- `numpy`: arrays\n",
    "- `itertools`: iterate through data structures\n",
    "- `os`: access the host operating system\n",
    "- `re`: regular expressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas    as pd\n",
    "import numpy     as np\n",
    "import itertools as it\n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions `get_filenames` and `unlist`\n",
    "\n",
    "The `get_filenames` recursively obtains the names of all files in the `path` directory and all of its subdirectories. The function returns a multi-level list if `path` contains subdirectories. The `unlist` function flattens the list by removing one level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filenames(path):\n",
    "    return([get_filenames(path+\"/\"+entry.name)\n",
    "            if entry.is_dir() \n",
    "            else path+\"/\"+entry.name \n",
    "            for entry \n",
    "            in os.scandir(path)\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unlist(alist):\n",
    "    return(list(it.chain.from_iterable(alist)\n",
    "               )\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create file list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `/home/jovyan/work` directory (inside the container) is mirrored with `/Users/david` (outside the container, on  the host, which is your/my latop.) This matching of directories is setup in the command that starts Jupyter Notebook:\n",
    "\n",
    "> `$ docker run -v /Users/david:/home/jovyan/work -it --rm -p 8888:8888 dataspace/datalab-notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `path` variable stores the root of the directory tree containing the `10,000` song files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/jovyan/work/Dropbox/Data/MillionSongSubset/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the two above functions (`get_filenames` and `unlist`) to create the list of 10,000 files.\n",
    "\n",
    "The function `get_filenames` returns a multi-level list, which is flattened using `unlist` into a list of full-path filenames, and stord in variable `filename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/work/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " '/home/jovyan/work/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAABD128F429CF47.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = unlist(unlist(unlist(get_filenames(path))))\n",
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store in `filenames` only the songs files\n",
    "\n",
    "The song files contain the string \"/TR\" and end with extension `.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/work/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " '/home/jovyan/work/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAABD128F429CF47.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"\\/TR.*\\.h5$\")\n",
    "filenames = [filename \n",
    "             for filename \n",
    "             in filenames \n",
    "             if p.search(filename)\n",
    "            ]\n",
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify we have the `10,000` files we expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the data stored in a song file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/work/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " '/home/jovyan/work/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAABD128F429CF47.h5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `HDFStore` function to open the (second) HDF5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store=pd.HDFStore(filenames[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the three `Groups` in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/ (RootGroup) 'H5 Song File'\n",
       "  children := ['musicbrainz' (Group), 'metadata' (Group), 'analysis' (Group)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on two groups \n",
    "\n",
    "- `metadata` which contains data produced by people\n",
    "- `analysis` which contains data produced by computers\n",
    "\n",
    "and ignore the `musicbrainz` group (for now.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects of the `metadata` group\n",
    "\n",
    "This group contains five objects:\n",
    "\n",
    "- One object of type `Table` named `songs`\n",
    "- Four objects of type `EArray` named `artist_terms_freq`, `artist_terms_weight`, `artist_terms` and `similar_artists`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/metadata (Group) 'metadata about the song'\n",
       "  children := ['songs' (Table), 'artist_terms_freq' (EArray), 'artist_terms_weight' (EArray), 'artist_terms' (EArray), 'similar_artists' (EArray)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each one of these objects will be inspected below. The `read` method will retrieve the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `songs` object of the `metadata` group\n",
    "\n",
    "Looks like a table based on the field names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/metadata/songs (Table(1,), shuffle, zlib(1)) 'table of metadata for one song'\n",
       "  description := {\n",
       "  \"analyzer_version\": StringCol(itemsize=32, shape=(), dflt=b'', pos=0),\n",
       "  \"artist_7digitalid\": Int32Col(shape=(), dflt=0, pos=1),\n",
       "  \"artist_familiarity\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"artist_hotttnesss\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"artist_id\": StringCol(itemsize=32, shape=(), dflt=b'', pos=4),\n",
       "  \"artist_latitude\": Float64Col(shape=(), dflt=0.0, pos=5),\n",
       "  \"artist_location\": StringCol(itemsize=1024, shape=(), dflt=b'', pos=6),\n",
       "  \"artist_longitude\": Float64Col(shape=(), dflt=0.0, pos=7),\n",
       "  \"artist_mbid\": StringCol(itemsize=40, shape=(), dflt=b'', pos=8),\n",
       "  \"artist_name\": StringCol(itemsize=1024, shape=(), dflt=b'', pos=9),\n",
       "  \"artist_playmeid\": Int32Col(shape=(), dflt=0, pos=10),\n",
       "  \"genre\": StringCol(itemsize=1024, shape=(), dflt=b'', pos=11),\n",
       "  \"idx_artist_terms\": Int32Col(shape=(), dflt=0, pos=12),\n",
       "  \"idx_similar_artists\": Int32Col(shape=(), dflt=0, pos=13),\n",
       "  \"release\": StringCol(itemsize=1024, shape=(), dflt=b'', pos=14),\n",
       "  \"release_7digitalid\": Int32Col(shape=(), dflt=0, pos=15),\n",
       "  \"song_hotttnesss\": Float64Col(shape=(), dflt=0.0, pos=16),\n",
       "  \"song_id\": StringCol(itemsize=32, shape=(), dflt=b'', pos=17),\n",
       "  \"title\": StringCol(itemsize=1024, shape=(), dflt=b'', pos=18),\n",
       "  \"track_7digitalid\": Int32Col(shape=(), dflt=0, pos=19)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (3,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.metadata.songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read` methods retrieves the data, which is stored in variable `x` so we can check its type and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(x):  <class 'numpy.ndarray'>\n",
      "x      :  [ (b'', 4550, 0.7478153693139534, 0.459189194680227, b'ARTWPGO1187FB52DC3', nan, b'Kingston, Jamaica', nan, b'cd5f7bd9-ee6f-4a99-8dd9-dc3afd9da736', b'Elephant Man', 535, b'', 0, 0, b'Riddim Driven: Power Cuts', 74571, 0.23962909777363708, b'SOLMCUV12A6BD54773', b'Loud And Clear', 769111)]\n"
     ]
    }
   ],
   "source": [
    "x = store.root.metadata.songs.read()\n",
    "print(\"type(x): \",type(x))\n",
    "print(\"x      : \",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice:\n",
    "\n",
    "- `artist_name`: Elephant Man\n",
    "- `title`: Loud and Clear\n",
    "- `genre`: [blank, missing]\n",
    "- `release`: Riddim Driven: Power Cuts\n",
    "\n",
    "YouTube: https://www.youtube.com/watch?v=P26QXy01JGY\n",
    "\n",
    "- Duration: 2:08 (see [here](https://www.beatport.com/release/riddim-driven-power-cut/138137))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `artists_terms` object of the `metadata` group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/metadata/artist_terms (EArray(10,), shuffle, zlib(1)) 'array of terms (Echo Nest tags) for an artist'\n",
       "  atom := StringAtom(itemsize=256, shape=(), dflt=b'')\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (32,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.metadata.artist_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be an array with `38` elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(x):  <class 'numpy.ndarray'>\n",
      "x      :  [b'dancehall' b'reggae' b'hip hop' b'jamaica' b'raga' b'kingston' b'urban'\n",
      " b'energetic' b'acoustic' b'pop']\n"
     ]
    }
   ],
   "source": [
    "x = store.root.metadata.artist_terms.read()\n",
    "\n",
    "print(\"type(x): \",type(x))\n",
    "print(\"x      : \",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look like _terms_ that describe the _artist_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `artists_terms_freq` object of the `metadata` group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/metadata/artist_terms_freq (EArray(10,), shuffle, zlib(1)) 'array of term (Echo Nest tags) frequencies for an artist'\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (1024,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.metadata.artist_terms_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another array of 38 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.94735746,  0.94730019,  0.6848307 ,  0.65292715,\n",
       "        0.44654665,  0.23787286,  0.1577559 ,  0.27394067,  0.31898712])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = store.root.metadata.artist_terms_freq.read()\n",
    "print(type(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between these frequencies and the weights below is unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `artists_terms_weight` object of the `metadata` group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/metadata/artist_terms_weight (EArray(38,), shuffle, zlib(1)) 'array of term (Echo Nest tags) weights for an artist'\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (1024,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.metadata.artist_terms_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another array of 38 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.8459884 ,  0.83068957,  0.79929112,  0.7882742 ,\n",
       "        0.78409474,  0.78162137,  0.77157135,  0.76701044,  0.76259756,\n",
       "        0.74642957,  0.72313246,  0.71631195,  0.69145399,  0.68487963,\n",
       "        0.68092924,  0.66818023,  0.65671327,  0.64044927,  0.62919326,\n",
       "        0.62628879,  0.62208271,  0.60905077,  0.60905061,  0.60905036,\n",
       "        0.60905025,  0.6090495 ,  0.60681945,  0.60252961,  0.59761364,\n",
       "        0.56556785,  0.55928456,  0.55928206,  0.5592817 ,  0.55928128,\n",
       "        0.55631773,  0.54045413,  0.53544559])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = store.root.metadata.artist_terms_weight.read()\n",
    "print(type(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `similar_artists` object of the `metadata` group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/metadata/similar_artists (EArray(100,), shuffle, zlib(1)) 'array of similar artists Echo Nest id'\n",
       "  atom := StringAtom(itemsize=20, shape=(), dflt=b'')\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (409,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.metadata.similar_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to check these array lengths for other songs. Is `100` a maximum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b'ARSZWK21187B9B26D7', b'ARLDW2Y1187B9B544F', b'ARG0TXR1187FB4E708',\n",
       "       b'AR6Z8OF1187FB5216E', b'ARUAG4R1187FB53500', b'AR4M1NA1187FB54703',\n",
       "       b'ARACWDD11F4C83EFB0', b'ARUSW6X1187FB3CF6E', b'ARJ4LIU1187B98FF60',\n",
       "       b'ARN0DMU1187FB5B63A', b'ARGPHQO11F4C8463D3', b'ARUPZB41187FB52CEE',\n",
       "       b'ARGS67J1187FB3FC1A', b'AR71RV81187B9A3A46', b'ARFN3551187FB4C930',\n",
       "       b'ARQVGOX11F4C83D683', b'ARHSO041187FB3D06D', b'ART5NIQ1187FB40252',\n",
       "       b'ARSPBQG1187B9A60B5', b'AR40GVR1187B9B6C87', b'ARYGOXC1187B98F69A',\n",
       "       b'ARXRNDO1187FB42BE5', b'ARKVEIM1187FB4D597', b'ARA97CU1187FB364DA',\n",
       "       b'ARR964E1187B9B95D5', b'AR74PG51187B9AAFA0', b'ARFSZGA11F4C846FF3',\n",
       "       b'ARAPFN61187B990019', b'ARS73GR1187FB4AE00', b'AR39HYB1187FB56A08',\n",
       "       b'ARGSEQR1187B9B48F6', b'ARYKJBJ12454A3DD19', b'ARX0RC51187B9A4056',\n",
       "       b'AROPXVN1187FB4E8F0', b'ARUXSE51187B997E35', b'ARFF0FC1187B9AFEAF',\n",
       "       b'ARCGVQJ11F50C4D0F3', b'AR5XW991187B99B270', b'ARN0IWD1187FB47BD1',\n",
       "       b'ARPAB1I1187B9AD8E4', b'ARMAVIJ1187B9AB9DE', b'AR3FIT31187FB41A7D',\n",
       "       b'ARNUFGE1187B9B7881', b'ARSYOWS1187FB41157', b'ARVOZJQ1187FB5A2F8',\n",
       "       b'AR59BQE1187FB3CBE0', b'ARDCZKA125FEF325B7', b'ARVXOWX1187B9AF5E5',\n",
       "       b'AR3OLP61187FB376EA', b'ARC5P3R1187B98CA5F', b'AR9IURO1187FB37CF5',\n",
       "       b'ARJACM31187FB3EFDF', b'ARBSRHV1187FB47B3D', b'ARVVNXI12454A4D38E',\n",
       "       b'ARMVRQP11F4C84409C', b'ARXDKEL11F4C83EEBD', b'AROGZJA11F4C846FD5',\n",
       "       b'AR20CFC1187B98A25D', b'ARJEHDD1187B9B3516', b'ARXAC5S1187FB5C549',\n",
       "       b'AREZMPH11F4C83B364', b'AR2GJ6Q1187FB570F0', b'ARFQERU11F4C83D1A0',\n",
       "       b'ARFKFW61187FB52EB7', b'ARQNRTK1187B9B58F2', b'ARUYIJ01187FB51CF6',\n",
       "       b'ARAOCCD129601F8537', b'ARY1LTC1187B9B1DC4', b'ARMXROY11F4C841033',\n",
       "       b'ARFHP8I1187B9B303F', b'AR9VN011187B9ADD25', b'AR70CDT1187FB5796F',\n",
       "       b'ARO0GHE1187FB37FF3', b'ARB6PDA1187FB5869C', b'AR6ZS6M1187FB57A03',\n",
       "       b'ARUF9BP1187B9AEEDD', b'ARXBCH91187B996EF6', b'ARLESEL11F4C844083',\n",
       "       b'ARSZDTJ11F43A69EBA', b'ARFKOLF11EBCD7B098', b'AR5HO8X1187FB4B3B2',\n",
       "       b'AREK9WT1187FB4CCEA', b'ARMIO761187B9AD613', b'ARWYUJI1269FCD5D78',\n",
       "       b'ARVVHDL1187FB5BC09', b'ARYMKEI1269FB32638', b'ARST7W01187B98A7A1',\n",
       "       b'AR1G3G71187B98FE83', b'ARSUG6D1187B988CF4', b'AR6XZ861187FB4CECD',\n",
       "       b'ARAG5LK1187B9AEDF1', b'ARIGD5I1187B9AEF8A', b'ARVKQID11F4C844E8F',\n",
       "       b'ARETNXQ11F4C846FD8', b'ARI46PY1187FB47BDB', b'ARZRXWL123E29C25FF',\n",
       "       b'ARM3EW81187B9AD130', b'ARCYSFF11F4C840551', b'ARESAVP1269FB26871',\n",
       "       b'ARMEGT61187FB4CAAA'], \n",
       "      dtype='|S20')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = store.root.metadata.similar_artists.read()\n",
    "print(type(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `metadata` portion of the first song file contains:\n",
    "\n",
    "1. a `song` object with variables: `artist_id`, `song_id`, `artist` (name), `title` (name), `artist_mbid` (musicbrainz), `genre` (?), and others\n",
    "1. `similar_artists` object, a list of similar artists (probably match `artist_id`\n",
    "1. `artists_terms` object, a list of tags describing the artist (i.e. \"male\", \"canada\", \"blues\", \"70s\")\n",
    "\n",
    "Even at this point we encounter the question: \n",
    "> How can we put this information (for a single song) into a single row of a table? \n",
    "\n",
    "The variable length `EArray` data about similar artists and artist terms doesn't easily fit into a table. \n",
    "\n",
    "But it gets worse. Keep reading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects of the `analysis` group\n",
    "\n",
    "Data in this group is produced by \"_Echo Nest analysis of the song_.\"\n",
    "\n",
    "All of the data in this group are of type `EArray`, except the `songs` object which is of type `Table`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/analysis (Group) 'Echo Nest analysis of the song'\n",
       "  children := ['tatums_confidence' (EArray), 'beats_confidence' (EArray), 'sections_confidence' (EArray), 'segments_loudness_start' (EArray), 'bars_confidence' (EArray), 'sections_start' (EArray), 'segments_confidence' (EArray), 'tatums_start' (EArray), 'bars_start' (EArray), 'segments_loudness_max' (EArray), 'segments_start' (EArray), 'segments_timbre' (EArray), 'songs' (Table), 'beats_start' (EArray), 'segments_pitches' (EArray), 'segments_loudness_max_time' (EArray)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find that some of the `EArray` data has two dimensions (is a table.)\n",
    "\n",
    "\n",
    "We will inspect some, but not all, of these objects below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `songs` object of the `analysis` group\n",
    "\n",
    "Happily, the `songs` object seems to contain variables, which we can place alongside the variables from the `song` object from the `metadata` group. \n",
    "\n",
    "Notice that the values of the array are followed by datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ (22050, b'bb9771eeef3d5b204a3c55e690f52a91', 0.0, 148.03546, 0.148, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0.169, -9.843, 0, 0.43, 137.915, 121.274, 4, 0.384, b'TRAAABD128F429CF47')], \n",
       "      dtype=[('analysis_sample_rate', '<i4'), ('audio_md5', 'S32'), ('danceability', '<f8'), ('duration', '<f8'), ('end_of_fade_in', '<f8'), ('energy', '<f8'), ('idx_bars_confidence', '<i4'), ('idx_bars_start', '<i4'), ('idx_beats_confidence', '<i4'), ('idx_beats_start', '<i4'), ('idx_sections_confidence', '<i4'), ('idx_sections_start', '<i4'), ('idx_segments_confidence', '<i4'), ('idx_segments_loudness_max', '<i4'), ('idx_segments_loudness_max_time', '<i4'), ('idx_segments_loudness_start', '<i4'), ('idx_segments_pitches', '<i4'), ('idx_segments_start', '<i4'), ('idx_segments_timbre', '<i4'), ('idx_tatums_confidence', '<i4'), ('idx_tatums_start', '<i4'), ('key', '<i4'), ('key_confidence', '<f8'), ('loudness', '<f8'), ('mode', '<i4'), ('mode_confidence', '<f8'), ('start_of_fade_out', '<f8'), ('tempo', '<f8'), ('time_signature', '<i4'), ('time_signature_confidence', '<f8'), ('track_id', 'S32')])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = store.root.analysis.songs.read()\n",
    "print(type(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can retrieve them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22050, b'bb9771eeef3d5b204a3c55e690f52a91', 0.0, 148.03546, 0.148, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0.169, -9.843, 0, 0.43, 137.915, 121.274, 4, 0.384, b'TRAAABD128F429CF47')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(b'bb9771eeef3d5b204a3c55e690f52a91', b'TRAAABD128F429CF47')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x[0])\n",
    "x[0][1], x[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ (22050, b'bb9771eeef3d5b204a3c55e690f52a91', 0.0, 148.03546, 0.148, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0.169, -9.843, 0, 0.43, 137.915, 121.274, 4, 0.384, b'TRAAABD128F429CF47')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype([('analysis_sample_rate', '<i4'), ('audio_md5', 'S32'), ('danceability', '<f8'), ('duration', '<f8'), ('end_of_fade_in', '<f8'), ('energy', '<f8'), ('idx_bars_confidence', '<i4'), ('idx_bars_start', '<i4'), ('idx_beats_confidence', '<i4'), ('idx_beats_start', '<i4'), ('idx_sections_confidence', '<i4'), ('idx_sections_start', '<i4'), ('idx_segments_confidence', '<i4'), ('idx_segments_loudness_max', '<i4'), ('idx_segments_loudness_max_time', '<i4'), ('idx_segments_loudness_start', '<i4'), ('idx_segments_pitches', '<i4'), ('idx_segments_start', '<i4'), ('idx_segments_timbre', '<i4'), ('idx_tatums_confidence', '<i4'), ('idx_tatums_start', '<i4'), ('key', '<i4'), ('key_confidence', '<f8'), ('loudness', '<f8'), ('mode', '<i4'), ('mode_confidence', '<f8'), ('start_of_fade_out', '<f8'), ('tempo', '<f8'), ('time_signature', '<i4'), ('time_signature_confidence', '<f8'), ('track_id', 'S32')])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatypes seem to indicate: \n",
    "\n",
    "- `<i4`: integer numbers\n",
    "- `<f8`: decimal numbers\n",
    "- `S32`: character strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of objects of the `analysis` group\n",
    "\n",
    "Four types:\n",
    "- tatums\n",
    "- segments\n",
    "- beats\n",
    "- bars\n",
    "- sections\n",
    "\n",
    "Assuming that the collection of values of each type partition the song, then the previous list is in order from smallest time duration to longest time duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.tatums_start.read().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.segments_start.read().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.beats_start.read().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.bars_start.read().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.sections_start.read().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tatums`, `beats`, `bars` and `sections` contain only `start` and `confidence` information.\n",
    "- `tatums_start`\n",
    "- `tatums_confidence`\n",
    "- `beats_start`\n",
    "- `beats_confidence`\n",
    "\n",
    "- `bars_start`\n",
    "- `bars_confidence`\n",
    "\n",
    "- `sections_start`\n",
    "- `sections_confidence`\n",
    "\n",
    "The `segments` contain, in addition, `pitch`, `timbre` and `loudness`:\n",
    "- `segments_start` \n",
    "- `segments_confidence`\n",
    "- `segments_pitches`\n",
    "- `segments_timbre`\n",
    "- `segments_loudness_max_time`\n",
    "- `segments_loudness_start`\n",
    "- `segments_loudness_max`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first three and last three `start` times of each type. They all seem to be consistent with a duration of `2:08` and so seem to have units in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.     ,  0.49075,  0.94331]),\n",
       " array([ 127.33542,  127.50345,  127.76454]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.segments_start.read()[0:3,], store.root.analysis.segments_start.read()[-3:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.30847,  0.53882,  0.7636 ]),\n",
       " array([ 127.0784 ,  127.32034,  127.56108]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.tatums_start.read()[0:3,], store.root.analysis.tatums_start.read()[-3:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.     ,   8.56912,  18.2259 ]),\n",
       " array([  82.59045,   96.2478 ,  113.05733]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.sections_start.read()[0:3,], store.root.analysis.sections_start.read()[-3:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.53882,  0.9906 ,  1.43869]),\n",
       " array([ 126.59472,  127.0784 ,  127.56108]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.beats_start.read()[0:3,], store.root.analysis.beats_start.read()[-3:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.9906 ,  2.73619,  4.67471]),\n",
       " array([ 120.32298,  122.275  ,  124.20791]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.bars_start.read()[0:3,], store.root.analysis.bars_start.read()[-3:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `confidence` objects of the `analysis` group\n",
    "\n",
    "Use the `stats.describe` function from the `scipy` library to summarize each array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tatums_confidence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=546, minmax=(0.0, 0.53300000000000003), mean=0.25041941391941391, variance=0.018323634778371477, skewness=-0.8054550877871492, kurtosis=-0.5684787689414659)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(store.root.analysis.tatums_confidence.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `segments_confidence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=599, minmax=(0.012, 1.0), mean=0.61527879799666119, variance=0.056756408763770166, skewness=-0.4871032551587329, kurtosis=-0.5046147365116327)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(store.root.analysis.segments_confidence.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `beats_confidence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=273, minmax=(0.0, 0.63300000000000001), mean=0.31813186813186811, variance=0.017093122252747252, skewness=-0.32171308627692596, kurtosis=-0.07362392751793756)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(store.root.analysis.beats_confidence.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `bars_confidence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=67, minmax=(0.0, 0.63300000000000001), mean=0.1247462686567164, variance=0.018039222523744909, skewness=1.5777257042176682, kurtosis=2.6614389928183817)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(store.root.analysis.bars_confidence.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sections_confidence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=9, minmax=(0.33600000000000002, 1.0), mean=0.56222222222222218, variance=0.057306194444444444, skewness=0.9111747459055977, kurtosis=-0.6801877987252616)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(store.root.analysis.sections_confidence.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the `segments_timbre` array \n",
    "\n",
    "It is two (2) dimensional, with 12 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599, 12)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.segments_timbre.read().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the `segments_pitches` array \n",
    "\n",
    "It is two (2) dimensional, with 12 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599, 12)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.root.analysis.segments_pitches.read().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The end"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
