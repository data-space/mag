{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read parts of the MSD into tables\n",
    "\n",
    "This notebook creates a pandas dataframe from the `/metadata/songs` and `/analysis/songs` tables in the HDF5 files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` module requires code from the _PyTables_ package. To load this package into Python from a console:\n",
    "\n",
    "> `$ conda install --name python3 PyTables`\n",
    "\n",
    "This only needs to happen once on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator \n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions\n",
    "\n",
    "The `get_filenames` function recursively gets the names of all files in a given directory `path` and all of its subdirectories. The function returns a multi-level list if `path` contains subdirectories. The `unlist` function flattens the list by removing one level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filenames(path):\n",
    "    return([get_filenames(path+\"/\"+entry.name)\n",
    "            if entry.is_dir() \n",
    "            else path+\"/\"+entry.name \n",
    "            for entry \n",
    "            in os.scandir(path)\n",
    "           ])\n",
    "\n",
    "def unlist(alist):\n",
    "    return(list(it.chain.from_iterable(alist)\n",
    "               )\n",
    "          )\n",
    "\n",
    "def var_list(base,numof):\n",
    "    return([base+str(ndx) for ndx in range(numof)]\n",
    "          )\n",
    "\n",
    "def h1d_array(in_array,n): \n",
    "    # n1d is the number of elements in `in_array`\n",
    "    n1d = functools.reduce(operator.mul,\n",
    "                           list(in_array.shape))\n",
    "    # return a 1 row 2D array with `n` columns\n",
    "    b = np.ndarray(shape=(1,n1d),\n",
    "                   buffer=in_array,\n",
    "                   dtype=in_array.dtype\n",
    "                  )[0:1,0:n]\n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `make_1row_df` function returns a single row dataframe and takes the following input:\n",
    "\n",
    "- `filename`: full path file name of an MSD HDF5 file containing data for a single song\n",
    "- `metadata_vars`: list of variable names from `/metadata/songs`\n",
    "- `analysis_vars`: list of variable names from `/analysis/songs`\n",
    "- `remove`: \n",
    "    - if `False` the variables listed in the last two parameters are retrieved from the input file\n",
    "    - if `True` all variables except those listed are retrieved from the input file\n",
    "\n",
    "See comments in the code for further details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_1row_df(filename='', metadata_vars=[], analysis_vars=[], remove=False):\n",
    "    # open `filename` as a HDF5 file\n",
    "    store = pd.HDFStore(filename,\"r\")\n",
    "    if remove==True:\n",
    "        # `metadata_vars` and `analysis_vars` contain the variables to remove\n",
    "        metadata_vars = list({item for item \n",
    "                                  in list(store.root.metadata.songs.read().dtype.names) \n",
    "                                  if item not in metadata_vars})\n",
    "        analysis_vars = list({item for item \n",
    "                                  in list(store.root.analysis.songs.read().dtype.names) \n",
    "                                  if item not in analysis_vars})\n",
    "    # else: `metadata_vars` and `analysis_vars` contain the variables to keep\n",
    "    \n",
    "    # retrieve the first `n` values as a horizontal array of 1 dimension\n",
    "    segments_pitches = h1d_array(store.root.analysis.segments_pitches.read(),0)\n",
    "    segments_timbre  = h1d_array(store.root.analysis.segments_timbre.read(),0)\n",
    "    bars_confidence  = h1d_array(store.root.analysis.bars_confidence.read(),0)\n",
    "    artist_terms     = h1d_array(store.root.metadata.artist_terms.read(),0)\n",
    "    \n",
    "    # store these values as variables in single dataframes\n",
    "    at_df = pd.DataFrame(artist_terms    ,columns=var_list('at_',artist_terms    .shape[1]))\n",
    "    bc_df = pd.DataFrame(bars_confidence ,columns=var_list('bc_',bars_confidence .shape[1]))\n",
    "    sp_df = pd.DataFrame(segments_pitches,columns=var_list('sp_',segments_pitches.shape[1]))\n",
    "    st_df = pd.DataFrame(segments_timbre ,columns=var_list('st_',segments_timbre .shape[1]))\n",
    "    \n",
    "    # merge these single dataframes into one single row dataframe\n",
    "    ret = pd.concat([\n",
    "            # retrieve a single row dataframe from `/metadata/songs`\n",
    "            pd.DataFrame(store.root.metadata.songs.read(), \n",
    "                         columns=metadata_vars),\n",
    "            # retrieve a single row dataframe from `/analysis/songs`\n",
    "            pd.DataFrame(store.root.analysis.songs.read(), \n",
    "                         columns=analysis_vars),\n",
    "            #at_df, \n",
    "            bc_df, \n",
    "            sp_df,\n",
    "            st_df],\n",
    "            axis=1) # `axes=1` means stack the dataframes horizontally \n",
    "    # close the HDF5 file\n",
    "    store.close()\n",
    "    # return the merged dataframe\n",
    "    return(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of (10,000) HDF5 (.h5) files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `path` variable stores the root of the directory tree containing all of the song files. The function `get_filenames` returns a multi-level list, which is flattened using `unlist` and stored in variable `filenames` as a list of full-path filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Documents\\\\B\\\\Bentley\\\\Coursework\\\\MA755\\\\MillionSongSubset\\\\data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " 'D:\\\\Documents\\\\B\\\\Bentley\\\\Coursework\\\\MA755\\\\MillionSongSubset\\\\data/A/A/A/TRAAABD128F429CF47.h5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = \"C:/Users/CH162975/Documents/B/MA755/MillionSongSubset/data\"\n",
    "path = \"D:\\Documents\\B\\Bentley\\Coursework\\MA755\\MillionSongSubset\\data\"\n",
    "filenames = unlist(unlist(unlist(get_filenames(path))))\n",
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store in the `filenames` variable only the files with extension `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/CH162975/Documents/B/MA755/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " 'C:/Users/CH162975/Documents/B/MA755/MillionSongSubset/data/A/A/A/TRAAABD128F429CF47.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"\\.h5$\")\n",
    "filenames = [filename for filename \n",
    "             in filenames if p.search(filename)]\n",
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get lists of variables from `/metadata/songs` and `/analysis/songs`\n",
    "\n",
    "The two tables `/metadata/songs` and `/analysis/songs` provide data that is easy to load into a dataframe. Their variables are displayed below so we know which to choose or omit when creating the corresponding dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `/metadata/songs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('analyzer_version', 'S32'), ('artist_7digitalid', '<i4'), ('artist_familiarity', '<f8'), ('artist_hotttnesss', '<f8'), ('artist_id', 'S32'), ('artist_latitude', '<f8'), ('artist_location', 'S1024'), ('artist_longitude', '<f8'), ('artist_mbid', 'S40'), ('artist_name', 'S1024'), ('artist_playmeid', '<i4'), ('genre', 'S1024'), ('idx_artist_terms', '<i4'), ('idx_similar_artists', '<i4'), ('release', 'S1024'), ('release_7digitalid', '<i4'), ('song_hotttnesss', '<f8'), ('song_id', 'S32'), ('title', 'S1024'), ('track_7digitalid', '<i4')]\n"
     ]
    }
   ],
   "source": [
    "tmp=pd.HDFStore(filenames[1])\n",
    "print(tmp.root.metadata.songs.read().dtype)\n",
    "tmp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `/analysis/songs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('analysis_sample_rate', '<i4'), ('audio_md5', 'S32'), ('danceability', '<f8'), ('duration', '<f8'), ('end_of_fade_in', '<f8'), ('energy', '<f8'), ('idx_bars_confidence', '<i4'), ('idx_bars_start', '<i4'), ('idx_beats_confidence', '<i4'), ('idx_beats_start', '<i4'), ('idx_sections_confidence', '<i4'), ('idx_sections_start', '<i4'), ('idx_segments_confidence', '<i4'), ('idx_segments_loudness_max', '<i4'), ('idx_segments_loudness_max_time', '<i4'), ('idx_segments_loudness_start', '<i4'), ('idx_segments_pitches', '<i4'), ('idx_segments_start', '<i4'), ('idx_segments_timbre', '<i4'), ('idx_tatums_confidence', '<i4'), ('idx_tatums_start', '<i4'), ('key', '<i4'), ('key_confidence', '<f8'), ('loudness', '<f8'), ('mode', '<i4'), ('mode_confidence', '<f8'), ('start_of_fade_out', '<f8'), ('tempo', '<f8'), ('time_signature', '<i4'), ('time_signature_confidence', '<f8'), ('track_id', 'S32')]\n"
     ]
    }
   ],
   "source": [
    "tmp=pd.HDFStore(filenames[1])\n",
    "print(tmp.root.analysis.songs.read().dtype)\n",
    "tmp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `/musicbrainz/songs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('idx_artist_mbtags', '<i4'), ('year', '<i4')]\n"
     ]
    }
   ],
   "source": [
    "tmp=pd.HDFStore(filenames[1])\n",
    "print(tmp.root.musicbrainz.songs.read().dtype)\n",
    "tmp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of 10,000 single row dataframes\n",
    "\n",
    "Because `remove=False` is specified the two lists of variables are retrieved from the two `Tables` displayed above. The result of this command is a list of 10,000 single row dataframes with columns indicated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may take up to twenty (20) minutes to create `mss_df_list` with the current set of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, (1, 16))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_df_list = [make_1row_df(filename=filename,\n",
    "                            metadata_vars=['artist_id','artist_name','artist_location',\n",
    "                                           'genre','artist_familiarity','artist_hotttnesss',\n",
    "                                           'song_id','title','song_hotttnesss'],\n",
    "                            # Omit: genre\n",
    "                            analysis_vars=['track_id','duration','key','loudness','mode','danceability',\n",
    "                                           'tempo'],\n",
    "                            # Omit: danceability, energy\n",
    "                            remove=False\n",
    "                           )\n",
    "                for filename in filenames[0:10000] # get data from all 10,000 files\n",
    "              ]\n",
    "len(mss_df_list), mss_df_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mss_df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all dataframes of `mss_df_list` into a single dataframe stored in `mss_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mss_df = pd.concat(mss_df_list,axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the head of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_familiarity</th>\n",
       "      <th>artist_hotttnesss</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>song_hotttnesss</th>\n",
       "      <th>track_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>danceability</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'ARD7TVE1187B99BFB1'</td>\n",
       "      <td>b'Casual'</td>\n",
       "      <td>b'California - LA'</td>\n",
       "      <td>b''</td>\n",
       "      <td>0.581794</td>\n",
       "      <td>0.401998</td>\n",
       "      <td>b'SOMZWCG12A8C13C480'</td>\n",
       "      <td>b\"I Didn't Mean To\"</td>\n",
       "      <td>0.602120</td>\n",
       "      <td>b'TRAAAAW128F429D538'</td>\n",
       "      <td>218.93179</td>\n",
       "      <td>1</td>\n",
       "      <td>-11.197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'ARMJAGH1187FB546F3'</td>\n",
       "      <td>b'The Box Tops'</td>\n",
       "      <td>b'Memphis, TN'</td>\n",
       "      <td>b''</td>\n",
       "      <td>0.630630</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>b'SOCIWDW12A8C13D406'</td>\n",
       "      <td>b'Soul Deep'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'TRAAABD128F429CF47'</td>\n",
       "      <td>148.03546</td>\n",
       "      <td>6</td>\n",
       "      <td>-9.843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'ARKRRTF1187B9984DA'</td>\n",
       "      <td>b'Sonora Santanera'</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>0.487357</td>\n",
       "      <td>0.343428</td>\n",
       "      <td>b'SOXVLOJ12AB0189215'</td>\n",
       "      <td>b'Amor De Cabaret'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'TRAAADZ128F9348C2E'</td>\n",
       "      <td>177.47546</td>\n",
       "      <td>8</td>\n",
       "      <td>-9.689</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'AR7G5I41187FB4CE6C'</td>\n",
       "      <td>b'Adam Ant'</td>\n",
       "      <td>b'London, England'</td>\n",
       "      <td>b''</td>\n",
       "      <td>0.630382</td>\n",
       "      <td>0.454231</td>\n",
       "      <td>b'SONHOTT12A8C13493C'</td>\n",
       "      <td>b'Something Girls'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'TRAAAEF128F4273421'</td>\n",
       "      <td>233.40363</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'ARXR32B1187FB57099'</td>\n",
       "      <td>b'Gob'</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>0.651046</td>\n",
       "      <td>0.401724</td>\n",
       "      <td>b'SOFSOCN12A8C143F5D'</td>\n",
       "      <td>b'Face the Ashes'</td>\n",
       "      <td>0.604501</td>\n",
       "      <td>b'TRAAAFD128F92F423A'</td>\n",
       "      <td>209.60608</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.501</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>129.738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist_id          artist_name     artist_location genre  \\\n",
       "0  b'ARD7TVE1187B99BFB1'            b'Casual'  b'California - LA'   b''   \n",
       "1  b'ARMJAGH1187FB546F3'      b'The Box Tops'      b'Memphis, TN'   b''   \n",
       "2  b'ARKRRTF1187B9984DA'  b'Sonora Santanera'                 b''   b''   \n",
       "3  b'AR7G5I41187FB4CE6C'          b'Adam Ant'  b'London, England'   b''   \n",
       "4  b'ARXR32B1187FB57099'               b'Gob'                 b''   b''   \n",
       "\n",
       "   artist_familiarity  artist_hotttnesss                song_id  \\\n",
       "0            0.581794           0.401998  b'SOMZWCG12A8C13C480'   \n",
       "1            0.630630           0.417500  b'SOCIWDW12A8C13D406'   \n",
       "2            0.487357           0.343428  b'SOXVLOJ12AB0189215'   \n",
       "3            0.630382           0.454231  b'SONHOTT12A8C13493C'   \n",
       "4            0.651046           0.401724  b'SOFSOCN12A8C143F5D'   \n",
       "\n",
       "                 title  song_hotttnesss               track_id   duration  \\\n",
       "0  b\"I Didn't Mean To\"         0.602120  b'TRAAAAW128F429D538'  218.93179   \n",
       "1         b'Soul Deep'              NaN  b'TRAAABD128F429CF47'  148.03546   \n",
       "2   b'Amor De Cabaret'              NaN  b'TRAAADZ128F9348C2E'  177.47546   \n",
       "3   b'Something Girls'              NaN  b'TRAAAEF128F4273421'  233.40363   \n",
       "4    b'Face the Ashes'         0.604501  b'TRAAAFD128F92F423A'  209.60608   \n",
       "\n",
       "   key  loudness  mode  danceability    tempo  \n",
       "0    1   -11.197     0             0   92.198  \n",
       "1    6    -9.843     0             0  121.274  \n",
       "2    8    -9.689     1             0  100.070  \n",
       "3    0    -9.013     1             0  119.293  \n",
       "4    2    -4.501     1             0  129.738  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check its dimensions (shape) and its variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10000, 16)\n",
      "columns: ['artist_id' 'artist_name' 'artist_location' 'genre' 'artist_familiarity'\n",
      " 'artist_hotttnesss' 'song_id' 'title' 'song_hotttnesss' 'track_id'\n",
      " 'duration' 'key' 'loudness' 'mode' 'danceability' 'tempo']\n"
     ]
    }
   ],
   "source": [
    "print('shape:',mss_df.shape)\n",
    "print('columns:',mss_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the table `mss_df` in a _pickle_ file\n",
    "\n",
    "First set the folder to save to and load from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_load_path = \"D:/Documents/B/Bentley/Coursework/MA755/MillionSongSubset/Graph\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `mss_df` to a _pickle_ file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_df.to_pickle(save_load_path+'/song_metadata.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `mss_df` from the _pickle_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_df = pd.read_pickle(save_load_path+'/song_metadata.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check that we retrieved the same number of rows and variables we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 16), Index(['artist_id', 'artist_name', 'artist_location', 'genre',\n",
       "        'artist_familiarity', 'artist_hotttnesss', 'song_id', 'title',\n",
       "        'song_hotttnesss', 'track_id', 'duration', 'key', 'loudness', 'mode',\n",
       "        'danceability', 'tempo'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_df.shape, mss_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
