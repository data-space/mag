{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - classification and regression\n",
    "\n",
    "Contents:\n",
    "1. Load required libraries\n",
    "1. Set initial parameters\n",
    "1. Create synthetic training datasets\n",
    "1. Create classification model\n",
    "1. Train the model and display accuracy\n",
    "1. Create regression model \n",
    "1. Train the model and display mean square error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING:theano.configdefaults:g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import pandas    as pd\n",
    "import numpy     as np\n",
    "import itertools as it\n",
    "\n",
    "from keras.utils       import np_utils \n",
    "from keras.models      import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic training datasets\n",
    "\n",
    "- Set initial parameters\n",
    "- Create a random `x_train` dataset with shape determined by parameters and with random values between `0` and `1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_variables =    10\n",
    "n_samples   =   100\n",
    "n_epoch     = 1000 # number of training iterations\n",
    "min_gen     =     1\n",
    "max_gen     =     4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector `x_gen` \n",
    "\n",
    "The target values of the training datase are created using `x_gen` and `x_train`, which is a matrix of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 3, 2, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gen    = np.random.randint(min_gen, \n",
    "                             max_gen, \n",
    "                             n_variables)\n",
    "x_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `x_train` as a random `n_samples` by `n_variables` matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22851124,  0.6911538 ,  0.56004727,  0.67052671,  0.17378597,\n",
       "         0.19749872,  0.90274427,  0.62814098,  0.05347696,  0.01514592],\n",
       "       [ 0.96486723,  0.54220649,  0.04387735,  0.25712173,  0.57847484,\n",
       "         0.31979752,  0.64303737,  0.1465508 ,  0.84077936,  0.90715859],\n",
       "       [ 0.78741383,  0.61496058,  0.97544603,  0.58859944,  0.40233823,\n",
       "         0.44395069,  0.39858653,  0.75847881,  0.48749377,  0.26658412],\n",
       "       [ 0.61545617,  0.69403582,  0.86812829,  0.83948976,  0.49926527,\n",
       "         0.32839493,  0.15577626,  0.24419588,  0.14039207,  0.02442083],\n",
       "       [ 0.04880384,  0.67821309,  0.44740578,  0.91701954,  0.1723927 ,\n",
       "         0.63117766,  0.8114399 ,  0.84902744,  0.54121457,  0.62243336],\n",
       "       [ 0.57434416,  0.79950348,  0.98551256,  0.03822113,  0.60775188,\n",
       "         0.52760587,  0.9438647 ,  0.05384105,  0.94909702,  0.91350137],\n",
       "       [ 0.70105092,  0.23007555,  0.68326945,  0.48948415,  0.38466666,\n",
       "         0.3888089 ,  0.84684306,  0.64717581,  0.33753778,  0.65295108],\n",
       "       [ 0.00610861,  0.23822366,  0.02371104,  0.29845857,  0.70677982,\n",
       "         0.55582491,  0.36959982,  0.47273037,  0.85312149,  0.05869851],\n",
       "       [ 0.14925503,  0.73777188,  0.87601811,  0.95621259,  0.55029473,\n",
       "         0.4467048 ,  0.6651265 ,  0.04375536,  0.5711779 ,  0.70831611],\n",
       "       [ 0.14925051,  0.01640224,  0.97936357,  0.05479665,  0.74530189,\n",
       "         0.53029473,  0.82867509,  0.81975077,  0.5383122 ,  0.14010755],\n",
       "       [ 0.11382972,  0.81335085,  0.18227401,  0.83889818,  0.02032581,\n",
       "         0.67791499,  0.42102301,  0.01225523,  0.63350283,  0.36229455],\n",
       "       [ 0.57384344,  0.30538407,  0.50202084,  0.42065738,  0.00709751,\n",
       "         0.20469182,  0.75903083,  0.20776234,  0.48497347,  0.29653756],\n",
       "       [ 0.97614674,  0.44711933,  0.23159618,  0.9314921 ,  0.66674284,\n",
       "         0.91968514,  0.08157583,  0.98295773,  0.95956288,  0.24249286],\n",
       "       [ 0.77427086,  0.92816893,  0.69048945,  0.06657337,  0.52033236,\n",
       "         0.41003167,  0.59138223,  0.17615155,  0.8283667 ,  0.29355382],\n",
       "       [ 0.88380191,  0.02835993,  0.58128833,  0.02942242,  0.45862762,\n",
       "         0.5322903 ,  0.76190561,  0.52741756,  0.10646956,  0.24710081],\n",
       "       [ 0.88096799,  0.79811343,  0.42856992,  0.4211345 ,  0.53667412,\n",
       "         0.95775997,  0.005286  ,  0.24001015,  0.27354935,  0.17147851],\n",
       "       [ 0.2714158 ,  0.93337262,  0.44622173,  0.22037221,  0.12972407,\n",
       "         0.53488524,  0.28521887,  0.05040369,  0.81326858,  0.1366532 ],\n",
       "       [ 0.90597314,  0.40979415,  0.4228483 ,  0.51369439,  0.70250002,\n",
       "         0.7676716 ,  0.7538193 ,  0.22978314,  0.32776658,  0.4272526 ],\n",
       "       [ 0.96689793,  0.88779972,  0.91306514,  0.76591005,  0.44648919,\n",
       "         0.49504374,  0.09512778,  0.55898093,  0.89427953,  0.22992013],\n",
       "       [ 0.55607065,  0.89781129,  0.49898472,  0.49935015,  0.1456396 ,\n",
       "         0.89654839,  0.65341911,  0.80080179,  0.4289044 ,  0.56059716],\n",
       "       [ 0.61641825,  0.91423988,  0.97932027,  0.2499423 ,  0.84513897,\n",
       "         0.48461912,  0.64080518,  0.70150792,  0.4603454 ,  0.8601877 ],\n",
       "       [ 0.16009931,  0.70901991,  0.80864718,  0.70178373,  0.94509855,\n",
       "         0.58354007,  0.13082243,  0.44791626,  0.73469173,  0.99281512],\n",
       "       [ 0.72476852,  0.03038364,  0.00339819,  0.98404072,  0.28361794,\n",
       "         0.43595785,  0.43809522,  0.28453905,  0.21253265,  0.49211616],\n",
       "       [ 0.70922569,  0.05032251,  0.60519402,  0.58222092,  0.96321751,\n",
       "         0.65490224,  0.74154921,  0.78493965,  0.92782554,  0.43443455],\n",
       "       [ 0.34220055,  0.24699522,  0.37993596,  0.54841714,  0.90219633,\n",
       "         0.87064789,  0.38522389,  0.76808171,  0.9832731 ,  0.25168273],\n",
       "       [ 0.0493471 ,  0.64099393,  0.92107395,  0.05003931,  0.41016539,\n",
       "         0.47014086,  0.27287162,  0.50134213,  0.61576041,  0.17568704],\n",
       "       [ 0.31016237,  0.53063976,  0.30428717,  0.73806831,  0.77819378,\n",
       "         0.86149668,  0.23540822,  0.39646477,  0.95883382,  0.82244135],\n",
       "       [ 0.63869883,  0.2006857 ,  0.7658606 ,  0.52809048,  0.85161874,\n",
       "         0.23363239,  0.62336143,  0.80453689,  0.62680524,  0.77609938],\n",
       "       [ 0.62308762,  0.79455039,  0.76914282,  0.34454013,  0.34077254,\n",
       "         0.76921388,  0.08652172,  0.6389265 ,  0.86865324,  0.8896804 ],\n",
       "       [ 0.19901102,  0.12122656,  0.93805507,  0.98515147,  0.00558086,\n",
       "         0.21390402,  0.57802009,  0.66428798,  0.6581022 ,  0.42065161],\n",
       "       [ 0.79193208,  0.00622232,  0.2268756 ,  0.16872981,  0.13386533,\n",
       "         0.68998682,  0.45970904,  0.45342825,  0.12111891,  0.03795816],\n",
       "       [ 0.78335504,  0.4048042 ,  0.30976258,  0.00954569,  0.0833136 ,\n",
       "         0.54131596,  0.12725915,  0.24370315,  0.65105037,  0.74970891],\n",
       "       [ 0.19031404,  0.5591608 ,  0.0306243 ,  0.76494969,  0.14431487,\n",
       "         0.01233211,  0.08467544,  0.74556304,  0.6565132 ,  0.59779528],\n",
       "       [ 0.57900606,  0.36801688,  0.09691668,  0.78256897,  0.95039654,\n",
       "         0.7820061 ,  0.32089722,  0.41887086,  0.73975308,  0.8636712 ],\n",
       "       [ 0.80431574,  0.76793282,  0.66392462,  0.91699728,  0.54679158,\n",
       "         0.81190194,  0.79724637,  0.51839884,  0.61601276,  0.22068687],\n",
       "       [ 0.3681719 ,  0.682337  ,  0.47174957,  0.13845744,  0.6530933 ,\n",
       "         0.54509204,  0.62255896,  0.31748604,  0.96400747,  0.5325599 ],\n",
       "       [ 0.20739956,  0.58655041,  0.99785461,  0.21851582,  0.75084873,\n",
       "         0.51894871,  0.30502065,  0.32277048,  0.48656906,  0.23274098],\n",
       "       [ 0.28987947,  0.85296265,  0.28501602,  0.900467  ,  0.60548027,\n",
       "         0.67584416,  0.60002677,  0.0231108 ,  0.76123569,  0.84520209],\n",
       "       [ 0.79037341,  0.34744526,  0.79853663,  0.4459659 ,  0.12799603,\n",
       "         0.21497657,  0.28632163,  0.00337758,  0.46835085,  0.01829606],\n",
       "       [ 0.37835573,  0.99854624,  0.24567998,  0.10406209,  0.28674964,\n",
       "         0.70333165,  0.51842997,  0.55629513,  0.60345569,  0.38877137],\n",
       "       [ 0.94879203,  0.40629542,  0.2901758 ,  0.85130383,  0.96399851,\n",
       "         0.78796214,  0.29404301,  0.16925921,  0.68668592,  0.01076115],\n",
       "       [ 0.69735593,  0.32502188,  0.50383368,  0.77126999,  0.89690675,\n",
       "         0.4874253 ,  0.85296392,  0.46329504,  0.81060942,  0.58390508],\n",
       "       [ 0.63153228,  0.23126511,  0.93806229,  0.61436368,  0.93691927,\n",
       "         0.95078591,  0.68678671,  0.63519848,  0.55834391,  0.34130526],\n",
       "       [ 0.27450693,  0.58433885,  0.69397625,  0.45766022,  0.83093794,\n",
       "         0.48385249,  0.1545721 ,  0.12913451,  0.11049185,  0.96092735],\n",
       "       [ 0.1898679 ,  0.93728865,  0.1087944 ,  0.73610033,  0.36792313,\n",
       "         0.84137189,  0.81219925,  0.54048038,  0.28644141,  0.22336423],\n",
       "       [ 0.82291343,  0.13575509,  0.78796865,  0.49074353,  0.57843177,\n",
       "         0.89721249,  0.45803851,  0.7293399 ,  0.48713955,  0.05238865],\n",
       "       [ 0.04701202,  0.15026233,  0.14327485,  0.17774822,  0.12724415,\n",
       "         0.74875067,  0.10972231,  0.33873905,  0.83187007,  0.58652726],\n",
       "       [ 0.58619776,  0.97625454,  0.03893576,  0.38603805,  0.59484576,\n",
       "         0.38009614,  0.45332535,  0.05654901,  0.2317886 ,  0.86418238],\n",
       "       [ 0.59593287,  0.41858212,  0.17819271,  0.43542308,  0.26540723,\n",
       "         0.2467089 ,  0.42077208,  0.81053956,  0.28055593,  0.60220062],\n",
       "       [ 0.29546339,  0.65189633,  0.81382272,  0.26878493,  0.22018251,\n",
       "         0.15071861,  0.86639231,  0.87473052,  0.15408404,  0.15991488],\n",
       "       [ 0.04718495,  0.89724205,  0.22599028,  0.07939679,  0.0423287 ,\n",
       "         0.52093463,  0.50117345,  0.63101037,  0.69533066,  0.17119341],\n",
       "       [ 0.36275357,  0.20710108,  0.23229264,  0.71278594,  0.32550505,\n",
       "         0.832092  ,  0.87517353,  0.62283594,  0.8380356 ,  0.01676773],\n",
       "       [ 0.16972911,  0.58235209,  0.80655865,  0.02815506,  0.32099508,\n",
       "         0.51214475,  0.13229151,  0.40294005,  0.28282483,  0.44094979],\n",
       "       [ 0.31031907,  0.10748693,  0.24755767,  0.96987093,  0.74772036,\n",
       "         0.01589396,  0.2428537 ,  0.56765477,  0.76129676,  0.11312729],\n",
       "       [ 0.19516788,  0.41345512,  0.14526979,  0.14983668,  0.98968494,\n",
       "         0.26592738,  0.75215208,  0.7959237 ,  0.645452  ,  0.33857114],\n",
       "       [ 0.57030562,  0.5176258 ,  0.52708186,  0.68918736,  0.35928474,\n",
       "         0.08586058,  0.12535655,  0.35988149,  0.03151212,  0.3535643 ],\n",
       "       [ 0.74068852,  0.31797467,  0.34333411,  0.4165721 ,  0.92346827,\n",
       "         0.97054822,  0.55378794,  0.3323366 ,  0.39707013,  0.21453482],\n",
       "       [ 0.8240454 ,  0.62170203,  0.33604319,  0.13544903,  0.786709  ,\n",
       "         0.37653273,  0.04890634,  0.63808937,  0.60924879,  0.17765041],\n",
       "       [ 0.25261744,  0.97598995,  0.55504472,  0.0473901 ,  0.50133707,\n",
       "         0.33075298,  0.70823813,  0.20642592,  0.53140666,  0.84211648],\n",
       "       [ 0.84599878,  0.42244963,  0.90365847,  0.68450341,  0.83057803,\n",
       "         0.87041952,  0.14581049,  0.23287972,  0.29324888,  0.88186136],\n",
       "       [ 0.07365953,  0.83110518,  0.01911832,  0.4901652 ,  0.69782284,\n",
       "         0.59327675,  0.47838923,  0.40248887,  0.93916836,  0.35281994],\n",
       "       [ 0.5777088 ,  0.55080657,  0.74443791,  0.54123854,  0.96624678,\n",
       "         0.6228865 ,  0.537806  ,  0.57355116,  0.11456035,  0.3900217 ],\n",
       "       [ 0.97977855,  0.44736266,  0.49078663,  0.54285732,  0.32427794,\n",
       "         0.43356259,  0.9303371 ,  0.9379012 ,  0.21005999,  0.05562449],\n",
       "       [ 0.9348441 ,  0.52409314,  0.53749589,  0.00890354,  0.9246589 ,\n",
       "         0.9162382 ,  0.07823621,  0.64312406,  0.49610796,  0.24149805],\n",
       "       [ 0.82333273,  0.15123553,  0.28315155,  0.30270124,  0.48101596,\n",
       "         0.39805394,  0.62165189,  0.85174848,  0.44081892,  0.37408117],\n",
       "       [ 0.28008583,  0.52618372,  0.05606394,  0.20219444,  0.92560625,\n",
       "         0.44424004,  0.88325903,  0.63861194,  0.29512643,  0.80488733],\n",
       "       [ 0.21512355,  0.35287999,  0.67802425,  0.13163402,  0.81374865,\n",
       "         0.96690799,  0.74217122,  0.38300092,  0.61155879,  0.22850131],\n",
       "       [ 0.09955753,  0.09899795,  0.37793724,  0.65309662,  0.81998816,\n",
       "         0.21029459,  0.05147283,  0.17804173,  0.1224037 ,  0.48504161],\n",
       "       [ 0.06057694,  0.61599118,  0.09873637,  0.42243601,  0.68138654,\n",
       "         0.33877707,  0.688074  ,  0.13186271,  0.99853298,  0.79921579],\n",
       "       [ 0.26905325,  0.20637036,  0.04663569,  0.61896795,  0.68357004,\n",
       "         0.20642064,  0.54285968,  0.24256971,  0.65744753,  0.05013954],\n",
       "       [ 0.01423055,  0.76588174,  0.65800014,  0.68975409,  0.00431615,\n",
       "         0.05481777,  0.26508186,  0.80617664,  0.36652706,  0.23005172],\n",
       "       [ 0.26080419,  0.20116133,  0.30009909,  0.35791261,  0.08520239,\n",
       "         0.42516267,  0.42004686,  0.59040172,  0.70038415,  0.36737945],\n",
       "       [ 0.53648651,  0.54422687,  0.82869754,  0.53062547,  0.95490238,\n",
       "         0.31551282,  0.88097868,  0.96157695,  0.24598645,  0.54737143],\n",
       "       [ 0.95778515,  0.94967204,  0.65975928,  0.13152109,  0.36850688,\n",
       "         0.47012876,  0.07203359,  0.22640163,  0.52818687,  0.89075645],\n",
       "       [ 0.72390825,  0.30700824,  0.08362171,  0.99682457,  0.36396552,\n",
       "         0.40602647,  0.21520594,  0.00726975,  0.45042013,  0.58651959],\n",
       "       [ 0.37846712,  0.98552577,  0.75831036,  0.45545483,  0.0781113 ,\n",
       "         0.10729256,  0.88302385,  0.08858685,  0.33789779,  0.16745426],\n",
       "       [ 0.78410595,  0.37126323,  0.40079404,  0.31598694,  0.15368414,\n",
       "         0.92610585,  0.68685578,  0.09038368,  0.92228877,  0.0390835 ],\n",
       "       [ 0.58586067,  0.13984992,  0.32049861,  0.30441623,  0.83638376,\n",
       "         0.70170898,  0.61283791,  0.90076616,  0.14833121,  0.20168246],\n",
       "       [ 0.64684444,  0.67382701,  0.94389746,  0.68174365,  0.55750871,\n",
       "         0.04009767,  0.34548564,  0.45594044,  0.51869905,  0.19779132],\n",
       "       [ 0.63845918,  0.82703763,  0.42726159,  0.04137849,  0.02110798,\n",
       "         0.67307882,  0.78171519,  0.25642096,  0.93263422,  0.1576451 ],\n",
       "       [ 0.19135703,  0.29272127,  0.59368631,  0.34955012,  0.33752577,\n",
       "         0.19023859,  0.24754895,  0.12531333,  0.0795029 ,  0.92412843],\n",
       "       [ 0.15968014,  0.46145092,  0.93328861,  0.37382964,  0.29863305,\n",
       "         0.84410959,  0.6451681 ,  0.70249583,  0.81318708,  0.48724116],\n",
       "       [ 0.64656252,  0.83283828,  0.46831779,  0.64489877,  0.14105499,\n",
       "         0.51396612,  0.15787197,  0.00762742,  0.78175969,  0.99561127],\n",
       "       [ 0.29691695,  0.75076349,  0.99695541,  0.77372813,  0.4140949 ,\n",
       "         0.91781605,  0.23402254,  0.88166168,  0.10994556,  0.44675655],\n",
       "       [ 0.02504055,  0.01515094,  0.02225921,  0.42606896,  0.11719185,\n",
       "         0.69678636,  0.79003298,  0.43150229,  0.48942045,  0.27053414],\n",
       "       [ 0.3504132 ,  0.75387099,  0.08429655,  0.87765314,  0.32758868,\n",
       "         0.01968501,  0.64669831,  0.61446973,  0.42204256,  0.13513868],\n",
       "       [ 0.11863664,  0.29850374,  0.5623908 ,  0.61709204,  0.33578092,\n",
       "         0.55255172,  0.41836612,  0.10516796,  0.90161159,  0.43875132],\n",
       "       [ 0.69200495,  0.10827832,  0.96591526,  0.78135311,  0.78093688,\n",
       "         0.65399566,  0.79024086,  0.15057151,  0.60882871,  0.64562803],\n",
       "       [ 0.97538173,  0.8750651 ,  0.54049226,  0.5007471 ,  0.01310951,\n",
       "         0.4302572 ,  0.6204662 ,  0.09969946,  0.79046122,  0.86302953],\n",
       "       [ 0.88575023,  0.71453915,  0.66838759,  0.00807509,  0.10796825,\n",
       "         0.28924461,  0.43585174,  0.70659264,  0.42301804,  0.67818427],\n",
       "       [ 0.82840508,  0.37731577,  0.61816715,  0.43701855,  0.070886  ,\n",
       "         0.88304623,  0.76064272,  0.70581659,  0.69102591,  0.63954135],\n",
       "       [ 0.16197798,  0.88654437,  0.0211608 ,  0.01017243,  0.54333285,\n",
       "         0.95681006,  0.87020887,  0.1595765 ,  0.01910247,  0.02305249],\n",
       "       [ 0.62166994,  0.51073757,  0.810016  ,  0.72751005,  0.79775635,\n",
       "         0.6868409 ,  0.80681558,  0.25820848,  0.81850626,  0.67336139],\n",
       "       [ 0.46249744,  0.31916708,  0.68895118,  0.11479338,  0.86327439,\n",
       "         0.90996866,  0.05281449,  0.53039833,  0.03667784,  0.552955  ],\n",
       "       [ 0.86994243,  0.23734314,  0.16319282,  0.33887387,  0.1814452 ,\n",
       "         0.74694552,  0.67455021,  0.75818689,  0.35008047,  0.43453915],\n",
       "       [ 0.04622543,  0.00501017,  0.92554136,  0.64359924,  0.71556018,\n",
       "         0.94160828,  0.3609226 ,  0.67518992,  0.15608543,  0.67695104],\n",
       "       [ 0.35011067,  0.88944262,  0.65964905,  0.79403385,  0.86651383,\n",
       "         0.83398769,  0.26755727,  0.61365452,  0.29288411,  0.13973953],\n",
       "       [ 0.40365544,  0.79786185,  0.22263682,  0.79269288,  0.5274801 ,\n",
       "         0.25221726,  0.19909286,  0.0292619 ,  0.79054252,  0.79036698],\n",
       "       [ 0.87368354,  0.94681367,  0.06301818,  0.96777127,  0.63334022,\n",
       "         0.75758023,  0.88067342,  0.47997977,  0.34372251,  0.93182713],\n",
       "       [ 0.64714639,  0.33746592,  0.82994703,  0.76127206,  0.89230615,\n",
       "         0.12571719,  0.43098381,  0.51644928,  0.63209318,  0.66836268]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.random.rand(n_samples,\n",
    "                         n_variables)\n",
    "x_train.shape\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training target vectors \n",
    "\n",
    "Create `y_train_float` as matrix product of `x_train` and `x_gen`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.32153063],\n",
       "       [ 10.05591722],\n",
       "       [ 10.71739432],\n",
       "       [  8.50341081],\n",
       "       [ 12.49024336],\n",
       "       [ 11.79245673],\n",
       "       [ 10.2176994 ],\n",
       "       [  7.99097743],\n",
       "       [ 11.78691026],\n",
       "       [  9.06098772],\n",
       "       [  9.37204779],\n",
       "       [  7.07348345],\n",
       "       [ 13.52217758],\n",
       "       [  9.57048663],\n",
       "       [  7.40999057],\n",
       "       [  9.49644443],\n",
       "       [  7.68069195],\n",
       "       [ 10.87475099],\n",
       "       [ 11.88801897],\n",
       "       [ 12.21709772],\n",
       "       [ 12.6438729 ],\n",
       "       [ 12.7454459 ],\n",
       "       [  8.47073176],\n",
       "       [ 12.83036712],\n",
       "       [ 12.05423756],\n",
       "       [  7.76460261],\n",
       "       [ 12.85710791],\n",
       "       [ 11.4559428 ],\n",
       "       [ 11.97170206],\n",
       "       [  9.62997114],\n",
       "       [  6.01956162],\n",
       "       [  7.26538131],\n",
       "       [  8.12882899],\n",
       "       [ 12.69285948],\n",
       "       [ 13.58907651],\n",
       "       [ 10.43465524],\n",
       "       [  8.78664839],\n",
       "       [ 12.67986555],\n",
       "       [  6.07531227],\n",
       "       [  9.75071298],\n",
       "       [ 11.2188522 ],\n",
       "       [ 12.84267965],\n",
       "       [ 13.0446808 ],\n",
       "       [  9.33382651],\n",
       "       [ 11.36647304],\n",
       "       [ 10.65693709],\n",
       "       [  7.25851391],\n",
       "       [  9.27742736],\n",
       "       [  8.4166366 ],\n",
       "       [  8.2221979 ],\n",
       "       [  7.9507268 ],\n",
       "       [ 11.00051787],\n",
       "       [  6.92189387],\n",
       "       [  8.59545104],\n",
       "       [  9.4582078 ],\n",
       "       [  6.91698129],\n",
       "       [ 10.72372844],\n",
       "       [  8.46064571],\n",
       "       [  9.47311982],\n",
       "       [ 12.02808224],\n",
       "       [ 10.74669255],\n",
       "       [ 11.08050693],\n",
       "       [ 10.21095167],\n",
       "       [ 10.06320184],\n",
       "       [  9.04985373],\n",
       "       [ 10.4228026 ],\n",
       "       [ 10.45249557],\n",
       "       [  6.57956035],\n",
       "       [ 10.27307896],\n",
       "       [  7.55776839],\n",
       "       [  7.78201661],\n",
       "       [  7.6392809 ],\n",
       "       [ 12.17368445],\n",
       "       [  9.4936089 ],\n",
       "       [  8.87686141],\n",
       "       [  7.90621931],\n",
       "       [  9.43829656],\n",
       "       [  9.60443773],\n",
       "       [  9.25477022],\n",
       "       [  9.16221487],\n",
       "       [  6.41789078],\n",
       "       [ 11.56313872],\n",
       "       [ 10.4250022 ],\n",
       "       [ 12.04299432],\n",
       "       [  7.64353105],\n",
       "       [  8.92634209],\n",
       "       [  9.18632201],\n",
       "       [ 12.13293514],\n",
       "       [ 10.83254894],\n",
       "       [  8.5784051 ],\n",
       "       [ 11.89722324],\n",
       "       [  8.08772135],\n",
       "       [ 13.40551008],\n",
       "       [  8.93630901],\n",
       "       [  9.56288354],\n",
       "       [ 10.90682802],\n",
       "       [ 12.03340808],\n",
       "       [ 10.03023511],\n",
       "       [ 14.54546968],\n",
       "       [ 11.09338323]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_float = x_train.dot(x_gen).reshape(n_samples,1) \n",
    "y_train_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `y_train_int` by rounding entries of `y_train_float` to the nearest integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8],\n",
       "       [10],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [12],\n",
       "       [12],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [14],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [13],\n",
       "       [13],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [11],\n",
       "       [12],\n",
       "       [10],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [14],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [13],\n",
       "       [ 6],\n",
       "       [10],\n",
       "       [11],\n",
       "       [13],\n",
       "       [13],\n",
       "       [ 9],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [12],\n",
       "       [11],\n",
       "       [11],\n",
       "       [10],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [12],\n",
       "       [10],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [12],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [10],\n",
       "       [15],\n",
       "       [11]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_int = np.round(y_train_float).astype(np.int32)\n",
    "y_train_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `y_train_cat` from `y_train_int` using `to_categorical` by creating binary variables for each (integer) value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = np_utils.to_categorical(y_train_int.reshape(n_samples,\n",
    "                                                          1))\n",
    "y_train_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first column of `y_train_cat` contains only zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_cat[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the correspondence between the unique values in `y_train_int` and the unique rows is `y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique integer values: [ 6  7  8  9 10 11 12 13 14 15]\n",
      "unique rows below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15\n",
       "0    0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "1    0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "2    0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
       "3    0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
       "4    0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
       "11   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
       "12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "20   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "30   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
       "98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"unique integer values:\",np.unique(y_train_int))\n",
    "print(\"unique rows below\")\n",
    "pd.DataFrame(y_train_cat).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "middle_layer_count = 64\n",
    "\n",
    "model.add(Dense(input_dim  = n_variables, \n",
    "                output_dim = middle_layer_count, \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(input_dim  = middle_layer_count, \n",
    "                output_dim = y_train_cat.shape[1], \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the loss function and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model \n",
    "\n",
    "Use the data in `x_train` and `y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, \n",
    "          y_train_cat, \n",
    "          nb_epoch      = n_epoch, \n",
    "          batch_size    = n_samples, \n",
    "          verbose       = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_train,\n",
    "               y_train_cat, \n",
    "               verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted values for the 3rd sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arow = 34\n",
    "print(\"target value:\",y_train_int[arow])\n",
    "print(\"prediction  :\",model.predict_classes(np.array([x_train[arow]]), \n",
    "                                            verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted values for the first `10` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"actual\"   : y_train_int.reshape(n_samples),\n",
    "              \"predicted\": model.predict_classes(x_train,\n",
    "                                                 verbose=False)}\n",
    "            )[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display frequency counts\n",
    "\n",
    "Display frequence counts for the absolute difference between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(x_train, \n",
    "                               verbose=False\n",
    "                              ).reshape(n_samples,)\n",
    "\n",
    "y_init = y_train_int.reshape(n_samples,)\n",
    "\n",
    "y_freq = np.bincount(abs(y_pred - y_init))\n",
    "\n",
    "print(\"Frequency counts:\", y_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print  (\"Accuracy: %.1f percent\" % \n",
    "        np.round(100*y_freq[0] / sum(y_freq), \n",
    "                 decimals=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create regression model\n",
    "\n",
    "The training data consists of:\n",
    "- `x_train` (same as above)\n",
    "- `y_train_float` calculated directly from `x_train` and `x_gen` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "middle_layer_count = 64\n",
    "\n",
    "model.add(Dense(input_dim  = n_variables, \n",
    "                output_dim = middle_layer_count, \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(input_dim  = middle_layer_count, \n",
    "                output_dim = y_train_float.shape[1])) \n",
    "\n",
    "model.compile(loss      = 'mean_absolute_error', \n",
    "              optimizer = 'rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, \n",
    "          y_train_float, \n",
    "          nb_epoch=n_epoch, \n",
    "          batch_size=n_samples, \n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the actual and predicted values side by side\n",
    "\n",
    "Include the square error for each row and the mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_err = pd.DataFrame({\n",
    "        \"actual\"   : y_train_float         .reshape(n_samples),\n",
    "        \"predicted\": model.predict(x_train).reshape(n_samples),\n",
    "        \"sq_err\"   : 0\n",
    "    })\n",
    "pred_err['sq_err'] = (pred_err['actual'] - pred_err['predicted'])**2\n",
    "print('Mean square error:', np.mean(pred_err['sq_err']))\n",
    "pred_err[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
