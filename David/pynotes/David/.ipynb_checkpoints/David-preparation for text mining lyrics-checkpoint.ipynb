{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Million Songs Dataset - preparation for text mining lyrics\n",
    "\n",
    "This notebook was initially a copy of \n",
    "\n",
    "- `Presentation-Alyssa Create-Dictionary-From-Word-Freq` by Alyssa Tasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the HDF5 files, there are also four SQLite databases available. These four databases are:\n",
    "\n",
    "* [track_metadata.db](http://labrosa.ee.columbia.edu/millionsong/sites/default/files/AdditionalFiles/track_metadata.db) contains most metadata about each track\n",
    "* [artist_term.db](http://www.ee.columbia.edu/~thierry/artist_term.db) links artists id's to the tags\n",
    "* [artist_similarity.db](http://www.ee.columbia.edu/~thierry/artist_similarity.db) contains similarity among artists\n",
    "* [mxm_dataset.db](http://labrosa.ee.columbia.edu/millionsong/sites/default/files/AdditionalFiles/mxm_dataset.db) has lyrics for many of the tracks\n",
    "   \n",
    "Information about the first three can be found at http://labrosa.ee.columbia.edu/millionsong/pages/getting-dataset#subset \n",
    "\n",
    "For information about the musiXmatch database go to http://labrosa.ee.columbia.edu/millionsong/musixmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Connections/Query Database\n",
    "\n",
    "We first need to create a connection to each of our database files. The connection path specifies the directory in which the downloaded files have been stored. We'll use the connection every time we query the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn_tracks     = sqlite3.connect('/Users/david/Dropbox/Data/track_metadata.db')\n",
    "conn_terms      = sqlite3.connect('/Users/david/Dropbox/Data/artist_term.db')\n",
    "conn_similarity = sqlite3.connect('/Users/david/Dropbox/Data/artist_similarity.db')\n",
    "conn_lyrics     = sqlite3.connect('/Users/david/Dropbox/Data/mxm_dataset.db')\n",
    "conn_lastfm     = sqlite3.connect('/Users/david/Dropbox/Data/lastfm_tags.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data frame with rows for each track and columns for each word. \n",
    "\n",
    "Cells contain the count of that word in the lyrics for that track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `mss_df` and `lyrics_df` dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_load_path = '/Users/David/Desktop'\n",
    "mss_df = pd.read_pickle(save_load_path+'/mss_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_load_path = '/Users/David/Desktop'\n",
    "lyrics_df = pd.read_pickle(save_load_path+'/lyrics_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>mxm_tid</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>4623710</td>\n",
       "      <td>i</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>4623710</td>\n",
       "      <td>the</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>4623710</td>\n",
       "      <td>you</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>4623710</td>\n",
       "      <td>to</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                track  mxm_tid word  count  is_test\n",
       "0  TRAAAAV128F421A322  4623710    i      6        0\n",
       "1  TRAAAAV128F421A322  4623710  the      4        0\n",
       "2  TRAAAAV128F421A322  4623710  you      2        0\n",
       "3  TRAAAAV128F421A322  4623710   to      2        0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `lyrics_df` dataframe was created with the following commands. Don't run them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "lyrics_df = pd.DataFrame(pd.read_sql('SELECT * FROM lyrics',\n",
    "                                     con=conn_lyrics))\n",
    "lyrics_df=lyrics_df.rename(columns = {'track_id':'track'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "save_load_path = '/Users/David/Desktop'\n",
    "lyrics_df.to_pickle(save_load_path+'/lyrics_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5000 unique words in all lyrics of all tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " array(['i', 'the', 'you', ..., 'pudiera', 'vuela', 'bla'], dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(lyrics_df.word.ravel())), pd.unique(lyrics_df.word.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the stopwords from the `nltk` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "stopword_set = set(nltk.corpus.stopwords.words('english'))\n",
    "is_not_stopword = [word not in stopword_set for word in lyrics_df.word.ravel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe `lyrics_sub_df` by removing the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics_sub_df = lyrics_df[is_not_stopword]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More words should be dropped. For example numbers and punctuation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went from 19 million to 12 million words-lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19045332, 5), (12789780, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.shape, lyrics_sub_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now 4884 unique words for all the lyrics, which doesn't seem like much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4884,\n",
       " array(['like', 'de', 'got', ..., 'pudiera', 'vuela', 'bla'], dtype=object))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(lyrics_sub_df.word.ravel())), pd.unique(lyrics_sub_df.word.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge the lyrics without stopwords dataframe `lyrics_sub_df` with the `mss_df` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_lyrics_df = lyrics_sub_df.merge(mss_df, how='inner', on='track')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now of 138 thousand words-lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137908, 121)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_lyrics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we really just want the variables `track`, `word` and `count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_lyrics_twc_df = mss_lyrics_df[['track','word','count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want more variables later then they should be merged into the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we _gather_ the rows into columns. __R__ users will recall the `tidyr` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mss_lyrics_pvt_df = mss_lyrics_df.pivot(index='track', \n",
    "                                        columns='word', \n",
    "                                        values='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now only have 2350 tracks, from the original 10,000 of `mss_df`, which have lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 4735)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_lyrics_pvt_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at a bit of the dataframe we see mostly `NaN` values and a few numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>amar</th>\n",
       "      <th>amart</th>\n",
       "      <th>amaz</th>\n",
       "      <th>ambit</th>\n",
       "      <th>amen</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>ami</th>\n",
       "      <th>amiga</th>\n",
       "      <th>amigo</th>\n",
       "      <th>amo</th>\n",
       "      <th>among</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAAABD128F429CF47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAEF128F4273421</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAFD128F92F423A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAARJ128F9320760</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAABJV128F1460C49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAABLR128F423B7E3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAABVM128F92CA9DC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAACER128F4290F96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAACFV128F935E50B</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAACHN128F1489601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "word                amar  amart  amaz  ambit  amen  america  american  ami  \\\n",
       "track                                                                        \n",
       "TRAAABD128F429CF47   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "TRAAAEF128F4273421   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "TRAAAFD128F92F423A   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "TRAAARJ128F9320760   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "TRAABJV128F1460C49   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "TRAABLR128F423B7E3   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "TRAABVM128F92CA9DC   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "TRAACER128F4290F96   NaN    NaN   NaN      1   NaN      NaN       NaN  NaN   \n",
       "TRAACFV128F935E50B   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "TRAACHN128F1489601   NaN    NaN   NaN    NaN   NaN      NaN       NaN  NaN   \n",
       "\n",
       "word                amiga  amigo  amo  among  \n",
       "track                                         \n",
       "TRAAABD128F429CF47    NaN    NaN  NaN    NaN  \n",
       "TRAAAEF128F4273421    NaN    NaN  NaN    NaN  \n",
       "TRAAAFD128F92F423A    NaN    NaN  NaN    NaN  \n",
       "TRAAARJ128F9320760    NaN    NaN  NaN    NaN  \n",
       "TRAABJV128F1460C49    NaN    NaN  NaN    NaN  \n",
       "TRAABLR128F423B7E3    NaN    NaN  NaN    NaN  \n",
       "TRAABVM128F92CA9DC    NaN    NaN  NaN      2  \n",
       "TRAACER128F4290F96    NaN    NaN  NaN    NaN  \n",
       "TRAACFV128F935E50B    NaN    NaN  NaN    NaN  \n",
       "TRAACHN128F1489601    NaN    NaN  NaN    NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_lyrics_pvt_df.iloc[0:10,140:152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NaN_locations = np.isnan(mss_lyrics_pvt_df)\n",
    "mss_lyrics_pvt_df[NaN_locations] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>amar</th>\n",
       "      <th>amart</th>\n",
       "      <th>amaz</th>\n",
       "      <th>ambit</th>\n",
       "      <th>amen</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>ami</th>\n",
       "      <th>amiga</th>\n",
       "      <th>amigo</th>\n",
       "      <th>amo</th>\n",
       "      <th>among</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAAABD128F429CF47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAEF128F4273421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAFD128F92F423A</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAARJ128F9320760</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAABJV128F1460C49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAABLR128F423B7E3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAABVM128F92CA9DC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAACER128F4290F96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAACFV128F935E50B</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAACHN128F1489601</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "word                amar  amart  amaz  ambit  amen  america  american  ami  \\\n",
       "track                                                                        \n",
       "TRAAABD128F429CF47     0      0     0      0     0        0         0    0   \n",
       "TRAAAEF128F4273421     0      0     0      0     0        0         0    0   \n",
       "TRAAAFD128F92F423A     0      0     0      0     0        0         0    0   \n",
       "TRAAARJ128F9320760     0      0     0      0     0        0         0    0   \n",
       "TRAABJV128F1460C49     0      0     0      0     0        0         0    0   \n",
       "TRAABLR128F423B7E3     0      0     0      0     0        0         0    0   \n",
       "TRAABVM128F92CA9DC     0      0     0      0     0        0         0    0   \n",
       "TRAACER128F4290F96     0      0     0      1     0        0         0    0   \n",
       "TRAACFV128F935E50B     0      0     0      0     0        0         0    0   \n",
       "TRAACHN128F1489601     0      0     0      0     0        0         0    0   \n",
       "\n",
       "word                amiga  amigo  amo  among  \n",
       "track                                         \n",
       "TRAAABD128F429CF47      0      0    0      0  \n",
       "TRAAAEF128F4273421      0      0    0      0  \n",
       "TRAAAFD128F92F423A      0      0    0      0  \n",
       "TRAAARJ128F9320760      0      0    0      0  \n",
       "TRAABJV128F1460C49      0      0    0      0  \n",
       "TRAABLR128F423B7E3      0      0    0      0  \n",
       "TRAABVM128F92CA9DC      0      0    0      2  \n",
       "TRAACER128F4290F96      0      0    0      0  \n",
       "TRAACFV128F935E50B      0      0    0      0  \n",
       "TRAACHN128F1489601      0      0    0      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_lyrics_pvt_df.iloc[0:10,140:152]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore the rest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading tags and tracks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_lastfm.execute(\"SELECT * FROM sqlite_master WHERE type = 'table'\")\n",
    "schema1 = res.fetchall()\n",
    "schema1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've created connections, there are a couple of ways we can pull data from the databases:\n",
    "\n",
    "1. We can use SQLite to create a cursor which then fetches records based on our query parameters. A cursor is a database object used to traverse records in a database. The .execute method creates a cursor and then calls the cursors execute method. It returns the results as a list.\n",
    "\n",
    "2. We can use the pandas read_sql function. It returns the results as a pandas DataFrame object\n",
    "\n",
    "First, we'll want to look at the database schema. We'll start off by querying the sqlite_master table from a single sqlite database file using a sqlite cursor. The sqlite_master table defines the schema for the database. We'll use that to get information about the database and create our first query. More information about the sqlite_master table can be found at https://www.sqlite.org/faq.html#q7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `tag_df` to contain `tag_id` (from row id) and `tag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_lastfm.execute(\"select * from tags\")\n",
    "tag_df = pd.DataFrame(res.fetchall(),\n",
    "             columns=['tag'])\n",
    "tag_df['tag_id'] = tag_df.index.values + 1\n",
    "tag_df.shape, len(pd.unique(tag_df.tag.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are over 0.5 million tags!\n",
    "\n",
    "The following sorts the list of tags and shows that at least this bunch doesn't have duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_df.sort_values('tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `track_df` to contain `track_id` and `track`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_lastfm.execute(\"select * from tids\")\n",
    "track_df = pd.DataFrame(res.fetchall(),\n",
    "             columns=['track'])\n",
    "track_df['track_id'] = track_df.index.values + 1\n",
    "track_df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `tid_tag_df` which will be used to merge `tag_df` and `track_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_lastfm.execute(\"select * from tid_tag\")\n",
    "tid_tag_df = pd.DataFrame(res.fetchall(),\n",
    "                          columns=['track_id', 'tag_id', 'val']\n",
    "                          )\n",
    "tid_tag_df[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `track_tag_df` by merging `track_df` and `tag_df` using `tid_tag_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track_tag_df = tid_tag_df.merge(track_df, \n",
    "                             how='inner', \n",
    "                             on='track_id') \\\n",
    "                         .merge(tag_df,\n",
    "                             how='inner',\n",
    "                             on='tag_id')\n",
    "track_tag_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have a dataframe `track_tag_df` with about half a million tags.\n",
    "\n",
    "I don't know what we can do with this. \n",
    "\n",
    "We could merge it with the `mss_df` dataframe (as below) but that doesn't seem productive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_tag_df = track_tag_df.merge(mss_df[['track','title','release']], \n",
    "                                how='inner',\n",
    "                                on='track')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_tag_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pd.unique(mss_tag_df.track.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alyssa's code from here to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_tracks.execute(\"SELECT * FROM sqlite_master WHERE type = 'table'\")\n",
    "schema1 = res.fetchall()\n",
    "type(schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a single table in the track_metadata, songs. We can also see the fields and data types of the columns. We'll query the table using the two methods outlined above (sqlite fetchall() method and pandas read_sql() method) and compare them. For processing speed we limit our query to the first two songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_tracks.execute(\"SELECT * FROM songs LIMIT 2\")\n",
    "songs_sqlite = res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that these are stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs_sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn it into a pandas DataFrame you can wrap it in a pandas DataFrame object, but you lose some of the information. For example, you can see that the column headers are given as numerical indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(songs_sqlite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to using the pandas read_sql function below. When we start pulling data from tables, this seems preferable, since it retains the column headers. But for preliminary exploration, using the sqlite3 fetchall() and fetchone() methods seem more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs_pd = pd.read_sql('SELECT * FROM songs LIMIT 2', con=conn_tracks)\n",
    "songs_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll explore each of the databases available to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## track_metadata\n",
    "\n",
    "We've seen that there is a single table in track metadata, called songs. Let's find out more about the table. We use our tracks connection to pull data from the songs table. We use fetchall(), which fetches all of the records. We'll use fetchall to get the length of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a connection and use it to get the number of rows in the database (number of items in the list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_tracks.execute(\"SELECT * FROM songs limit 10\")\n",
    "#len(res.fetchall()) \n",
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we look at the contents of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We come up with an empty list. Why? \n",
    "\n",
    "It's because there are no remaining rows to fetch using that cursor. When we used the cursor to determine the length of our list, we traversed the entire list. We need to re-initialize the cursor to look at the values in the list. We'll save the list to a variable this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_tracks.execute(\"SELECT * FROM songs\")\n",
    "tracks = res.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tracks), tracks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at a single track using fetchone(), which fetches the next record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_tracks.execute(\"SELECT * FROM songs\")\n",
    "res.fetchone(), res.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using fetchone()[i] can be used to extract the ith element from the record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_tracks.execute(\"SELECT * FROM songs\")\n",
    "res.fetchone()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets read all of the data into a dataframe we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs = pd.read_sql(\"SELECT * FROM SONGS\", con = conn_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## artist_term\n",
    "\n",
    "The first thing we'll do is look at the table structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_terms.execute(\"Select * FROM sqlite_master where type = 'table'\")\n",
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 5 tables in this database: artists, terms, artist_term, mbtags, and artist_mbtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artists table is simply a list of all of the artists represented in the database. There are 44,745 artists in the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artists = pd.read_sql(\"SELECT * FROM artists\", con=conn_terms)\n",
    "len(artists), artists.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terms table contains 7643 different terms. \n",
    "\n",
    "From http://labrosa.ee.columbia.edu/millionsong/pages/what-difference-between-terms-and-mbtags\n",
    "\n",
    "\"Terms\" are the tags provided by The Echo Nest. They can come from a number of places, but mostly blogs as far as we understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "terms = pd.read_sql(\"SELECT * FROM terms\", con=conn_terms)\n",
    "len(terms), terms.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artist_term table links artists and terms. There are 1,109,381 rows in this table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_term = pd.read_sql(\"SELECT * FROM artist_term\", con=conn_terms)\n",
    "len(artist_term), artist_term.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sum function to find the number of terms associated with artist \"AR002UA1187B9A637D\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(artist_term['artist_id'] == 'AR002UA1187B9A637D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at the terms associated with artist \"AR002UA1187B9A637D\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_term.loc[artist_term['artist_id'] == 'AR002UA1187B9A637D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mbtags table contains 2321 terms. \n",
    "\n",
    " http://labrosa.ee.columbia.edu/millionsong/pages/what-difference-between-terms-and-mbtags\n",
    "\n",
    "\"Mbtags\" are musicbrainz tags, specifically applied by humans to a particular artist. This explains why there are fewer of them (see 'mbtags_count'), but they are usually very clean and informative. For instance, if you want to create a genre recognition task where classes are mutually exclusive, mbtags are likely to be more reliable then terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mbtags = pd.read_sql(\"SELECT * FROM mbtags\", con=conn_terms)\n",
    "len(mbtags), mbtags[200:219]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the artist_mbtag table associates artists with mbtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_mbtag = pd.read_sql(\"SELECT * FROM artist_mbtag\", con=conn_terms)\n",
    "len(artist_mbtag), artist_mbtag.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, using mbtags returns fewer results than using terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_mbtag.loc[artist_mbtag['artist_id'] == 'AR002UA1187B9A637D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## artist_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two tables in the artist_similarity database: artists and similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_similarity.execute(\"Select * FROM sqlite_master where type = 'table'\")\n",
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 44,745 artists in the artists table, the same number of rows in the artist_terms database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artists_s = pd.read_sql(\"SELECT * FROM artists\", con = conn_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(artists_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity = pd.read_sql(\"SELECT * FROM similarity\", con = conn_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2,201,916 rows in the similarity table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same artist we used in exploring the artist_term database, we find the artist is similar to 46 other artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity.loc[similarity['target'] == 'AR002UA1187B9A637D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mxm_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mxm_dataset has two tables: words and lyrics. \n",
    "\n",
    "The words table has a single column: word\n",
    "\n",
    "The lyrics table has five columns:\n",
    "track_id: MSD song id\n",
    "mxm_tid: musiXmatch track id\n",
    "word: one of the words in the table words\n",
    "count: the word count for that track\n",
    "is_test: tells you if a track is in the test set(1) or not(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_lyrics.execute(\"Select * FROM sqlite_master where type = 'table'\")\n",
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5000 unique words in the words table. We look at the first 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics_df = pd.DataFrame(pd.read_sql('SELECT * FROM lyrics limit 10', con=conn_lyrics))\n",
    "lyrics_df[['track_id','mxm_tid','word','count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(words), words.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lyrics table contains the most data of all the tables we've looked at. There are 19,045,332 rows. This is because each row contains two track id's, a word, a count of the number of times the word appears, and a field indicating whether its part of the train or test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics = pd.read_sql(\"SELECT * FROM lyrics\", con=conn_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics.loc[lyrics['track_id'] == 'TRAAAAV128F421A322']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we close our database connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn_tracks.close()\n",
    "conn_terms.close()\n",
    "conn_similarity.close()\n",
    "conn_lyrics.close()\n",
    "conn_lastfm.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "http://labrosa.ee.columbia.edu/millionsong/musixmatch\n",
    "\n",
    "http://labrosa.ee.columbia.edu/millionsong/blog/11-4-11-musixmatch-dataset-connecting-lyrics\n",
    "\n",
    "https://docs.python.org/3.5/library/sqlite3.html\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql.html\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
