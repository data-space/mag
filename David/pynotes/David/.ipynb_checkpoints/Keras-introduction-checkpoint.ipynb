{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - classification and regression\n",
    "\n",
    "Contents:\n",
    "1. Load required libraries\n",
    "1. Set initial parameters\n",
    "1. Create synthetic training datasets\n",
    "1. Create classification model\n",
    "1. Train the model and display accuracy\n",
    "1. Create regression model \n",
    "1. Train the model and display mean square error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas    as pd\n",
    "import numpy     as np\n",
    "import itertools as it\n",
    "\n",
    "from keras.utils       import np_utils \n",
    "from keras.models      import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic training datasets\n",
    "\n",
    "- Set initial parameters\n",
    "- Create a random `x_train` dataset with shape determined by parameters and with random values between `0` and `1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_variables =    10\n",
    "n_samples   =   100\n",
    "n_epoch     = 10000 # number of training iterations\n",
    "min_gen     =     1\n",
    "max_gen     =     4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector `x_gen` \n",
    "\n",
    "The target values of the training datase are created using `x_gen` and `x_train`, which is a matrix of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 2, 1, 3, 3, 3, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gen    = np.random.randint(min_gen, \n",
    "                             max_gen, \n",
    "                             n_variables)\n",
    "x_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `x_train` as a random `n_samples` by `n_variables` matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.91757987e-01,   1.19641117e-01,   3.41608971e-01,\n",
       "          8.58649495e-01,   3.94650245e-01,   4.36248546e-01,\n",
       "          4.50340854e-01,   3.40854603e-01,   1.66086734e-01,\n",
       "          3.05437807e-01],\n",
       "       [  4.05436201e-01,   1.29635167e-01,   7.79616658e-01,\n",
       "          8.13094723e-01,   9.92713048e-01,   7.17005614e-01,\n",
       "          5.16586369e-01,   3.12930154e-02,   1.68805704e-01,\n",
       "          6.33136196e-01],\n",
       "       [  3.96891433e-01,   1.50290680e-01,   4.35668622e-01,\n",
       "          8.21066074e-01,   1.09440456e-01,   3.72808489e-01,\n",
       "          3.07067483e-01,   3.54139406e-01,   5.33341128e-01,\n",
       "          3.06274575e-02],\n",
       "       [  5.29931457e-02,   3.33134872e-01,   4.81082108e-01,\n",
       "          2.05225754e-01,   6.16644667e-01,   8.29698016e-01,\n",
       "          7.58200793e-01,   7.13725390e-01,   2.29721518e-01,\n",
       "          9.57759257e-01],\n",
       "       [  8.42540797e-02,   2.28325236e-01,   8.68036686e-01,\n",
       "          6.27919495e-01,   5.13697871e-01,   2.58466576e-01,\n",
       "          2.16684686e-01,   8.77462216e-01,   5.30247950e-02,\n",
       "          4.44888085e-02],\n",
       "       [  2.32129741e-01,   3.81690754e-01,   7.43292463e-01,\n",
       "          2.31292789e-01,   7.20187073e-01,   2.28470512e-01,\n",
       "          5.96887097e-01,   8.46759958e-01,   7.57350240e-01,\n",
       "          1.99351039e-01],\n",
       "       [  3.30521169e-01,   2.74396444e-01,   9.77093478e-02,\n",
       "          1.56125731e-01,   6.67735935e-01,   1.85598065e-01,\n",
       "          7.10577521e-01,   4.50398552e-01,   1.02489178e-01,\n",
       "          3.79158289e-01],\n",
       "       [  1.66691340e-01,   6.90337350e-01,   2.55171866e-02,\n",
       "          1.64125867e-01,   4.01731687e-01,   8.99192546e-01,\n",
       "          6.79481766e-01,   5.97692254e-01,   1.04489904e-01,\n",
       "          8.02060276e-02],\n",
       "       [  9.58471046e-01,   5.63538584e-02,   8.72649651e-02,\n",
       "          8.21407601e-03,   1.57736815e-01,   8.81209395e-01,\n",
       "          8.36515467e-01,   2.04845433e-01,   5.22320170e-01,\n",
       "          5.98730211e-01],\n",
       "       [  8.05755112e-01,   7.23141289e-01,   7.42953590e-01,\n",
       "          3.66955299e-01,   4.86263341e-01,   5.50300095e-01,\n",
       "          7.65644535e-01,   5.16190863e-01,   9.97534074e-01,\n",
       "          8.35932269e-01],\n",
       "       [  2.32524598e-01,   6.69969592e-01,   9.92388726e-01,\n",
       "          1.93128187e-01,   1.98953738e-01,   2.76402673e-02,\n",
       "          8.13507902e-01,   9.99274969e-01,   3.72691505e-02,\n",
       "          8.15279570e-01],\n",
       "       [  6.06024952e-01,   6.29452595e-01,   3.30644982e-01,\n",
       "          6.19962507e-01,   9.39405972e-01,   9.86934538e-01,\n",
       "          8.96650164e-01,   3.73941000e-01,   7.22244492e-01,\n",
       "          5.42366604e-01],\n",
       "       [  7.21166432e-01,   6.76734654e-01,   9.08315040e-01,\n",
       "          6.55291257e-01,   4.08974994e-02,   1.29772513e-01,\n",
       "          1.58108392e-01,   7.94809370e-01,   5.19638925e-01,\n",
       "          9.26348683e-02],\n",
       "       [  7.91897118e-01,   4.97617210e-01,   3.51261677e-01,\n",
       "          3.40554202e-02,   6.13572017e-01,   8.49107309e-01,\n",
       "          7.39230937e-01,   3.15809614e-01,   7.07842726e-01,\n",
       "          7.40354593e-01],\n",
       "       [  8.18307185e-01,   5.38008380e-01,   5.13368567e-01,\n",
       "          8.13376302e-01,   1.06073667e-01,   1.50559523e-01,\n",
       "          9.29869234e-01,   7.27773647e-01,   3.85968241e-01,\n",
       "          2.64889402e-01],\n",
       "       [  8.00231650e-01,   4.84280067e-01,   2.88894160e-01,\n",
       "          3.06227980e-01,   9.92065624e-01,   2.73258888e-02,\n",
       "          8.76789953e-04,   4.12651109e-01,   8.11025245e-01,\n",
       "          1.92917199e-01],\n",
       "       [  8.84980648e-01,   6.13984285e-01,   8.73943917e-01,\n",
       "          7.78090560e-01,   2.57495210e-01,   8.94349502e-01,\n",
       "          1.96205764e-01,   6.36257596e-01,   5.05580766e-01,\n",
       "          5.22782211e-01],\n",
       "       [  8.70798336e-01,   8.55002735e-01,   9.43069118e-02,\n",
       "          3.49481903e-01,   6.58870236e-01,   7.88560211e-01,\n",
       "          3.54986426e-01,   8.26783457e-02,   8.06799968e-02,\n",
       "          4.29740043e-01],\n",
       "       [  5.47903396e-01,   5.08468167e-02,   9.54459048e-01,\n",
       "          8.28141285e-01,   5.79443393e-02,   1.06932856e-01,\n",
       "          5.25626704e-02,   3.38508981e-01,   4.45035188e-01,\n",
       "          8.49367968e-01],\n",
       "       [  9.41267763e-01,   3.89661652e-01,   1.34948605e-01,\n",
       "          2.82782729e-01,   6.86092597e-01,   8.70083387e-01,\n",
       "          5.55556015e-01,   1.34761839e-02,   6.82392407e-01,\n",
       "          8.41104917e-01],\n",
       "       [  3.77093293e-01,   3.00531093e-01,   2.43533612e-02,\n",
       "          6.54983474e-01,   9.94931128e-01,   7.37714808e-01,\n",
       "          3.99787614e-01,   8.20012351e-01,   2.19937006e-01,\n",
       "          4.29883924e-01],\n",
       "       [  5.66903730e-01,   2.74670218e-01,   5.53852984e-01,\n",
       "          5.00672015e-01,   3.51400207e-02,   8.32406082e-01,\n",
       "          6.05296917e-01,   6.28100993e-01,   7.55856695e-01,\n",
       "          2.83772782e-01],\n",
       "       [  9.21604356e-01,   9.43106444e-01,   9.14310018e-01,\n",
       "          8.04636629e-01,   4.16253428e-01,   3.12945748e-01,\n",
       "          4.12307592e-01,   5.21239539e-01,   5.48648145e-01,\n",
       "          8.26244945e-01],\n",
       "       [  5.87943823e-02,   5.51468118e-01,   9.08880969e-01,\n",
       "          6.62195831e-01,   7.62800920e-02,   1.17024238e-01,\n",
       "          6.71195454e-01,   1.11506185e-01,   6.26566148e-01,\n",
       "          8.94968162e-01],\n",
       "       [  9.40528570e-01,   4.88816650e-01,   5.80216096e-01,\n",
       "          2.52982490e-02,   1.84568677e-01,   3.22080963e-01,\n",
       "          4.57491918e-01,   4.12277434e-01,   2.61172426e-01,\n",
       "          1.66397572e-01],\n",
       "       [  2.79538837e-02,   7.55620725e-01,   8.41387617e-01,\n",
       "          5.40724655e-01,   1.18926238e-01,   9.77902084e-02,\n",
       "          2.99359989e-01,   5.16141187e-01,   4.13124724e-01,\n",
       "          2.64172505e-01],\n",
       "       [  3.55677690e-01,   1.73913762e-01,   2.48204828e-01,\n",
       "          8.05232011e-01,   9.11712796e-01,   2.26072023e-01,\n",
       "          9.82461350e-01,   9.00030328e-01,   7.44983274e-01,\n",
       "          5.50611473e-01],\n",
       "       [  3.37182537e-01,   2.31220893e-01,   1.39844793e-01,\n",
       "          9.53728438e-01,   6.58835365e-01,   6.12375672e-01,\n",
       "          9.39212262e-01,   4.87833765e-01,   9.57463854e-01,\n",
       "          7.76504317e-01],\n",
       "       [  9.11900242e-01,   3.72382522e-01,   9.64005467e-01,\n",
       "          2.37801489e-02,   2.70153865e-01,   5.75241367e-01,\n",
       "          5.00635976e-01,   6.51701382e-01,   3.07904749e-01,\n",
       "          5.87061752e-01],\n",
       "       [  2.07814717e-01,   1.88424660e-01,   7.80764651e-01,\n",
       "          6.36461261e-01,   9.55145133e-01,   7.59895068e-01,\n",
       "          1.35172446e-01,   5.17796135e-02,   4.33915044e-01,\n",
       "          5.99211959e-01],\n",
       "       [  9.15540674e-01,   1.99128438e-01,   7.12231189e-02,\n",
       "          6.54525176e-01,   7.03032681e-01,   9.28345503e-01,\n",
       "          5.51523760e-01,   2.67444368e-01,   5.22429607e-01,\n",
       "          3.84609283e-01],\n",
       "       [  2.42354037e-01,   5.38813289e-01,   8.14761118e-01,\n",
       "          9.91428912e-01,   7.29633964e-01,   8.45663514e-01,\n",
       "          8.54823310e-01,   1.13427632e-01,   3.64294662e-01,\n",
       "          1.60967983e-02],\n",
       "       [  8.24061336e-01,   3.26482231e-01,   2.97201212e-01,\n",
       "          1.92414576e-01,   9.69688907e-01,   4.26010257e-01,\n",
       "          6.01429056e-01,   9.45982594e-01,   2.50502165e-01,\n",
       "          6.40909826e-01],\n",
       "       [  3.58541988e-01,   2.03464959e-01,   8.45317990e-01,\n",
       "          5.30274817e-01,   6.41395142e-01,   3.53520190e-02,\n",
       "          4.24583642e-01,   5.27270455e-01,   9.97905788e-01,\n",
       "          3.68437769e-01],\n",
       "       [  3.81981390e-01,   5.96276237e-01,   8.55461347e-01,\n",
       "          1.78349314e-01,   9.64337404e-01,   6.02426651e-01,\n",
       "          7.36727186e-01,   6.25527920e-01,   3.49085161e-01,\n",
       "          2.38405572e-01],\n",
       "       [  4.78691837e-01,   7.61034494e-02,   5.71014141e-01,\n",
       "          9.63612684e-01,   1.82774615e-01,   4.64666359e-01,\n",
       "          3.19068673e-01,   3.71141433e-01,   8.85154976e-01,\n",
       "          3.42340569e-01],\n",
       "       [  9.11709099e-01,   6.25222332e-01,   1.81895539e-01,\n",
       "          8.59006309e-01,   2.29299913e-01,   1.71995367e-01,\n",
       "          9.05894233e-01,   9.86208006e-01,   4.93022118e-01,\n",
       "          4.66240776e-01],\n",
       "       [  4.83444954e-01,   7.71936784e-01,   2.24664233e-01,\n",
       "          9.63685828e-01,   5.89679194e-01,   3.95398616e-01,\n",
       "          7.68258130e-01,   3.92126208e-01,   5.73404631e-01,\n",
       "          8.72131225e-01],\n",
       "       [  4.26185103e-01,   5.76109998e-02,   7.04174110e-01,\n",
       "          4.93102915e-01,   5.89263116e-01,   6.04869837e-01,\n",
       "          9.33899139e-01,   8.11527727e-01,   1.00711381e-02,\n",
       "          3.17760676e-01],\n",
       "       [  3.20555490e-01,   7.64830771e-01,   2.01162130e-01,\n",
       "          7.44299209e-01,   5.47365371e-01,   8.16592107e-01,\n",
       "          8.70026548e-01,   4.20423063e-01,   7.90913731e-01,\n",
       "          8.68835971e-01],\n",
       "       [  2.32141280e-01,   8.80204502e-01,   1.07579374e-03,\n",
       "          7.17904018e-01,   4.99510480e-01,   6.53973873e-02,\n",
       "          7.21227335e-01,   5.86602027e-01,   1.18045186e-01,\n",
       "          4.20251574e-01],\n",
       "       [  7.75307257e-02,   7.39533404e-01,   8.81930700e-01,\n",
       "          7.94050860e-01,   4.54847078e-01,   9.05661508e-02,\n",
       "          8.97835520e-01,   1.97965806e-01,   8.11271338e-01,\n",
       "          8.87383816e-02],\n",
       "       [  4.72086668e-01,   6.78271648e-01,   7.97978886e-01,\n",
       "          1.51591803e-01,   5.05198890e-01,   1.93067437e-01,\n",
       "          2.72870784e-01,   9.97801288e-01,   3.82267306e-01,\n",
       "          4.62293274e-01],\n",
       "       [  3.88066922e-01,   1.83887139e-01,   3.32941571e-01,\n",
       "          1.93731670e-01,   1.43728157e-01,   9.73337824e-02,\n",
       "          6.17021307e-01,   4.65212030e-01,   9.79070015e-02,\n",
       "          4.87150857e-01],\n",
       "       [  6.05052333e-01,   7.23243565e-02,   1.63023843e-01,\n",
       "          4.40559632e-01,   7.03196574e-01,   3.30898089e-01,\n",
       "          6.63217714e-01,   3.24584615e-01,   1.15434186e-01,\n",
       "          1.07427747e-01],\n",
       "       [  6.32760370e-01,   7.79105400e-01,   2.53977110e-01,\n",
       "          9.45218108e-02,   8.64620647e-01,   4.37891252e-01,\n",
       "          9.09141711e-02,   5.29728099e-01,   8.17258471e-01,\n",
       "          5.91340965e-01],\n",
       "       [  6.03213729e-01,   6.46172114e-01,   1.82745868e-01,\n",
       "          7.87735642e-01,   8.23503818e-01,   3.49006858e-01,\n",
       "          3.85331449e-01,   2.32059142e-01,   5.56200049e-01,\n",
       "          2.45351343e-01],\n",
       "       [  6.71537575e-01,   1.27534759e-01,   8.53292541e-01,\n",
       "          7.25627757e-01,   2.88670089e-01,   6.54724583e-01,\n",
       "          6.12760046e-01,   2.22021457e-01,   5.91607975e-01,\n",
       "          3.90897683e-01],\n",
       "       [  8.86445709e-01,   5.37057886e-01,   8.90180314e-01,\n",
       "          7.40591811e-01,   3.29449657e-01,   6.39910328e-01,\n",
       "          1.61553039e-01,   3.83925789e-01,   7.56444180e-01,\n",
       "          8.68557977e-01],\n",
       "       [  4.11225622e-01,   5.12879938e-01,   2.30956663e-01,\n",
       "          8.00574308e-01,   3.16402155e-02,   9.54983559e-01,\n",
       "          9.87215697e-01,   2.35651629e-01,   5.60966652e-02,\n",
       "          2.12509943e-01],\n",
       "       [  6.57243637e-02,   2.83976012e-01,   6.77565931e-01,\n",
       "          6.96449861e-01,   5.11661834e-01,   5.53189434e-01,\n",
       "          4.27543958e-01,   7.43591731e-02,   2.84174366e-01,\n",
       "          6.30301777e-02],\n",
       "       [  1.46861185e-01,   2.26784362e-01,   2.28333578e-01,\n",
       "          5.20397438e-01,   2.25440604e-01,   2.87407120e-01,\n",
       "          4.58240827e-01,   7.40201850e-01,   1.17422644e-01,\n",
       "          2.87388515e-01],\n",
       "       [  7.76919012e-01,   8.52050009e-01,   8.58592488e-02,\n",
       "          6.76767236e-01,   8.19109523e-01,   7.50040139e-01,\n",
       "          2.58929051e-01,   7.96814942e-01,   8.57641002e-01,\n",
       "          9.24733535e-01],\n",
       "       [  5.97966957e-01,   4.85899115e-01,   6.56659336e-01,\n",
       "          5.29649526e-01,   2.38672235e-01,   6.53883526e-02,\n",
       "          7.87687366e-01,   5.26179868e-01,   3.64813464e-01,\n",
       "          3.74796853e-01],\n",
       "       [  3.69178095e-01,   1.40819099e-01,   2.73876912e-01,\n",
       "          8.31822079e-01,   1.66355822e-01,   4.89961556e-01,\n",
       "          7.64333024e-02,   3.04347139e-01,   3.88539808e-01,\n",
       "          5.49344950e-01],\n",
       "       [  6.86576776e-01,   6.29381964e-01,   3.74923729e-01,\n",
       "          8.45528594e-01,   9.76874587e-01,   7.75141759e-01,\n",
       "          2.26661077e-01,   5.84093345e-01,   5.08788203e-01,\n",
       "          3.73641480e-01],\n",
       "       [  2.60788178e-01,   6.55643545e-01,   1.90726325e-01,\n",
       "          7.75194840e-01,   4.92361254e-01,   4.59603099e-01,\n",
       "          1.99409825e-01,   2.71608087e-01,   6.96463576e-01,\n",
       "          3.20233001e-01],\n",
       "       [  9.41314915e-01,   9.55435717e-01,   6.30131103e-02,\n",
       "          9.00778248e-01,   5.48530436e-01,   6.28110221e-01,\n",
       "          2.31812924e-01,   7.55927800e-01,   8.85499483e-01,\n",
       "          6.71027477e-01],\n",
       "       [  1.62027772e-01,   1.07891488e-01,   5.03866336e-01,\n",
       "          4.92004498e-01,   5.31028039e-02,   6.47553083e-01,\n",
       "          3.25498666e-01,   1.85546596e-01,   4.46563088e-03,\n",
       "          4.69096375e-01],\n",
       "       [  6.35738911e-01,   7.45616859e-01,   2.58503591e-01,\n",
       "          4.58593166e-01,   7.23357683e-01,   5.91885166e-01,\n",
       "          3.78381242e-01,   4.83179792e-01,   5.22129713e-01,\n",
       "          5.46594315e-01],\n",
       "       [  4.84873917e-01,   2.08065056e-01,   3.69052409e-01,\n",
       "          7.34876774e-01,   8.90524925e-01,   2.68374438e-01,\n",
       "          7.70427340e-01,   3.05797099e-01,   6.02125670e-01,\n",
       "          9.52178994e-01],\n",
       "       [  3.56651044e-01,   3.57736543e-01,   9.71098047e-01,\n",
       "          3.13303685e-01,   8.46981662e-01,   7.16056768e-01,\n",
       "          9.49733753e-01,   1.56186747e-01,   9.01749631e-01,\n",
       "          4.02812767e-01],\n",
       "       [  2.16749313e-01,   4.16855223e-01,   3.12623146e-02,\n",
       "          3.06992487e-01,   4.88978256e-01,   9.61931488e-01,\n",
       "          2.48052739e-01,   7.21486837e-01,   5.27053191e-01,\n",
       "          1.67551192e-01],\n",
       "       [  3.99619115e-01,   9.17065317e-02,   2.74882784e-01,\n",
       "          7.75560808e-01,   1.25272725e-01,   7.29482778e-01,\n",
       "          3.36101394e-01,   1.19088231e-01,   6.58800728e-01,\n",
       "          3.89280275e-01],\n",
       "       [  6.29669464e-01,   9.74431449e-01,   3.64911687e-01,\n",
       "          3.68459181e-01,   3.64351654e-01,   9.83666924e-01,\n",
       "          3.94859643e-01,   1.80163389e-01,   1.89249105e-02,\n",
       "          4.57803012e-01],\n",
       "       [  6.95902653e-01,   2.61639565e-01,   2.62215449e-01,\n",
       "          6.30788546e-01,   9.39761726e-01,   3.37150688e-01,\n",
       "          6.49082441e-01,   3.45432941e-01,   4.46910877e-02,\n",
       "          8.19077376e-02],\n",
       "       [  5.34536537e-01,   8.61049079e-01,   7.24598848e-01,\n",
       "          8.64646355e-01,   7.00697524e-01,   7.81984699e-01,\n",
       "          4.90300705e-02,   9.63311402e-01,   2.21488352e-01,\n",
       "          6.32769667e-01],\n",
       "       [  9.29275040e-01,   9.40593353e-01,   7.38322711e-01,\n",
       "          3.91810588e-01,   8.99444693e-01,   9.89164787e-01,\n",
       "          6.46541844e-02,   3.90754636e-01,   2.45427566e-01,\n",
       "          1.58199589e-01],\n",
       "       [  8.69516407e-01,   5.76816160e-01,   1.70251175e-01,\n",
       "          4.39479440e-01,   2.58119113e-02,   1.02087966e-01,\n",
       "          6.55146704e-01,   3.24278084e-01,   6.92849109e-01,\n",
       "          7.60780728e-01],\n",
       "       [  4.51297418e-01,   2.55645319e-01,   1.23088176e-01,\n",
       "          7.58159164e-01,   1.55958147e-01,   7.16600682e-01,\n",
       "          4.91756950e-02,   1.93885440e-01,   3.58578765e-01,\n",
       "          8.52235504e-02],\n",
       "       [  2.49164742e-01,   4.02156522e-01,   1.42924544e-01,\n",
       "          7.38850291e-01,   7.76074251e-01,   9.98774299e-01,\n",
       "          7.43659795e-01,   8.25016455e-01,   1.75532693e-01,\n",
       "          3.50991336e-02],\n",
       "       [  4.94174395e-01,   2.25630281e-01,   2.83845542e-01,\n",
       "          3.63162169e-01,   2.24240624e-01,   9.74239377e-01,\n",
       "          3.24781270e-01,   4.09036873e-01,   4.35316202e-01,\n",
       "          2.64236061e-01],\n",
       "       [  2.28837419e-01,   2.99489460e-01,   2.52381345e-01,\n",
       "          3.08233872e-01,   2.79166041e-01,   7.87272204e-01,\n",
       "          2.92517419e-01,   6.17631160e-01,   3.92229108e-01,\n",
       "          9.13985387e-01],\n",
       "       [  6.83554075e-02,   5.24243720e-01,   2.51139748e-01,\n",
       "          9.81352644e-01,   6.92161002e-01,   1.50427325e-01,\n",
       "          6.03827772e-01,   7.08571212e-01,   4.49297706e-01,\n",
       "          7.76635462e-01],\n",
       "       [  6.43481236e-01,   3.28074558e-01,   4.18314808e-02,\n",
       "          4.82621605e-01,   4.18002146e-01,   9.52638554e-01,\n",
       "          5.48499742e-01,   9.69153882e-01,   2.96072635e-01,\n",
       "          5.90963061e-01],\n",
       "       [  8.37279512e-01,   6.02615175e-01,   5.64981026e-01,\n",
       "          1.78608262e-01,   6.22240128e-01,   1.30759114e-01,\n",
       "          7.79997198e-01,   9.25721351e-01,   4.52434381e-01,\n",
       "          8.80792414e-01],\n",
       "       [  9.69459347e-01,   8.66716967e-01,   6.11092853e-01,\n",
       "          1.16370304e-01,   8.30880308e-01,   9.29268864e-01,\n",
       "          4.42515064e-01,   9.06305807e-01,   9.05572588e-01,\n",
       "          2.60905248e-01],\n",
       "       [  8.99984025e-01,   6.18817610e-01,   3.91070652e-01,\n",
       "          4.16002048e-02,   6.06886274e-01,   1.16290212e-01,\n",
       "          7.11800752e-02,   9.60024402e-01,   5.31486948e-01,\n",
       "          3.51368286e-01],\n",
       "       [  6.65243873e-01,   9.97855232e-01,   2.29539221e-01,\n",
       "          7.03301007e-01,   8.28173967e-01,   9.24804912e-01,\n",
       "          4.38233146e-01,   5.12212760e-01,   2.22449571e-01,\n",
       "          7.41556482e-01],\n",
       "       [  5.17327104e-01,   8.81659343e-01,   2.47399690e-01,\n",
       "          8.65552735e-02,   3.93666133e-01,   2.27933779e-01,\n",
       "          9.24943107e-01,   1.20483722e-01,   9.32165973e-01,\n",
       "          4.19805542e-01],\n",
       "       [  1.77890961e-01,   5.58330024e-01,   6.43844723e-01,\n",
       "          2.77092698e-01,   3.16671693e-02,   6.50120947e-01,\n",
       "          8.93991687e-01,   1.25007230e-01,   4.08976193e-01,\n",
       "          4.71396521e-01],\n",
       "       [  3.32106864e-01,   6.72515721e-01,   2.67627730e-03,\n",
       "          9.23778087e-01,   6.93252146e-01,   1.15795814e-01,\n",
       "          9.32568931e-01,   4.12090407e-01,   8.76893566e-01,\n",
       "          2.52665419e-01],\n",
       "       [  8.78977288e-01,   6.71248502e-01,   4.29085368e-01,\n",
       "          9.41932525e-01,   9.93574397e-01,   2.74503872e-01,\n",
       "          4.55124254e-01,   4.00426796e-01,   5.14282265e-02,\n",
       "          7.49641622e-01],\n",
       "       [  1.80710465e-01,   1.50947509e-01,   5.14284978e-01,\n",
       "          2.93577286e-01,   1.19255275e-01,   1.24638040e-01,\n",
       "          2.50205139e-01,   4.30741288e-01,   6.03924503e-01,\n",
       "          2.12152518e-01],\n",
       "       [  6.06850772e-01,   5.27042205e-01,   2.29268727e-01,\n",
       "          3.41068004e-01,   1.05770163e-01,   1.17609914e-01,\n",
       "          7.35090364e-01,   1.04791534e-02,   1.34178641e-02,\n",
       "          9.39010904e-01],\n",
       "       [  3.88777815e-01,   4.78067660e-01,   5.26492258e-02,\n",
       "          3.53701063e-01,   3.36634993e-01,   2.12285627e-01,\n",
       "          9.83851987e-01,   6.50396169e-01,   3.01309559e-01,\n",
       "          7.08595935e-01],\n",
       "       [  6.18515813e-01,   5.40531203e-02,   3.81316308e-01,\n",
       "          3.70150979e-01,   9.02635655e-01,   7.47580083e-01,\n",
       "          2.31340634e-01,   6.99359263e-01,   2.62834357e-01,\n",
       "          8.58725782e-01],\n",
       "       [  9.11299177e-01,   3.54602153e-01,   8.14409109e-01,\n",
       "          3.14693877e-02,   5.80743640e-01,   4.04625959e-01,\n",
       "          4.04739052e-01,   1.17137334e-01,   1.24552246e-01,\n",
       "          4.33513222e-01],\n",
       "       [  8.82754673e-01,   6.87698481e-01,   6.20855208e-01,\n",
       "          6.32997518e-01,   8.11322446e-01,   4.51942276e-01,\n",
       "          8.56490314e-01,   5.34411950e-01,   4.49770407e-01,\n",
       "          6.85084825e-01],\n",
       "       [  7.68831627e-01,   8.90437723e-01,   5.48260342e-01,\n",
       "          1.20662752e-01,   2.14692914e-03,   9.60375792e-01,\n",
       "          7.39163941e-01,   6.14104867e-01,   8.85330611e-01,\n",
       "          1.18691051e-02],\n",
       "       [  9.88009843e-01,   5.83309421e-01,   3.28302772e-01,\n",
       "          3.14367318e-01,   5.01500876e-01,   7.65998066e-01,\n",
       "          2.57447124e-01,   7.02878308e-01,   3.75492222e-01,\n",
       "          5.97947014e-01],\n",
       "       [  1.51315464e-01,   4.06237498e-01,   1.15959269e-01,\n",
       "          2.80442421e-01,   7.37539715e-01,   5.60113420e-01,\n",
       "          9.84036446e-01,   1.88441297e-01,   5.85916484e-01,\n",
       "          5.33960561e-01],\n",
       "       [  3.72761760e-01,   3.60955261e-01,   4.83497278e-02,\n",
       "          8.95447857e-01,   2.40824723e-01,   9.75705298e-01,\n",
       "          9.81318840e-01,   5.22609902e-01,   4.25097929e-01,\n",
       "          3.28553107e-01],\n",
       "       [  6.66229522e-01,   9.58536966e-01,   6.19107506e-01,\n",
       "          7.75604975e-01,   5.43463177e-01,   3.92459178e-01,\n",
       "          6.89813870e-01,   9.10153567e-01,   4.31727414e-01,\n",
       "          3.01500448e-01],\n",
       "       [  8.64645187e-01,   7.82851929e-01,   6.69646044e-01,\n",
       "          5.98750718e-02,   4.56733280e-01,   8.90241448e-01,\n",
       "          2.05534765e-01,   7.12766253e-01,   1.51085480e-01,\n",
       "          7.07102721e-02],\n",
       "       [  2.94221688e-01,   9.21068261e-01,   4.39948142e-01,\n",
       "          3.37667887e-01,   9.84913028e-01,   1.28192524e-02,\n",
       "          5.07971841e-01,   1.34364858e-01,   2.06342220e-01,\n",
       "          2.78192261e-01],\n",
       "       [  9.87722893e-01,   8.57746453e-01,   7.82087945e-01,\n",
       "          6.83744351e-01,   7.76046760e-01,   8.72923599e-01,\n",
       "          1.02515971e-01,   9.75018456e-01,   9.14186781e-01,\n",
       "          6.75991615e-01],\n",
       "       [  5.72956258e-01,   4.50947012e-01,   6.81867514e-02,\n",
       "          6.17948276e-01,   3.08356618e-01,   8.12857496e-01,\n",
       "          4.72197456e-01,   3.39509240e-01,   1.04921008e-02,\n",
       "          6.65851636e-01],\n",
       "       [  8.74773086e-01,   4.62091637e-01,   6.68196499e-01,\n",
       "          6.25768295e-01,   6.93169214e-02,   8.18434562e-01,\n",
       "          1.73860091e-01,   2.00349490e-01,   7.40028700e-01,\n",
       "          6.26331179e-01],\n",
       "       [  4.20309330e-01,   2.99253230e-01,   9.24344671e-02,\n",
       "          6.27843235e-01,   4.41398439e-01,   8.00189474e-01,\n",
       "          1.24548297e-01,   2.92764881e-01,   1.13645437e-01,\n",
       "          5.88709753e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.random.rand(n_samples,\n",
    "                         n_variables)\n",
    "x_train.shape\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training target vectors \n",
    "\n",
    "Create `y_train_float` as matrix product of `x_train` and `x_gen`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.52740876],\n",
       "       [ 10.10383118],\n",
       "       [  7.37513906],\n",
       "       [ 11.38354009],\n",
       "       [  7.5468291 ],\n",
       "       [  9.55824087],\n",
       "       [  7.51858131],\n",
       "       [  9.43025098],\n",
       "       [ 10.73704226],\n",
       "       [ 13.99248053],\n",
       "       [ 10.80420952],\n",
       "       [ 14.16651082],\n",
       "       [  9.72974315],\n",
       "       [ 12.3048658 ],\n",
       "       [ 12.11748741],\n",
       "       [  7.78209183],\n",
       "       [ 13.30211454],\n",
       "       [ 10.39337646],\n",
       "       [  8.05187442],\n",
       "       [ 11.67168225],\n",
       "       [ 11.01384267],\n",
       "       [ 11.3612029 ],\n",
       "       [ 13.53147933],\n",
       "       [  8.70455221],\n",
       "       [  8.7841188 ],\n",
       "       [  7.31821015],\n",
       "       [ 12.35713957],\n",
       "       [ 12.80886401],\n",
       "       [ 11.42694983],\n",
       "       [  8.48200612],\n",
       "       [ 11.76177412],\n",
       "       [ 11.17017322],\n",
       "       [ 12.22945528],\n",
       "       [  8.72621832],\n",
       "       [ 11.2349356 ],\n",
       "       [  9.30376204],\n",
       "       [ 13.73257652],\n",
       "       [ 12.72093946],\n",
       "       [ 11.36990296],\n",
       "       [ 13.57816476],\n",
       "       [  9.47145573],\n",
       "       [  9.18438902],\n",
       "       [ 10.07723706],\n",
       "       [  7.00701819],\n",
       "       [  7.99353633],\n",
       "       [  9.93967426],\n",
       "       [  9.62980147],\n",
       "       [ 10.70482199],\n",
       "       [ 12.48399409],\n",
       "       [ 11.13785145],\n",
       "       [  6.92276502],\n",
       "       [  7.5384704 ],\n",
       "       [ 14.41782077],\n",
       "       [  9.97250366],\n",
       "       [  7.59250507],\n",
       "       [ 12.37510946],\n",
       "       [  8.45592149],\n",
       "       [ 14.22302349],\n",
       "       [  6.66129784],\n",
       "       [ 11.273155  ],\n",
       "       [ 11.14036303],\n",
       "       [ 11.40342026],\n",
       "       [  9.27475269],\n",
       "       [  8.32492602],\n",
       "       [ 10.9146538 ],\n",
       "       [  9.27804613],\n",
       "       [ 13.35030305],\n",
       "       [ 11.98594797],\n",
       "       [ 10.29615234],\n",
       "       [  7.06855886],\n",
       "       [ 11.89658926],\n",
       "       [  9.25615513],\n",
       "       [  9.74596854],\n",
       "       [ 10.55060726],\n",
       "       [ 12.90054495],\n",
       "       [ 12.98495876],\n",
       "       [ 14.57817804],\n",
       "       [  9.69545222],\n",
       "       [ 13.78707227],\n",
       "       [  9.72133525],\n",
       "       [  9.23915904],\n",
       "       [ 10.64842649],\n",
       "       [ 12.22682992],\n",
       "       [  5.50970417],\n",
       "       [  8.37278959],\n",
       "       [ 10.47725789],\n",
       "       [ 11.00303346],\n",
       "       [  8.67227909],\n",
       "       [ 14.07030735],\n",
       "       [ 12.72910572],\n",
       "       [ 12.3395434 ],\n",
       "       [  9.53241631],\n",
       "       [ 12.44137223],\n",
       "       [ 13.64155129],\n",
       "       [ 11.12390231],\n",
       "       [  7.55319313],\n",
       "       [ 15.72182908],\n",
       "       [ 10.44909067],\n",
       "       [ 11.10817603],\n",
       "       [  8.59252672]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_float = x_train.dot(x_gen).reshape(n_samples,1) \n",
    "y_train_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `y_train_int` by rounding entries of `y_train_float` to the nearest integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [11],\n",
       "       [14],\n",
       "       [11],\n",
       "       [14],\n",
       "       [10],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [11],\n",
       "       [11],\n",
       "       [14],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [12],\n",
       "       [13],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 9],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [14],\n",
       "       [13],\n",
       "       [11],\n",
       "       [14],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [10],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [14],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [14],\n",
       "       [ 7],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [13],\n",
       "       [12],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [12],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [13],\n",
       "       [13],\n",
       "       [15],\n",
       "       [10],\n",
       "       [14],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 6],\n",
       "       [ 8],\n",
       "       [10],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [14],\n",
       "       [13],\n",
       "       [12],\n",
       "       [10],\n",
       "       [12],\n",
       "       [14],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [16],\n",
       "       [10],\n",
       "       [11],\n",
       "       [ 9]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_int = np.round(y_train_float).astype(np.int32)\n",
    "y_train_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `y_train_cat` from `y_train_int` using `to_categorical` by creating binary variables for each (integer) value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = np_utils.to_categorical(y_train_int.reshape(n_samples,\n",
    "                                                          1))\n",
    "y_train_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first column of `y_train_cat` contains only zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_cat[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the correspondence between the unique values in `y_train_int` and the unique rows is `y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique integer values: [ 6  7  8  9 10 11 12 13 14 15 16]\n",
      "unique rows below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "76  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "83  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "96  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     15   16  \n",
       "0   0.0  0.0  \n",
       "2   0.0  0.0  \n",
       "3   0.0  0.0  \n",
       "4   0.0  0.0  \n",
       "7   0.0  0.0  \n",
       "9   0.0  0.0  \n",
       "13  0.0  0.0  \n",
       "16  0.0  0.0  \n",
       "76  1.0  0.0  \n",
       "83  0.0  0.0  \n",
       "96  0.0  1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"unique integer values:\",np.unique(y_train_int))\n",
    "print(\"unique rows below\")\n",
    "pd.DataFrame(y_train_cat).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "middle_layer_count = 64\n",
    "\n",
    "model.add(Dense(input_dim  = n_variables, \n",
    "                output_dim = middle_layer_count, \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(input_dim  = middle_layer_count, \n",
    "                output_dim = y_train_cat.shape[1], \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the loss function and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model \n",
    "\n",
    "Use the data in `x_train` and `y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11cf57ba8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train_cat, \n",
    "          nb_epoch      = n_epoch, \n",
    "          batch_size    = n_samples, \n",
    "          verbose       = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5974449491500855"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train,\n",
    "               y_train_cat, \n",
    "               verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted values for the 3rd sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target value: [7]\n",
      "prediction  : [7]\n"
     ]
    }
   ],
   "source": [
    "arow = 34\n",
    "print(\"target value:\",y_train_int[arow])\n",
    "print(\"prediction  :\",model.predict_classes(np.array([x_train[arow]]), \n",
    "                                            verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted values for the first `10` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predicted\n",
       "0       7          7\n",
       "1       8          8\n",
       "2       6          6\n",
       "3       9         10\n",
       "4       8          8\n",
       "5       9          9\n",
       "6       8          8\n",
       "7       8          8\n",
       "8      11          9\n",
       "9      11         11"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"actual\"   : y_train_int.reshape(n_samples),\n",
    "              \"predicted\": model.predict_classes(x_train,\n",
    "                                                 verbose=False)}\n",
    "            )[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display frequency counts\n",
    "\n",
    "Display frequence counts for the absolute difference between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency counts: [68 30  2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_train, \n",
    "                               verbose=False\n",
    "                              ).reshape(n_samples,)\n",
    "\n",
    "y_init = y_train_int.reshape(n_samples,)\n",
    "\n",
    "y_freq = np.bincount(abs(y_pred - y_init))\n",
    "\n",
    "print(\"Frequency counts:\", y_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.0 percent\n"
     ]
    }
   ],
   "source": [
    "print  (\"Accuracy: %.1f percent\" % \n",
    "        np.round(100*y_freq[0] / sum(y_freq), \n",
    "                 decimals=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create regression model\n",
    "\n",
    "The training data consists of:\n",
    "- `x_train` (same as above)\n",
    "- `y_train_float` calculated directly from `x_train` and `x_gen` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "middle_layer_count = 64\n",
    "\n",
    "model.add(Dense(input_dim  = n_variables, \n",
    "                output_dim = middle_layer_count, \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(input_dim  = middle_layer_count, \n",
    "                output_dim = y_train_float.shape[1])) \n",
    "\n",
    "model.compile(loss      = 'mean_absolute_error', \n",
    "              optimizer = 'rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12793f7f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train_float, \n",
    "          nb_epoch=n_epoch, \n",
    "          batch_size=n_samples, \n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the actual and predicted values side by side\n",
    "\n",
    "Include the square error for each row and the mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error: 0.01089013223843814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>sq_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.284502</td>\n",
       "      <td>7.340265</td>\n",
       "      <td>0.003110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.696034</td>\n",
       "      <td>7.733113</td>\n",
       "      <td>0.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.858850</td>\n",
       "      <td>5.907280</td>\n",
       "      <td>0.002345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.930823</td>\n",
       "      <td>9.081603</td>\n",
       "      <td>0.022735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.419558</td>\n",
       "      <td>8.573089</td>\n",
       "      <td>0.023572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.984392</td>\n",
       "      <td>9.072179</td>\n",
       "      <td>0.007707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.860556</td>\n",
       "      <td>7.941057</td>\n",
       "      <td>0.006480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.786004</td>\n",
       "      <td>7.898627</td>\n",
       "      <td>0.012684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.063776</td>\n",
       "      <td>11.087074</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.384567</td>\n",
       "      <td>11.388608</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  predicted    sq_err\n",
       "0   7.284502   7.340265  0.003110\n",
       "1   7.696034   7.733113  0.001375\n",
       "2   5.858850   5.907280  0.002345\n",
       "3   8.930823   9.081603  0.022735\n",
       "4   8.419558   8.573089  0.023572\n",
       "5   8.984392   9.072179  0.007707\n",
       "6   7.860556   7.941057  0.006480\n",
       "7   7.786004   7.898627  0.012684\n",
       "8  11.063776  11.087074  0.000543\n",
       "9  11.384567  11.388608  0.000016"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_err = pd.DataFrame({\n",
    "        \"actual\"   : y_train_float         .reshape(n_samples),\n",
    "        \"predicted\": model.predict(x_train).reshape(n_samples),\n",
    "        \"sq_err\"   : 0\n",
    "    })\n",
    "pred_err['sq_err'] = (pred_err['actual'] - pred_err['predicted'])**2\n",
    "print('Mean square error:', np.mean(pred_err['sq_err']))\n",
    "pred_err[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
