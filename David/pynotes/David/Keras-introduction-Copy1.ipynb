{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - classification and regression\n",
    "\n",
    "Contents:\n",
    "1. Load required libraries\n",
    "1. Set initial parameters\n",
    "1. Create synthetic training datasets\n",
    "1. Create classification model\n",
    "1. Train the model and display accuracy\n",
    "1. Create regression model \n",
    "1. Train the model and display mean square error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas    as pd\n",
    "import numpy     as np\n",
    "import itertools as it\n",
    "\n",
    "from keras.utils       import np_utils \n",
    "from keras.models      import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic training datasets\n",
    "\n",
    "- Set initial parameters\n",
    "- Create a random `x_train` dataset with shape determined by parameters and with random values between `0` and `1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_variables =    10\n",
    "n_samples   =   100\n",
    "n_epoch     = 1000 # number of training iterations\n",
    "min_gen     =     1\n",
    "max_gen     =     4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector `x_gen` \n",
    "\n",
    "The target values of the training datase are created using `x_gen` and `x_train`, which is a matrix of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 3, 1, 3, 3, 2, 2, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gen    = np.random.randint(min_gen, \n",
    "                             max_gen, \n",
    "                             n_variables)\n",
    "x_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `x_train` as a random `n_samples` by `n_variables` matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.94891662e-01,   5.25680413e-01,   9.62383760e-01,\n",
       "          1.16891216e-01,   7.06236827e-01,   4.59722805e-01,\n",
       "          9.65906793e-01,   8.09460008e-01,   4.40249419e-01,\n",
       "          9.66237213e-01],\n",
       "       [  8.08310169e-01,   6.74090611e-02,   1.39509411e-01,\n",
       "          9.40890957e-01,   5.56976022e-01,   2.67645729e-01,\n",
       "          3.00196651e-01,   3.46497558e-01,   6.40575670e-01,\n",
       "          8.60456696e-01],\n",
       "       [  4.90604829e-01,   9.01335301e-02,   4.33618147e-01,\n",
       "          2.77028152e-02,   8.91216353e-02,   4.12616603e-01,\n",
       "          5.02741203e-01,   8.77438927e-02,   3.37528099e-01,\n",
       "          7.95626259e-01],\n",
       "       [  3.64098726e-01,   4.12637065e-01,   1.87368557e-01,\n",
       "          4.74045631e-01,   8.84753196e-01,   5.06400035e-01,\n",
       "          2.24539307e-01,   3.93005903e-01,   9.55736530e-03,\n",
       "          4.65035230e-01],\n",
       "       [  6.92346000e-01,   7.15851420e-01,   6.61932787e-01,\n",
       "          3.52890682e-01,   6.13384588e-01,   7.17335480e-01,\n",
       "          4.28201878e-01,   7.06219617e-02,   3.20021850e-01,\n",
       "          3.38952525e-01],\n",
       "       [  2.44223340e-01,   4.10300154e-01,   5.99360591e-02,\n",
       "          9.35298286e-01,   5.64550223e-02,   5.63798164e-02,\n",
       "          3.12896361e-01,   5.40517956e-01,   2.87964434e-01,\n",
       "          2.59251747e-01],\n",
       "       [  4.35405928e-01,   2.26690427e-01,   8.33071930e-01,\n",
       "          5.39591300e-02,   7.68748915e-01,   4.04669678e-01,\n",
       "          4.10049588e-01,   4.65471741e-01,   8.35267390e-01,\n",
       "          4.34286437e-01],\n",
       "       [  4.35743057e-01,   1.16412347e-01,   7.07672839e-01,\n",
       "          7.98627913e-01,   7.84900167e-01,   7.86380149e-01,\n",
       "          8.17734031e-01,   7.61592683e-01,   4.84264045e-01,\n",
       "          2.05480436e-02],\n",
       "       [  5.96084598e-01,   7.92503648e-01,   1.31447893e-01,\n",
       "          1.82499166e-01,   9.21436703e-01,   9.72976088e-01,\n",
       "          6.82027023e-02,   2.35234605e-01,   3.08493143e-01,\n",
       "          5.68744949e-01],\n",
       "       [  3.63409727e-01,   9.62211439e-01,   9.88578614e-01,\n",
       "          7.89432408e-01,   4.26147974e-01,   2.31503416e-01,\n",
       "          4.18330904e-01,   9.67166309e-01,   5.46382990e-01,\n",
       "          6.57536371e-01],\n",
       "       [  9.81298307e-01,   5.67574126e-01,   2.48353036e-01,\n",
       "          7.64143916e-01,   1.26754962e-02,   5.25476870e-01,\n",
       "          5.87501887e-01,   8.36974134e-01,   8.23847294e-01,\n",
       "          9.62241759e-01],\n",
       "       [  8.70582836e-01,   2.40903195e-01,   2.28145696e-01,\n",
       "          3.62659463e-01,   9.97229044e-01,   7.34538545e-01,\n",
       "          5.89246977e-01,   3.91828200e-01,   5.13296132e-01,\n",
       "          5.55594254e-01],\n",
       "       [  8.85417408e-01,   7.71181591e-01,   6.26680437e-02,\n",
       "          8.78777162e-01,   9.92230142e-01,   9.21074403e-01,\n",
       "          4.02111121e-01,   1.85256525e-02,   6.14744379e-02,\n",
       "          5.16470629e-01],\n",
       "       [  4.96798093e-01,   6.50226904e-02,   1.41169092e-01,\n",
       "          4.91561738e-01,   7.83213567e-01,   2.18662944e-02,\n",
       "          7.23024700e-01,   2.12753131e-01,   2.56920906e-01,\n",
       "          2.64995479e-01],\n",
       "       [  3.27715239e-02,   6.14737179e-01,   7.44647007e-01,\n",
       "          3.09456810e-01,   5.29015352e-01,   9.12085964e-01,\n",
       "          8.02748801e-01,   3.60301280e-01,   9.78290615e-01,\n",
       "          8.19552449e-01],\n",
       "       [  3.44012796e-01,   9.00594714e-02,   4.97715308e-01,\n",
       "          3.91260027e-01,   1.57477336e-01,   8.68985996e-01,\n",
       "          9.20869289e-01,   4.84280131e-01,   8.19162507e-01,\n",
       "          7.54698059e-01],\n",
       "       [  3.89905062e-01,   8.10719372e-01,   9.82734705e-02,\n",
       "          3.78039779e-01,   2.62609858e-01,   6.03398909e-01,\n",
       "          7.48887348e-01,   2.88223494e-01,   9.11278441e-01,\n",
       "          7.16372491e-01],\n",
       "       [  7.95653982e-01,   2.20998369e-01,   9.24797113e-01,\n",
       "          5.44976635e-01,   7.01071062e-01,   7.61790874e-01,\n",
       "          7.28240647e-01,   8.28226629e-01,   1.11978037e-02,\n",
       "          9.88415057e-01],\n",
       "       [  5.90558346e-01,   2.84032683e-02,   1.27131419e-01,\n",
       "          1.73010919e-01,   8.23106036e-01,   8.65444961e-02,\n",
       "          9.06426401e-01,   1.46345741e-01,   4.61251093e-01,\n",
       "          6.26835626e-01],\n",
       "       [  4.71570103e-01,   9.26527545e-01,   2.29380314e-01,\n",
       "          9.23071866e-01,   3.14056446e-01,   1.40753694e-02,\n",
       "          1.44244967e-01,   2.44116265e-01,   6.74586051e-01,\n",
       "          6.85461511e-01],\n",
       "       [  8.84039998e-01,   3.24196407e-01,   6.06431912e-01,\n",
       "          1.72257419e-02,   8.60509179e-01,   3.63019283e-01,\n",
       "          3.01511757e-01,   4.10410584e-02,   6.57018217e-01,\n",
       "          5.46060533e-03],\n",
       "       [  5.30870871e-01,   3.91684472e-01,   8.24859349e-01,\n",
       "          7.71817540e-01,   8.76200590e-01,   2.37204488e-01,\n",
       "          3.96693494e-01,   7.68002049e-01,   8.25766108e-01,\n",
       "          1.01866561e-01],\n",
       "       [  7.30701335e-01,   7.45179955e-01,   8.07275403e-02,\n",
       "          2.27232933e-01,   5.28498267e-01,   5.40464636e-02,\n",
       "          9.87537708e-01,   4.92598484e-02,   6.56495606e-02,\n",
       "          3.70114181e-01],\n",
       "       [  8.28771451e-01,   9.23264817e-01,   5.71314323e-01,\n",
       "          3.15840434e-01,   2.66036017e-01,   1.65670624e-01,\n",
       "          3.93809358e-01,   1.45917839e-01,   5.98375780e-01,\n",
       "          2.60018612e-01],\n",
       "       [  4.74673251e-01,   7.57188200e-01,   3.27082696e-01,\n",
       "          4.32851766e-02,   4.43353511e-01,   7.13933501e-01,\n",
       "          7.47903867e-01,   7.18007072e-01,   3.95611694e-01,\n",
       "          5.77439539e-01],\n",
       "       [  4.77005292e-01,   6.58126987e-01,   8.25597250e-01,\n",
       "          1.90721550e-01,   6.60082751e-01,   8.41375735e-01,\n",
       "          5.01779588e-02,   3.34077468e-01,   6.25547547e-01,\n",
       "          9.86396626e-01],\n",
       "       [  7.09146584e-01,   7.77022531e-01,   8.42104688e-01,\n",
       "          7.94832638e-02,   5.40221645e-01,   3.20610593e-01,\n",
       "          2.45705955e-01,   1.81996683e-01,   1.63035471e-01,\n",
       "          1.92542646e-01],\n",
       "       [  1.26479537e-01,   8.42288779e-01,   8.59559525e-01,\n",
       "          3.54415224e-02,   9.11762397e-01,   2.66615065e-01,\n",
       "          6.16346558e-01,   7.83668812e-01,   4.00408547e-01,\n",
       "          1.06922986e-01],\n",
       "       [  2.40075573e-01,   8.54134717e-01,   5.26655494e-01,\n",
       "          3.94128878e-01,   9.63231355e-01,   2.46714262e-01,\n",
       "          2.07498360e-01,   4.90633229e-01,   7.41766982e-01,\n",
       "          4.44489173e-01],\n",
       "       [  6.43889187e-01,   6.67113397e-01,   8.22008581e-01,\n",
       "          5.30419592e-01,   9.56331074e-01,   6.81522069e-01,\n",
       "          9.50347586e-01,   4.15901407e-01,   7.34917329e-01,\n",
       "          3.18045033e-01],\n",
       "       [  7.72059755e-01,   9.94170262e-01,   3.46989012e-01,\n",
       "          5.45761368e-01,   8.57693056e-01,   5.20610370e-01,\n",
       "          9.73257442e-01,   5.45502347e-01,   8.47130954e-01,\n",
       "          6.26871177e-01],\n",
       "       [  6.04595071e-01,   7.19155929e-01,   3.88707937e-01,\n",
       "          8.69632709e-01,   5.35585411e-01,   5.65055730e-02,\n",
       "          3.79578690e-01,   7.21746826e-01,   6.49720190e-01,\n",
       "          2.57925059e-01],\n",
       "       [  7.16487178e-01,   6.34689765e-01,   8.44811996e-01,\n",
       "          6.29687230e-01,   2.97236993e-01,   2.48569031e-01,\n",
       "          8.50538977e-01,   8.73579594e-01,   1.15653371e-01,\n",
       "          5.91451777e-01],\n",
       "       [  7.13874778e-01,   2.39901914e-01,   1.71247890e-01,\n",
       "          7.70914004e-01,   8.67083771e-01,   1.11061864e-01,\n",
       "          9.97883002e-01,   8.40670245e-01,   1.93905408e-01,\n",
       "          8.04863295e-01],\n",
       "       [  9.35057811e-02,   7.76687683e-01,   1.40863109e-01,\n",
       "          4.81892000e-01,   5.43611698e-01,   9.50733956e-01,\n",
       "          1.72114984e-01,   9.19374402e-01,   1.16306347e-01,\n",
       "          1.59593299e-01],\n",
       "       [  5.39737955e-02,   5.48610631e-01,   9.53520727e-01,\n",
       "          9.20284810e-01,   8.13582081e-01,   3.22066019e-01,\n",
       "          8.80663039e-01,   4.33231001e-01,   1.13047287e-01,\n",
       "          4.07354585e-01],\n",
       "       [  5.38489867e-01,   5.66074746e-02,   6.14330644e-01,\n",
       "          2.83091623e-02,   9.63222497e-01,   1.63125399e-01,\n",
       "          3.81761215e-01,   7.62686327e-02,   2.28070732e-01,\n",
       "          4.71441318e-01],\n",
       "       [  4.61700077e-02,   5.27326267e-01,   2.10327358e-01,\n",
       "          4.80871721e-01,   4.97451706e-01,   9.21851811e-01,\n",
       "          8.63757705e-01,   3.15280613e-02,   5.89649652e-01,\n",
       "          4.76697713e-01],\n",
       "       [  5.04834545e-01,   9.89755860e-01,   3.53151507e-01,\n",
       "          8.72435111e-01,   3.67607722e-01,   1.14277105e-01,\n",
       "          6.18947681e-01,   1.24050588e-01,   7.97062086e-01,\n",
       "          6.24628675e-01],\n",
       "       [  2.89982981e-01,   8.09239455e-01,   7.08613163e-01,\n",
       "          5.49597568e-01,   5.98968620e-03,   8.73025727e-01,\n",
       "          2.51300266e-01,   4.26282722e-01,   4.85345454e-01,\n",
       "          2.46146370e-03],\n",
       "       [  5.99834835e-01,   3.33122213e-01,   5.58159762e-01,\n",
       "          4.91601296e-01,   4.66103446e-01,   7.42452415e-01,\n",
       "          9.79801296e-01,   7.03774859e-01,   2.58615593e-01,\n",
       "          8.24324721e-01],\n",
       "       [  3.18112457e-01,   9.19108346e-01,   9.10802493e-01,\n",
       "          8.42117835e-01,   6.22860438e-01,   6.29488507e-01,\n",
       "          7.39671639e-01,   3.66258111e-01,   4.77113954e-01,\n",
       "          1.77732845e-01],\n",
       "       [  6.63551485e-01,   8.97630364e-01,   3.54888785e-01,\n",
       "          4.58892173e-01,   7.59492119e-01,   8.98317421e-01,\n",
       "          1.10362432e-01,   7.87068125e-02,   6.01560283e-01,\n",
       "          4.94009033e-01],\n",
       "       [  3.09508640e-01,   6.52965532e-01,   2.24591243e-01,\n",
       "          4.95014978e-01,   3.75340242e-01,   2.29128090e-01,\n",
       "          4.43697064e-01,   4.25300294e-02,   3.52498704e-01,\n",
       "          9.25021321e-01],\n",
       "       [  1.67314280e-01,   3.07684683e-01,   7.35290501e-01,\n",
       "          8.87929244e-01,   2.86446670e-01,   8.63555204e-03,\n",
       "          5.32992267e-01,   2.99136182e-01,   7.48308226e-01,\n",
       "          4.45190884e-01],\n",
       "       [  7.75140343e-01,   2.82268621e-02,   5.93414840e-01,\n",
       "          4.35239772e-01,   3.95785476e-01,   3.54329140e-01,\n",
       "          5.34554462e-01,   4.81284478e-01,   6.98487419e-01,\n",
       "          7.60804185e-02],\n",
       "       [  5.07063956e-01,   9.84869219e-01,   1.00896160e-01,\n",
       "          8.56882953e-01,   7.71013145e-01,   2.37424454e-01,\n",
       "          6.43795496e-01,   4.42991783e-01,   8.79288763e-02,\n",
       "          9.26524787e-01],\n",
       "       [  1.91275195e-01,   4.72825387e-01,   3.95921004e-01,\n",
       "          2.02721862e-01,   8.03281167e-01,   6.82991190e-01,\n",
       "          9.66106563e-01,   9.44169897e-01,   4.10306942e-01,\n",
       "          2.48226638e-01],\n",
       "       [  9.14019263e-01,   4.10525438e-01,   2.94565336e-01,\n",
       "          7.87429277e-01,   9.93536549e-01,   2.84012803e-01,\n",
       "          2.14283855e-01,   8.50208328e-01,   7.74672641e-01,\n",
       "          9.57308154e-02],\n",
       "       [  8.27552539e-01,   4.83904504e-01,   7.88497379e-01,\n",
       "          2.26883330e-01,   1.28078606e-01,   3.39581878e-01,\n",
       "          1.76617171e-01,   2.77745725e-01,   6.26865609e-01,\n",
       "          3.22813373e-01],\n",
       "       [  4.56229210e-01,   4.36111649e-01,   1.14530140e-01,\n",
       "          6.82063456e-01,   7.22075670e-01,   8.88673433e-01,\n",
       "          9.92392255e-01,   7.05927857e-02,   7.24021277e-01,\n",
       "          4.03884337e-01],\n",
       "       [  4.94756112e-01,   6.07880791e-01,   1.50180380e-01,\n",
       "          3.77424377e-01,   8.47417364e-01,   4.15138278e-01,\n",
       "          5.53147652e-01,   3.04491932e-01,   3.37856123e-01,\n",
       "          3.02935305e-01],\n",
       "       [  1.97359849e-01,   4.82146181e-01,   2.62474510e-01,\n",
       "          4.05254104e-01,   7.04427913e-01,   8.36749270e-01,\n",
       "          3.17796641e-02,   7.65718821e-01,   2.24603974e-01,\n",
       "          9.04137932e-01],\n",
       "       [  6.70279838e-01,   5.88211138e-01,   9.79852485e-01,\n",
       "          2.60508167e-01,   4.69296124e-01,   4.70998488e-01,\n",
       "          4.75878046e-01,   8.97484682e-01,   8.41024664e-02,\n",
       "          9.85583803e-01],\n",
       "       [  8.75829731e-01,   7.64300123e-01,   1.74172788e-01,\n",
       "          2.27617510e-01,   1.11469102e-01,   8.83952917e-01,\n",
       "          8.40466237e-01,   1.64646782e-01,   5.01756447e-01,\n",
       "          9.74526731e-01],\n",
       "       [  2.87070454e-01,   2.42043824e-01,   2.32347530e-01,\n",
       "          5.37693229e-01,   4.72174493e-02,   5.29214519e-01,\n",
       "          7.84894605e-01,   7.66128467e-01,   2.49118271e-01,\n",
       "          4.32203685e-01],\n",
       "       [  6.41224211e-01,   6.99549673e-01,   5.62159569e-01,\n",
       "          4.46019850e-01,   9.72216507e-02,   9.29238451e-01,\n",
       "          1.53059719e-01,   6.69620598e-02,   3.58394579e-01,\n",
       "          3.33532322e-01],\n",
       "       [  7.35208077e-01,   3.51505849e-01,   6.25564669e-02,\n",
       "          7.86522785e-01,   3.38739528e-01,   3.96023339e-01,\n",
       "          5.08733276e-01,   1.58862302e-01,   8.41327740e-01,\n",
       "          5.29151060e-01],\n",
       "       [  7.33390278e-01,   4.69611208e-01,   9.83399511e-01,\n",
       "          1.99870798e-01,   3.59723251e-01,   4.31524528e-01,\n",
       "          9.23025043e-01,   3.46985804e-01,   4.69927865e-01,\n",
       "          3.28007998e-02],\n",
       "       [  7.19302743e-01,   8.32134122e-01,   2.70987462e-01,\n",
       "          1.37377800e-01,   3.83629236e-02,   9.69158621e-01,\n",
       "          5.81340080e-01,   5.21358012e-01,   8.22187931e-01,\n",
       "          5.27991884e-02],\n",
       "       [  8.11315943e-01,   6.98152186e-01,   6.48168334e-01,\n",
       "          5.07250868e-01,   3.92923810e-02,   4.14558447e-01,\n",
       "          5.64571409e-01,   7.09418607e-01,   5.64617012e-01,\n",
       "          9.56012979e-01],\n",
       "       [  1.82704531e-01,   8.73536205e-01,   2.37164251e-01,\n",
       "          5.84283431e-01,   8.89104382e-01,   4.97093430e-01,\n",
       "          3.97692136e-01,   7.07402983e-01,   7.41161754e-01,\n",
       "          6.88022511e-01],\n",
       "       [  1.93324950e-01,   4.19409983e-01,   5.13927993e-02,\n",
       "          9.07992991e-01,   9.17134024e-01,   6.16314459e-01,\n",
       "          7.04129121e-01,   3.18367376e-01,   3.65843629e-01,\n",
       "          1.86733656e-02],\n",
       "       [  1.69432367e-01,   7.67238020e-01,   6.22352807e-02,\n",
       "          3.25697515e-01,   9.08076706e-01,   4.88259607e-01,\n",
       "          6.35532107e-01,   6.37306962e-01,   2.67369662e-01,\n",
       "          3.57087241e-01],\n",
       "       [  5.29014043e-02,   5.81347700e-01,   1.34001054e-01,\n",
       "          9.55371998e-01,   5.63306314e-01,   1.49926827e-01,\n",
       "          7.75119778e-01,   9.09011127e-01,   6.63227907e-01,\n",
       "          1.42315042e-01],\n",
       "       [  7.22172862e-01,   7.29366628e-01,   5.39141323e-02,\n",
       "          6.42355134e-01,   7.71827233e-01,   7.38793520e-01,\n",
       "          1.98557816e-01,   7.47310650e-01,   9.98813346e-01,\n",
       "          3.45277187e-01],\n",
       "       [  2.88582131e-01,   8.68758472e-01,   7.21133287e-01,\n",
       "          5.39545772e-01,   1.81575620e-01,   5.39077706e-01,\n",
       "          9.24372501e-01,   6.89453594e-01,   4.19294630e-01,\n",
       "          2.52871771e-01],\n",
       "       [  9.37359991e-01,   3.41516635e-01,   8.51802641e-01,\n",
       "          9.03134641e-02,   7.86342779e-01,   8.56260097e-01,\n",
       "          8.95604579e-01,   5.29375327e-01,   8.69649950e-01,\n",
       "          1.58565974e-01],\n",
       "       [  9.89859079e-01,   7.59175006e-01,   8.53972240e-01,\n",
       "          7.49052122e-01,   4.89440428e-01,   7.19822291e-01,\n",
       "          5.08212447e-01,   4.94035731e-01,   6.38712912e-01,\n",
       "          3.10250021e-01],\n",
       "       [  9.70903739e-01,   9.42937179e-01,   8.15470904e-01,\n",
       "          3.25024005e-01,   7.93800918e-01,   5.56334308e-01,\n",
       "          7.54884607e-01,   2.21782589e-01,   3.98912194e-01,\n",
       "          8.57039902e-01],\n",
       "       [  6.58135627e-01,   6.40802515e-02,   1.68393370e-01,\n",
       "          9.73152514e-01,   7.06396826e-01,   9.04307408e-01,\n",
       "          2.39388752e-02,   5.43158826e-01,   6.51175001e-01,\n",
       "          1.46939218e-01],\n",
       "       [  7.26816206e-02,   3.32032311e-01,   5.70812202e-01,\n",
       "          2.72835580e-01,   6.49930403e-01,   6.52507469e-01,\n",
       "          9.92252252e-01,   7.77710366e-02,   2.87072135e-01,\n",
       "          9.38767609e-01],\n",
       "       [  4.11819956e-01,   7.82917989e-02,   8.08691625e-01,\n",
       "          3.93051194e-01,   5.24299684e-01,   4.06576904e-01,\n",
       "          8.37365174e-02,   6.96818202e-01,   2.30624540e-01,\n",
       "          6.53824439e-01],\n",
       "       [  6.10786459e-01,   9.10104318e-01,   4.54811018e-02,\n",
       "          8.71327316e-01,   9.93027082e-01,   6.18687963e-01,\n",
       "          3.92650040e-01,   3.93169743e-01,   6.72034831e-01,\n",
       "          1.96771345e-01],\n",
       "       [  3.12721508e-01,   2.79008893e-01,   9.92712780e-01,\n",
       "          1.63750142e-01,   9.98318814e-01,   5.97709697e-01,\n",
       "          6.09144921e-01,   9.54044083e-01,   1.48152690e-01,\n",
       "          3.46171824e-01],\n",
       "       [  4.65232341e-01,   7.89716318e-01,   5.60107846e-01,\n",
       "          5.14794914e-01,   5.36616999e-01,   2.96421460e-01,\n",
       "          9.61501137e-01,   5.41493460e-02,   7.82380368e-01,\n",
       "          3.10648486e-01],\n",
       "       [  1.52576510e-01,   2.59253548e-01,   1.67392528e-01,\n",
       "          2.95221133e-01,   5.97429009e-01,   5.55711499e-01,\n",
       "          6.10864501e-01,   3.39182489e-01,   9.88803637e-01,\n",
       "          4.58406315e-02],\n",
       "       [  8.19204535e-01,   6.59631221e-01,   1.70266423e-01,\n",
       "          1.91546320e-01,   9.85457901e-01,   2.66684851e-01,\n",
       "          5.99627451e-01,   3.87621726e-01,   8.28736111e-01,\n",
       "          7.15153307e-01],\n",
       "       [  3.28773717e-01,   6.41253150e-01,   1.30800191e-01,\n",
       "          9.69934810e-02,   2.25541688e-04,   8.43114721e-01,\n",
       "          3.97993091e-01,   8.70409006e-01,   4.42681085e-01,\n",
       "          4.71531816e-01],\n",
       "       [  7.66123502e-01,   2.89932097e-01,   9.56074844e-01,\n",
       "          1.83472509e-01,   4.04272628e-01,   7.47072909e-01,\n",
       "          7.02706064e-01,   6.19680152e-01,   1.90607766e-01,\n",
       "          1.51318299e-01],\n",
       "       [  4.45523448e-01,   8.22051543e-01,   4.51052287e-01,\n",
       "          4.06238848e-01,   8.73601555e-01,   2.06796558e-01,\n",
       "          1.76659092e-01,   6.95448571e-01,   8.38617563e-01,\n",
       "          2.11628119e-01],\n",
       "       [  3.09323546e-01,   4.78545969e-01,   2.31086617e-01,\n",
       "          2.70181473e-01,   2.99818388e-01,   1.79123844e-01,\n",
       "          1.94949280e-01,   2.83786863e-01,   9.26147162e-01,\n",
       "          3.15347182e-02],\n",
       "       [  4.15599367e-01,   3.37303501e-01,   6.52115624e-01,\n",
       "          5.26937543e-02,   2.21732160e-01,   7.05420660e-01,\n",
       "          6.16312075e-01,   2.26861362e-01,   1.81846763e-01,\n",
       "          4.34839169e-01],\n",
       "       [  3.86493286e-01,   3.35637399e-01,   5.45548239e-01,\n",
       "          8.74500713e-01,   6.39249967e-01,   7.15993039e-01,\n",
       "          9.43144406e-01,   2.77393678e-01,   7.57476918e-01,\n",
       "          9.33168152e-01],\n",
       "       [  9.13222773e-01,   6.72577555e-01,   5.47508921e-01,\n",
       "          1.15443247e-01,   8.11944329e-01,   7.42088300e-01,\n",
       "          3.76787623e-01,   3.39171752e-02,   2.65745006e-02,\n",
       "          7.95768273e-01],\n",
       "       [  9.69973487e-01,   7.55627463e-01,   5.34818884e-01,\n",
       "          1.57015368e-01,   4.94343517e-01,   7.95535905e-01,\n",
       "          6.88887874e-02,   5.02462802e-01,   8.22142311e-01,\n",
       "          8.77616357e-01],\n",
       "       [  5.05225383e-01,   9.13573843e-01,   3.61147896e-01,\n",
       "          5.69934486e-01,   9.32538515e-01,   2.92585715e-01,\n",
       "          7.94519154e-01,   4.96462551e-02,   5.85865137e-02,\n",
       "          7.60711518e-01],\n",
       "       [  8.81009977e-01,   4.10938611e-01,   7.52380567e-02,\n",
       "          6.25815169e-01,   3.73586434e-01,   7.08421678e-01,\n",
       "          4.96721141e-01,   1.46559700e-01,   2.53165744e-01,\n",
       "          3.91850892e-01],\n",
       "       [  7.18081492e-01,   3.60293382e-01,   5.93465003e-01,\n",
       "          5.16330155e-01,   3.27602978e-01,   1.22322714e-01,\n",
       "          3.58116895e-01,   3.34319730e-01,   2.69904129e-01,\n",
       "          1.65852913e-02],\n",
       "       [  1.75439505e-01,   4.50973918e-01,   9.65986662e-01,\n",
       "          1.71706502e-01,   4.83839165e-01,   9.19880095e-01,\n",
       "          5.46611596e-01,   5.67754011e-01,   8.46926219e-01,\n",
       "          6.81723977e-02],\n",
       "       [  6.91557528e-02,   1.69406531e-01,   8.81401880e-01,\n",
       "          6.49306650e-01,   7.91482030e-01,   8.54558941e-01,\n",
       "          5.24201196e-01,   7.58005792e-01,   1.23893827e-01,\n",
       "          2.79105834e-01],\n",
       "       [  6.26521864e-01,   3.46474731e-02,   1.88613438e-01,\n",
       "          9.33902710e-02,   4.45774118e-01,   5.51432316e-02,\n",
       "          4.78682251e-01,   9.73002968e-01,   9.79500202e-01,\n",
       "          8.19007673e-02],\n",
       "       [  6.11801512e-01,   6.99061101e-01,   4.50192749e-01,\n",
       "          6.91085559e-01,   5.62617401e-01,   1.59260636e-01,\n",
       "          9.39331266e-02,   6.95833522e-01,   5.66918371e-01,\n",
       "          1.87978318e-01],\n",
       "       [  6.07329841e-02,   5.19368218e-01,   6.47847870e-01,\n",
       "          6.24337053e-01,   5.32052438e-01,   6.75273476e-01,\n",
       "          6.56207044e-01,   6.59255589e-01,   4.97528397e-01,\n",
       "          6.59292584e-01],\n",
       "       [  6.58946182e-01,   2.33523697e-01,   2.26099266e-02,\n",
       "          8.23872144e-01,   5.74977086e-01,   3.03690942e-01,\n",
       "          7.53774920e-02,   2.99963625e-01,   8.42072685e-01,\n",
       "          2.43715460e-01],\n",
       "       [  8.92554048e-02,   8.56545629e-01,   2.58487313e-01,\n",
       "          1.75786502e-01,   2.72285820e-01,   2.53548029e-01,\n",
       "          1.83430490e-01,   7.73961568e-01,   4.18899671e-01,\n",
       "          1.69905852e-01],\n",
       "       [  4.55474513e-01,   7.43761351e-01,   8.33483444e-01,\n",
       "          9.92094939e-01,   3.48530926e-01,   5.47749435e-01,\n",
       "          4.37425145e-01,   7.82672348e-01,   5.75078101e-01,\n",
       "          9.58188771e-01],\n",
       "       [  7.74942579e-01,   4.89188783e-01,   2.84413615e-02,\n",
       "          6.58064239e-01,   9.22439665e-01,   5.67576833e-02,\n",
       "          9.73161808e-01,   1.44920358e-01,   2.62608183e-01,\n",
       "          6.00856334e-01],\n",
       "       [  9.86393916e-01,   1.15653405e-01,   1.46537967e-01,\n",
       "          1.14251347e-01,   3.28630034e-01,   1.21114318e-01,\n",
       "          3.48223186e-01,   3.86539306e-01,   2.54533112e-01,\n",
       "          5.21450831e-01],\n",
       "       [  7.34781490e-01,   3.58449818e-01,   5.79659863e-01,\n",
       "          2.79198631e-01,   5.23200098e-02,   2.73614018e-01,\n",
       "          1.59296864e-01,   7.29370910e-01,   9.35668812e-02,\n",
       "          3.35957563e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.random.rand(n_samples,\n",
    "                         n_variables)\n",
    "x_train.shape\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training target vectors \n",
    "\n",
    "Create `y_train_float` as matrix product of `x_train` and `x_gen`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12.07730283],\n",
       "       [  9.741318  ],\n",
       "       [  6.06943508],\n",
       "       [  7.09807295],\n",
       "       [  8.99138507],\n",
       "       [  6.84507783],\n",
       "       [  8.34112302],\n",
       "       [ 12.20095924],\n",
       "       [  8.36479175],\n",
       "       [ 11.10619263],\n",
       "       [ 12.70645191],\n",
       "       [ 10.63262148],\n",
       "       [ 10.87927346],\n",
       "       [  6.89670328],\n",
       "       [ 11.52355355],\n",
       "       [ 11.33820698],\n",
       "       [ 10.25776729],\n",
       "       [ 12.2104629 ],\n",
       "       [  7.49973216],\n",
       "       [  8.18014726],\n",
       "       [  7.00606699],\n",
       "       [ 10.6610356 ],\n",
       "       [  7.22219274],\n",
       "       [  7.79272515],\n",
       "       [  9.79701561],\n",
       "       [  9.25028996],\n",
       "       [  6.39764842],\n",
       "       [  8.09685691],\n",
       "       [  8.27848681],\n",
       "       [ 12.83978167],\n",
       "       [ 13.27399716],\n",
       "       [  9.77064943],\n",
       "       [ 10.96601653],\n",
       "       [ 11.21957434],\n",
       "       [  8.69335167],\n",
       "       [ 10.2926138 ],\n",
       "       [  5.51084772],\n",
       "       [  9.8459422 ],\n",
       "       [ 10.00401789],\n",
       "       [  8.95129676],\n",
       "       [ 11.94772574],\n",
       "       [ 11.58730711],\n",
       "       [  9.59637354],\n",
       "       [  7.09051348],\n",
       "       [  8.4928013 ],\n",
       "       [  8.9757022 ],\n",
       "       [ 10.07358125],\n",
       "       [ 10.56721711],\n",
       "       [ 10.72933641],\n",
       "       [  7.41686875],\n",
       "       [ 11.86767577],\n",
       "       [  8.2197531 ],\n",
       "       [  8.54990094],\n",
       "       [  9.94883163],\n",
       "       [ 10.96504465],\n",
       "       [  9.11385393],\n",
       "       [  8.41057898],\n",
       "       [  9.82658734],\n",
       "       [  9.60940377],\n",
       "       [ 10.38361057],\n",
       "       [ 10.97147118],\n",
       "       [ 10.38757288],\n",
       "       [  9.84699179],\n",
       "       [  8.59132292],\n",
       "       [ 10.3125068 ],\n",
       "       [ 11.57609831],\n",
       "       [ 10.82798779],\n",
       "       [ 12.33753298],\n",
       "       [ 12.58931372],\n",
       "       [ 11.50117471],\n",
       "       [ 10.49494496],\n",
       "       [  9.11937801],\n",
       "       [  7.39372679],\n",
       "       [ 11.14536187],\n",
       "       [  9.55786315],\n",
       "       [ 10.11876629],\n",
       "       [  8.41643238],\n",
       "       [  9.77520946],\n",
       "       [  8.54184219],\n",
       "       [  9.85417516],\n",
       "       [  8.68659616],\n",
       "       [  6.01226462],\n",
       "       [  7.4178849 ],\n",
       "       [ 12.897246  ],\n",
       "       [  8.47818548],\n",
       "       [ 10.31588361],\n",
       "       [  9.16600614],\n",
       "       [  9.3059588 ],\n",
       "       [  6.93286665],\n",
       "       [ 10.06380619],\n",
       "       [ 10.10770738],\n",
       "       [  7.79063313],\n",
       "       [  8.48179434],\n",
       "       [ 10.66104777],\n",
       "       [  8.28561289],\n",
       "       [  5.95975296],\n",
       "       [ 12.44222297],\n",
       "       [  9.46981957],\n",
       "       [  6.11797146],\n",
       "       [  6.57815436]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_float = x_train.dot(x_gen).reshape(n_samples,1) \n",
    "y_train_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `y_train_int` by rounding entries of `y_train_float` to the nearest integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12],\n",
       "       [10],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [13],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [12],\n",
       "       [11],\n",
       "       [10],\n",
       "       [12],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 7],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [13],\n",
       "       [10],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [ 6],\n",
       "       [10],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [12],\n",
       "       [12],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [11],\n",
       "       [10],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [13],\n",
       "       [12],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [11],\n",
       "       [10],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [13],\n",
       "       [ 8],\n",
       "       [10],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [10],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [12],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [ 7]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_int = np.round(y_train_float).astype(np.int32)\n",
    "y_train_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `y_train_cat` from `y_train_int` using `to_categorical` by creating binary variables for each (integer) value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = np_utils.to_categorical(y_train_int.reshape(n_samples,\n",
    "                                                          1))\n",
    "y_train_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first column of `y_train_cat` contains only zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_cat[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the correspondence between the unique values in `y_train_int` and the unique rows is `y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique integer values: [ 6  7  8  9 10 11 12 13]\n",
      "unique rows below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    10   11   12   13\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"unique integer values:\",np.unique(y_train_int))\n",
    "print(\"unique rows below\")\n",
    "pd.DataFrame(y_train_cat).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "middle_layer_count = 64\n",
    "\n",
    "model.add(Dense(input_dim  = n_variables, \n",
    "                output_dim = middle_layer_count, \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(input_dim  = middle_layer_count, \n",
    "                output_dim = y_train_cat.shape[1], \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the loss function and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model \n",
    "\n",
    "Use the data in `x_train` and `y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x112f824e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train_cat, \n",
    "          nb_epoch      = n_epoch, \n",
    "          batch_size    = n_samples, \n",
    "          verbose       = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8327729034423828"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train,\n",
    "               y_train_cat, \n",
    "               verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted values for the 3rd sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target value: [9]\n",
      "prediction  : [10]\n"
     ]
    }
   ],
   "source": [
    "arow = 34\n",
    "print(\"target value:\",y_train_int[arow])\n",
    "print(\"prediction  :\",model.predict_classes(np.array([x_train[arow]]), \n",
    "                                            verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted values for the first `10` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predicted\n",
       "0      12         10\n",
       "1      10         10\n",
       "2       6          7\n",
       "3       7          9\n",
       "4       9         10\n",
       "5       7         10\n",
       "6       8         10\n",
       "7      12         10\n",
       "8       8          9\n",
       "9      11         10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"actual\"   : y_train_int.reshape(n_samples),\n",
    "              \"predicted\": model.predict_classes(x_train,\n",
    "                                                 verbose=False)}\n",
    "            )[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display frequency counts\n",
    "\n",
    "Display frequence counts for the absolute difference between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency counts: [28 32 25 13  2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_train, \n",
    "                               verbose=False\n",
    "                              ).reshape(n_samples,)\n",
    "\n",
    "y_init = y_train_int.reshape(n_samples,)\n",
    "\n",
    "y_freq = np.bincount(abs(y_pred - y_init))\n",
    "\n",
    "print(\"Frequency counts:\", y_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print  (\"Accuracy: %.1f percent\" % \n",
    "        np.round(100*y_freq[0] / sum(y_freq), \n",
    "                 decimals=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create regression model\n",
    "\n",
    "The training data consists of:\n",
    "- `x_train` (same as above)\n",
    "- `y_train_float` calculated directly from `x_train` and `x_gen` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "middle_layer_count = 64\n",
    "\n",
    "model.add(Dense(input_dim  = n_variables, \n",
    "                output_dim = middle_layer_count, \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(input_dim  = middle_layer_count, \n",
    "                output_dim = y_train_float.shape[1])) \n",
    "\n",
    "model.compile(loss      = 'mean_absolute_error', \n",
    "              optimizer = 'rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, \n",
    "          y_train_float, \n",
    "          nb_epoch=n_epoch, \n",
    "          batch_size=n_samples, \n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the actual and predicted values side by side\n",
    "\n",
    "Include the square error for each row and the mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_err = pd.DataFrame({\n",
    "        \"actual\"   : y_train_float         .reshape(n_samples),\n",
    "        \"predicted\": model.predict(x_train).reshape(n_samples),\n",
    "        \"sq_err\"   : 0\n",
    "    })\n",
    "pred_err['sq_err'] = (pred_err['actual'] - pred_err['predicted'])**2\n",
    "print('Mean square error:', np.mean(pred_err['sq_err']))\n",
    "pred_err[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
