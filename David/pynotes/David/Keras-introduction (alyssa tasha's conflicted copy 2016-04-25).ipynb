{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - classification and regression\n",
    "\n",
    "Contents:\n",
    "1. Load required libraries\n",
    "1. Set initial parameters\n",
    "1. Create synthetic training datasets\n",
    "1. Create classification model\n",
    "1. Train the model and display accuracy\n",
    "1. Create regression model \n",
    "1. Train the model and display mean square error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas    as pd\n",
    "import numpy     as np\n",
    "import itertools as it\n",
    "\n",
    "from keras.utils       import np_utils \n",
    "from keras.models      import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic training datasets\n",
    "\n",
    "- Set initial parameters\n",
    "- Create a random `x_train` dataset with shape determined by parameters and with random values between `0` and `1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_variables =    10\n",
    "n_samples   =   100\n",
    "n_epoch     = 10000 # number of training iterations\n",
    "min_gen     =     1\n",
    "max_gen     =     4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector `x_gen` \n",
    "\n",
    "The target values of the training datase are created using `x_gen` and `x_train`, which is a matrix of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 1, 1, 2, 1, 1, 3, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gen    = np.random.randint(min_gen, \n",
    "                             max_gen, \n",
    "                             n_variables)\n",
    "x_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `x_train` as a random `n_samples` by `n_variables` matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.66545455e-01,   3.00231037e-01,   5.86119027e-01,\n",
       "          6.54306159e-01,   9.95102926e-01,   1.02686484e-01,\n",
       "          4.69199754e-02,   6.29896071e-01,   1.11859404e-01,\n",
       "          9.45219830e-01],\n",
       "       [  9.04000912e-01,   5.64037330e-01,   3.17608475e-01,\n",
       "          2.97278108e-01,   4.85601537e-01,   1.16181012e-01,\n",
       "          7.33164876e-01,   9.92565430e-01,   8.58867051e-02,\n",
       "          7.86145155e-01],\n",
       "       [  2.34856672e-01,   5.97461624e-01,   7.36601331e-01,\n",
       "          3.74237071e-01,   8.48955961e-02,   2.17768411e-02,\n",
       "          6.02672862e-01,   8.35869385e-01,   7.10771015e-02,\n",
       "          9.29156281e-01],\n",
       "       [  7.27901093e-01,   6.41518674e-01,   3.98372851e-01,\n",
       "          9.77725388e-01,   1.99914324e-01,   6.43125623e-01,\n",
       "          2.24639631e-01,   9.39826858e-01,   2.92807064e-01,\n",
       "          8.02076631e-01],\n",
       "       [  5.34411273e-01,   5.42871151e-01,   3.45395538e-01,\n",
       "          5.25376849e-01,   9.60999872e-01,   1.29774998e-01,\n",
       "          4.53188525e-01,   9.00538317e-01,   5.74158425e-01,\n",
       "          7.60533071e-01],\n",
       "       [  6.41248055e-01,   1.42472052e-01,   7.15528875e-01,\n",
       "          4.63203919e-02,   5.70913514e-02,   9.35013534e-01,\n",
       "          3.22393380e-01,   8.34999694e-01,   7.09534346e-01,\n",
       "          2.27682843e-01],\n",
       "       [  7.12977822e-01,   7.11658964e-01,   3.04127506e-02,\n",
       "          7.09711984e-01,   7.06101905e-02,   2.36628320e-01,\n",
       "          1.00409970e-01,   4.92666115e-01,   8.37272677e-01,\n",
       "          5.90665007e-01],\n",
       "       [  6.37777247e-01,   5.58895896e-01,   5.64361565e-01,\n",
       "          1.54485416e-01,   5.27668984e-01,   6.62580770e-01,\n",
       "          9.48047848e-01,   6.83767678e-01,   1.14971471e-01,\n",
       "          2.01007779e-01],\n",
       "       [  8.75122624e-01,   1.91126942e-01,   6.76892223e-01,\n",
       "          1.21134682e-01,   8.16827459e-01,   6.28708430e-01,\n",
       "          2.46458080e-01,   9.15296697e-01,   9.78300149e-01,\n",
       "          6.01462903e-01],\n",
       "       [  9.22673805e-01,   7.40141780e-01,   7.43495856e-01,\n",
       "          9.29991759e-01,   8.97851599e-01,   1.05366576e-01,\n",
       "          2.42294957e-01,   7.78983796e-01,   9.95111176e-01,\n",
       "          3.44223476e-01],\n",
       "       [  9.95352413e-01,   9.99626170e-01,   9.73664737e-01,\n",
       "          9.19014106e-01,   9.16753450e-01,   3.66817492e-01,\n",
       "          3.86908703e-01,   1.69110802e-01,   9.18779508e-01,\n",
       "          9.83735621e-01],\n",
       "       [  9.78694719e-01,   2.06862640e-01,   2.98524357e-01,\n",
       "          9.39275484e-03,   2.74252238e-01,   9.33050789e-01,\n",
       "          2.85622114e-01,   1.36362577e-01,   4.24503098e-01,\n",
       "          1.95392431e-01],\n",
       "       [  8.69651590e-01,   9.22687460e-01,   9.64337923e-01,\n",
       "          9.27418384e-01,   3.28613034e-01,   9.09158759e-01,\n",
       "          3.22521776e-01,   8.03719718e-01,   8.22813310e-01,\n",
       "          3.61006094e-01],\n",
       "       [  9.49823135e-01,   3.01236648e-01,   6.78122061e-01,\n",
       "          5.74900799e-01,   3.30475898e-01,   2.89188981e-01,\n",
       "          6.22740967e-01,   4.08884632e-01,   9.07043557e-01,\n",
       "          9.73671748e-01],\n",
       "       [  9.00446431e-01,   3.70215444e-01,   5.01230948e-01,\n",
       "          6.72794770e-01,   6.21419938e-01,   5.41715159e-01,\n",
       "          2.11777672e-01,   4.20867248e-01,   3.89980129e-01,\n",
       "          3.06562937e-01],\n",
       "       [  1.83907275e-01,   3.52873313e-01,   4.18776032e-01,\n",
       "          9.45648742e-01,   9.89569106e-01,   7.19074535e-01,\n",
       "          2.10508996e-01,   5.42607185e-01,   8.93214456e-01,\n",
       "          1.80039560e-01],\n",
       "       [  6.15469930e-01,   1.44079221e-01,   3.96196409e-01,\n",
       "          4.22585763e-01,   8.47707318e-01,   4.81000571e-01,\n",
       "          7.46409335e-01,   6.49380752e-02,   1.97996158e-01,\n",
       "          7.43061397e-03],\n",
       "       [  7.44469225e-01,   2.49264093e-01,   8.81008594e-01,\n",
       "          1.09205055e-01,   7.05673942e-01,   1.93207619e-01,\n",
       "          8.64306615e-01,   1.33227833e-01,   5.40411808e-01,\n",
       "          5.98364830e-01],\n",
       "       [  1.99703879e-01,   3.53366968e-01,   7.43907273e-02,\n",
       "          6.57250801e-01,   1.90827178e-01,   3.03656192e-01,\n",
       "          2.83513682e-02,   2.56783981e-02,   3.52382288e-01,\n",
       "          6.45809115e-01],\n",
       "       [  9.55445731e-01,   1.62316734e-01,   6.85092024e-01,\n",
       "          1.92117918e-01,   7.78495946e-01,   7.09264159e-01,\n",
       "          5.67767223e-01,   3.69037021e-01,   5.17985497e-01,\n",
       "          2.08037728e-01],\n",
       "       [  4.25681018e-01,   9.77610755e-01,   2.26278929e-01,\n",
       "          9.31995431e-01,   3.00451627e-01,   1.50312832e-01,\n",
       "          8.96284564e-01,   7.59678209e-01,   3.61414525e-01,\n",
       "          7.70712797e-01],\n",
       "       [  3.33795489e-02,   1.62085815e-01,   1.72883054e-01,\n",
       "          3.97297725e-01,   3.50665067e-01,   9.54243022e-01,\n",
       "          8.54903197e-01,   7.83534086e-01,   8.71193774e-01,\n",
       "          8.47968991e-01],\n",
       "       [  1.24585904e-01,   1.93427903e-01,   1.19755586e-01,\n",
       "          6.86572476e-01,   2.71093443e-01,   2.51713330e-01,\n",
       "          5.09465521e-01,   2.70801658e-01,   8.74282016e-01,\n",
       "          7.95695843e-01],\n",
       "       [  9.27960142e-01,   1.27937429e-01,   9.29441278e-02,\n",
       "          6.01842227e-02,   1.05713793e-01,   8.98527789e-01,\n",
       "          4.58465210e-01,   4.90618985e-02,   5.73712400e-01,\n",
       "          6.60369044e-02],\n",
       "       [  9.22745892e-01,   6.89041402e-01,   3.51443708e-01,\n",
       "          9.67292011e-01,   3.34958601e-01,   8.39673669e-01,\n",
       "          7.36481334e-01,   9.22579845e-01,   3.64084506e-01,\n",
       "          9.37460934e-01],\n",
       "       [  9.92591109e-01,   2.10752966e-01,   9.94044051e-01,\n",
       "          6.36053721e-01,   8.68873240e-01,   7.25882111e-01,\n",
       "          9.11831424e-01,   3.98264475e-01,   9.26558390e-01,\n",
       "          3.11460350e-01],\n",
       "       [  4.62620609e-01,   9.19874532e-01,   9.20223797e-01,\n",
       "          1.95471702e-02,   7.96709822e-01,   2.15055266e-01,\n",
       "          8.95120529e-01,   5.12717036e-01,   3.62825469e-01,\n",
       "          1.86293518e-03],\n",
       "       [  3.29830283e-01,   8.06413092e-01,   5.12640153e-01,\n",
       "          1.99447987e-01,   5.71284276e-02,   1.63864379e-01,\n",
       "          5.39589745e-01,   7.71503881e-01,   1.37634011e-01,\n",
       "          3.99660134e-01],\n",
       "       [  8.03848088e-01,   3.88648723e-01,   1.15772319e-01,\n",
       "          4.03366830e-02,   2.02790082e-01,   2.42664414e-01,\n",
       "          5.86204332e-01,   2.92516043e-01,   4.22064494e-01,\n",
       "          8.98873015e-01],\n",
       "       [  5.13414185e-01,   4.51658241e-01,   8.28610816e-01,\n",
       "          4.80887692e-01,   6.01070755e-02,   3.00861040e-01,\n",
       "          8.34747331e-01,   8.48685599e-01,   2.74297830e-01,\n",
       "          2.94700135e-01],\n",
       "       [  7.53928452e-01,   4.40216476e-01,   4.36259394e-02,\n",
       "          3.43235479e-01,   5.90039882e-01,   9.37132025e-01,\n",
       "          1.16371580e-01,   3.35653609e-01,   4.03097271e-01,\n",
       "          8.60351165e-01],\n",
       "       [  7.31822383e-01,   7.56297626e-01,   7.98949339e-01,\n",
       "          1.18669717e-01,   1.48985491e-01,   8.89598116e-01,\n",
       "          5.60728772e-01,   1.40307986e-01,   8.93579235e-01,\n",
       "          9.21574140e-01],\n",
       "       [  1.06643106e-01,   5.04259040e-01,   1.67011568e-01,\n",
       "          3.92726696e-01,   9.10131595e-01,   4.11631517e-01,\n",
       "          9.94824559e-01,   2.79488711e-01,   6.80956029e-01,\n",
       "          1.90630679e-01],\n",
       "       [  8.30259202e-01,   5.85308522e-02,   1.44011732e-01,\n",
       "          6.57656833e-01,   2.65682627e-01,   1.54025836e-01,\n",
       "          8.74793698e-01,   2.68861979e-01,   8.18305964e-02,\n",
       "          7.36182931e-01],\n",
       "       [  7.68717744e-03,   6.41669746e-01,   5.37421436e-01,\n",
       "          2.95576734e-01,   4.47297503e-01,   8.05592480e-01,\n",
       "          8.30136293e-02,   9.52241563e-01,   4.57212265e-01,\n",
       "          1.86322547e-02],\n",
       "       [  2.80272755e-01,   1.97661104e-02,   4.27861162e-02,\n",
       "          9.73906994e-01,   6.52226284e-01,   8.94771137e-01,\n",
       "          7.82938334e-02,   2.15370392e-01,   2.87102964e-01,\n",
       "          6.02968924e-01],\n",
       "       [  7.84001540e-01,   2.52651944e-01,   9.83152073e-01,\n",
       "          3.44961708e-01,   3.39828306e-01,   5.95977581e-01,\n",
       "          6.88990979e-01,   5.13138811e-01,   5.69575005e-01,\n",
       "          9.27806616e-01],\n",
       "       [  3.72812838e-01,   9.38283458e-02,   1.58554830e-01,\n",
       "          5.73658366e-01,   3.97217015e-01,   4.25126517e-01,\n",
       "          4.98821918e-01,   4.54289823e-01,   1.75682630e-01,\n",
       "          6.43991943e-01],\n",
       "       [  8.31882506e-01,   6.42133008e-01,   2.10196711e-02,\n",
       "          9.99452923e-01,   9.39116142e-01,   5.61063249e-01,\n",
       "          6.21871363e-01,   4.18004546e-01,   8.59835365e-02,\n",
       "          1.14926407e-01],\n",
       "       [  3.42727508e-01,   7.08615275e-01,   9.39315326e-02,\n",
       "          8.04713657e-02,   1.21130790e-02,   5.16339307e-01,\n",
       "          9.35921603e-01,   8.49266402e-01,   9.75013799e-02,\n",
       "          9.14514077e-01],\n",
       "       [  9.79706726e-01,   6.35858278e-01,   3.50749111e-01,\n",
       "          8.47527111e-01,   1.19537068e-01,   4.65700810e-01,\n",
       "          7.58511717e-01,   2.20086489e-01,   9.57626311e-01,\n",
       "          7.13698260e-01],\n",
       "       [  2.63577854e-01,   5.46883416e-01,   9.55073924e-01,\n",
       "          3.02611769e-01,   3.66723430e-01,   9.40342500e-02,\n",
       "          9.36121821e-02,   2.00137839e-01,   7.74822932e-01,\n",
       "          5.69523610e-01],\n",
       "       [  4.03110705e-01,   7.70998263e-01,   3.69889571e-01,\n",
       "          4.24365952e-01,   4.63129744e-01,   1.01555913e-01,\n",
       "          3.11039116e-01,   5.41261088e-01,   6.06081372e-01,\n",
       "          3.75943302e-01],\n",
       "       [  3.28609029e-01,   3.70277856e-01,   5.77734302e-01,\n",
       "          2.70659624e-01,   6.07214215e-02,   4.85443216e-01,\n",
       "          7.85895713e-01,   5.09669898e-01,   4.34618047e-01,\n",
       "          3.31162894e-01],\n",
       "       [  5.13857904e-01,   7.01931263e-01,   4.45268045e-01,\n",
       "          9.57285718e-01,   9.58170589e-01,   6.91209775e-01,\n",
       "          8.49341796e-01,   8.48999446e-01,   5.85726029e-01,\n",
       "          5.23942433e-01],\n",
       "       [  6.48859230e-01,   9.00317489e-01,   8.59697524e-01,\n",
       "          5.95149925e-01,   9.61254891e-01,   8.63289114e-01,\n",
       "          3.13547591e-01,   9.03801114e-01,   8.85747191e-01,\n",
       "          7.30348071e-01],\n",
       "       [  2.20415948e-04,   8.93762649e-01,   3.93436972e-01,\n",
       "          6.71311634e-01,   7.38652518e-01,   6.08685123e-01,\n",
       "          9.36668274e-01,   8.88468798e-01,   9.44552476e-01,\n",
       "          1.81708575e-01],\n",
       "       [  1.49204574e-01,   6.26111859e-01,   5.33370591e-01,\n",
       "          1.15695477e-01,   6.49098519e-01,   5.99657054e-01,\n",
       "          2.75144226e-01,   1.49915735e-01,   2.09296305e-01,\n",
       "          8.90331023e-01],\n",
       "       [  4.42957121e-01,   8.59776267e-01,   2.36762976e-01,\n",
       "          7.57200784e-01,   6.07892885e-01,   9.61264693e-01,\n",
       "          8.20945724e-01,   9.84636115e-01,   5.14067632e-01,\n",
       "          8.50004627e-01],\n",
       "       [  8.23248876e-02,   9.27172084e-01,   7.37711520e-01,\n",
       "          5.98896909e-02,   9.07760387e-01,   4.79510742e-01,\n",
       "          2.40633295e-01,   5.93168959e-01,   4.97038633e-01,\n",
       "          1.45193364e-01],\n",
       "       [  4.24320913e-01,   8.21405257e-01,   7.12377884e-01,\n",
       "          1.72434123e-01,   6.16605343e-01,   4.07770347e-01,\n",
       "          6.54398761e-02,   7.29798913e-01,   7.74556846e-01,\n",
       "          3.36143854e-01],\n",
       "       [  4.81598417e-01,   2.12983142e-01,   3.74964043e-01,\n",
       "          8.35035346e-01,   5.18771832e-01,   1.26737983e-02,\n",
       "          4.75084261e-01,   7.09246739e-01,   6.62121686e-01,\n",
       "          2.57568991e-01],\n",
       "       [  3.34268998e-01,   2.64812170e-01,   1.41691521e-01,\n",
       "          2.54125577e-01,   3.60002238e-01,   1.32762978e-01,\n",
       "          2.80716719e-01,   4.36333647e-01,   3.59380733e-01,\n",
       "          6.42945078e-01],\n",
       "       [  3.54767502e-01,   2.48282704e-01,   7.21071257e-01,\n",
       "          4.64648447e-01,   1.55429473e-03,   1.24454499e-01,\n",
       "          5.99702186e-01,   4.12995588e-01,   5.67026777e-02,\n",
       "          1.15754078e-01],\n",
       "       [  2.62845272e-01,   3.55342813e-01,   3.07853495e-01,\n",
       "          6.15082145e-01,   1.66953105e-01,   9.86394779e-02,\n",
       "          6.65012227e-01,   4.91464205e-01,   3.56946433e-01,\n",
       "          5.10070989e-01],\n",
       "       [  2.74575020e-01,   2.32994887e-02,   7.39270753e-01,\n",
       "          6.07577148e-01,   7.06232686e-01,   1.86220687e-01,\n",
       "          5.69934349e-01,   6.65824579e-01,   7.12454044e-01,\n",
       "          6.22732441e-01],\n",
       "       [  3.12432705e-01,   5.60231498e-01,   4.54073605e-02,\n",
       "          3.18855543e-01,   2.31422489e-01,   4.45418633e-01,\n",
       "          5.44935077e-01,   1.38317038e-01,   9.35548183e-01,\n",
       "          8.61403975e-01],\n",
       "       [  1.69950814e-01,   7.74218705e-01,   6.98728212e-03,\n",
       "          3.45001730e-01,   7.15513772e-01,   8.34145048e-02,\n",
       "          7.39697608e-01,   3.19435197e-01,   2.58494580e-01,\n",
       "          7.54387998e-01],\n",
       "       [  2.98935934e-01,   1.18175855e-01,   4.30983789e-01,\n",
       "          5.26329876e-03,   2.01762232e-01,   7.14830161e-01,\n",
       "          5.60091743e-01,   2.15567105e-01,   9.47340523e-01,\n",
       "          8.51131275e-01],\n",
       "       [  2.46782278e-01,   5.44967547e-02,   2.74997925e-01,\n",
       "          2.44431849e-01,   7.84736481e-02,   4.38091193e-01,\n",
       "          7.13361741e-01,   5.50340175e-01,   7.29498542e-01,\n",
       "          3.34988929e-01],\n",
       "       [  8.32672684e-01,   3.02678599e-01,   3.06729744e-01,\n",
       "          6.61618606e-01,   8.43733659e-01,   2.12874670e-01,\n",
       "          3.39177151e-01,   4.73228111e-01,   8.38864154e-01,\n",
       "          8.79917941e-01],\n",
       "       [  3.19446760e-01,   4.50688841e-01,   4.96133865e-02,\n",
       "          2.20684174e-01,   6.74802482e-01,   8.58721689e-01,\n",
       "          7.57887227e-01,   7.00076885e-01,   6.72975771e-01,\n",
       "          6.40127028e-01],\n",
       "       [  4.99440611e-01,   3.78722864e-01,   5.17935619e-01,\n",
       "          2.25307907e-01,   9.00169339e-01,   6.79483189e-01,\n",
       "          8.64295360e-01,   9.01115456e-01,   3.96161698e-01,\n",
       "          6.57462908e-01],\n",
       "       [  4.22406728e-01,   7.77895782e-01,   9.30453702e-01,\n",
       "          3.39611348e-01,   7.67132370e-01,   3.82354130e-01,\n",
       "          2.65461845e-01,   1.24386131e-01,   6.81820434e-01,\n",
       "          1.04959980e-01],\n",
       "       [  3.33768201e-01,   2.32184060e-02,   8.64223041e-01,\n",
       "          6.65340309e-01,   3.66400416e-01,   2.77877809e-01,\n",
       "          4.01991628e-01,   1.72561467e-01,   6.14628133e-02,\n",
       "          1.31044896e-01],\n",
       "       [  1.97098053e-01,   6.09367389e-01,   6.21761985e-02,\n",
       "          4.35484871e-01,   4.56535671e-01,   4.29141520e-01,\n",
       "          2.64165153e-03,   6.38915388e-01,   8.26828909e-01,\n",
       "          8.55137214e-01],\n",
       "       [  8.08641025e-01,   1.93972925e-02,   4.83652558e-02,\n",
       "          1.13629619e-01,   4.59945456e-01,   1.16211716e-01,\n",
       "          5.66946377e-01,   1.14903096e-01,   3.88336485e-01,\n",
       "          1.45528124e-01],\n",
       "       [  7.01695827e-01,   4.77035637e-01,   3.51256148e-01,\n",
       "          2.33718860e-01,   4.53467928e-01,   8.13698266e-01,\n",
       "          5.37028519e-01,   4.02331004e-01,   8.22377997e-02,\n",
       "          6.17518673e-01],\n",
       "       [  6.85073416e-02,   6.96343788e-01,   7.88373229e-01,\n",
       "          9.24880364e-01,   4.62522940e-01,   3.36462809e-01,\n",
       "          1.57228350e-01,   3.96074204e-01,   6.09593222e-01,\n",
       "          1.57841172e-01],\n",
       "       [  7.01474671e-01,   3.62630225e-01,   5.66619201e-01,\n",
       "          4.37511934e-01,   6.08147547e-01,   9.06987118e-01,\n",
       "          4.96363471e-01,   6.81662842e-01,   1.24753409e-01,\n",
       "          3.36310194e-02],\n",
       "       [  5.69218092e-01,   2.64302171e-01,   4.93476001e-01,\n",
       "          2.08421518e-01,   1.93335927e-02,   9.69623064e-01,\n",
       "          5.20043608e-01,   7.56030179e-01,   4.79117209e-01,\n",
       "          7.23186301e-01],\n",
       "       [  5.52651762e-01,   9.76771000e-01,   1.22070743e-01,\n",
       "          3.98747560e-01,   6.16534358e-02,   8.89248432e-01,\n",
       "          6.23250194e-01,   9.25150181e-01,   3.91263352e-01,\n",
       "          8.83745475e-01],\n",
       "       [  2.43052572e-01,   3.51531589e-01,   8.43110700e-01,\n",
       "          9.72169263e-01,   7.37160662e-01,   6.81724905e-01,\n",
       "          1.89248585e-01,   6.04789455e-01,   2.37751600e-01,\n",
       "          8.09409828e-01],\n",
       "       [  2.97329226e-01,   8.37398664e-01,   2.00434392e-01,\n",
       "          8.08597539e-01,   2.40822093e-01,   9.20246394e-01,\n",
       "          7.58958811e-01,   6.32251314e-01,   3.62980859e-01,\n",
       "          8.45214328e-01],\n",
       "       [  7.75810372e-01,   2.52339695e-01,   5.48228628e-01,\n",
       "          4.38572067e-01,   4.38005046e-01,   6.24452650e-01,\n",
       "          9.44526045e-01,   6.47837585e-01,   5.52299184e-01,\n",
       "          1.07552767e-02],\n",
       "       [  7.56549894e-01,   2.87222977e-01,   9.31332558e-01,\n",
       "          6.44272954e-01,   2.70694317e-01,   7.03229020e-01,\n",
       "          8.10119427e-01,   9.60485567e-01,   1.15923640e-01,\n",
       "          7.22905695e-01],\n",
       "       [  8.32637096e-01,   3.59070428e-01,   3.03846459e-01,\n",
       "          6.35466266e-01,   4.93954192e-01,   1.61329324e-01,\n",
       "          9.42592020e-01,   8.01596593e-01,   9.37548809e-01,\n",
       "          2.28964781e-01],\n",
       "       [  2.69795623e-01,   4.84597506e-01,   4.73905159e-03,\n",
       "          6.71132829e-01,   8.74452156e-01,   2.77495269e-01,\n",
       "          3.76552036e-01,   1.84181243e-01,   2.44131943e-01,\n",
       "          7.55918808e-01],\n",
       "       [  6.91389491e-01,   5.21360176e-01,   5.47127469e-01,\n",
       "          7.03348185e-01,   4.19465114e-01,   7.45711093e-01,\n",
       "          1.77054036e-01,   9.34408783e-01,   7.86940892e-01,\n",
       "          4.05199606e-01],\n",
       "       [  6.79605256e-01,   4.77557221e-01,   2.91309708e-01,\n",
       "          3.23791740e-01,   4.99093346e-01,   5.27026316e-01,\n",
       "          6.82847860e-01,   7.23466762e-01,   1.12568238e-01,\n",
       "          7.22588156e-01],\n",
       "       [  6.32151930e-01,   9.33536018e-01,   3.30859329e-01,\n",
       "          3.53210467e-01,   2.41185113e-01,   3.92112726e-01,\n",
       "          8.52788950e-01,   6.72193778e-01,   2.14188314e-01,\n",
       "          6.82972206e-01],\n",
       "       [  6.23644149e-01,   4.75918141e-01,   1.44719858e-01,\n",
       "          9.82207542e-01,   4.32159538e-01,   6.25873144e-01,\n",
       "          3.44710141e-01,   5.99221089e-01,   6.21694539e-01,\n",
       "          2.78355190e-01],\n",
       "       [  2.34643125e-01,   6.67161061e-01,   6.95738214e-01,\n",
       "          8.45152399e-01,   9.60001244e-01,   5.20761810e-02,\n",
       "          1.62171289e-01,   4.64019607e-01,   1.94323738e-01,\n",
       "          1.02922607e-01],\n",
       "       [  7.08160439e-01,   4.45703961e-01,   1.89432967e-01,\n",
       "          4.50049225e-01,   5.42462813e-01,   2.55393441e-01,\n",
       "          9.72774988e-01,   3.99606355e-01,   7.63048650e-01,\n",
       "          1.31454975e-01],\n",
       "       [  6.32488727e-01,   3.27248315e-01,   5.09966445e-01,\n",
       "          4.85774993e-01,   9.23274578e-01,   7.35324034e-02,\n",
       "          2.68148599e-01,   6.15978011e-01,   3.38716556e-01,\n",
       "          6.83249439e-01],\n",
       "       [  5.80989217e-01,   8.83641006e-01,   3.75119594e-01,\n",
       "          8.06084927e-01,   2.08104012e-02,   9.70527085e-01,\n",
       "          9.87917518e-01,   4.30276305e-01,   7.43265141e-01,\n",
       "          7.68833531e-01],\n",
       "       [  6.94822873e-01,   6.82391599e-01,   3.61249188e-01,\n",
       "          6.32456989e-01,   2.32990734e-01,   6.86283611e-02,\n",
       "          7.56623772e-01,   1.06616483e-01,   6.88444544e-01,\n",
       "          9.61913777e-01],\n",
       "       [  4.18023630e-01,   7.12317487e-01,   1.77842985e-01,\n",
       "          7.12216407e-01,   8.97121103e-01,   9.53407853e-01,\n",
       "          4.13673371e-01,   3.14210273e-01,   4.89267633e-01,\n",
       "          7.32803491e-01],\n",
       "       [  9.66968200e-02,   4.11536183e-01,   2.65136800e-01,\n",
       "          6.89340926e-01,   5.32644030e-02,   4.10328451e-01,\n",
       "          5.16584289e-01,   3.62364536e-01,   8.36497202e-01,\n",
       "          8.09027141e-01],\n",
       "       [  2.23084833e-01,   6.04226349e-01,   2.32086494e-03,\n",
       "          4.34882708e-01,   6.84161701e-01,   3.74314736e-01,\n",
       "          2.23206131e-01,   9.65910049e-01,   1.94291951e-01,\n",
       "          7.50258898e-01],\n",
       "       [  9.93946783e-01,   5.16753017e-01,   3.94400755e-01,\n",
       "          1.99370171e-01,   6.08781502e-01,   1.15551808e-01,\n",
       "          5.01474368e-01,   9.75719992e-01,   4.63672079e-01,\n",
       "          3.75517039e-01],\n",
       "       [  9.53377128e-02,   8.22143793e-01,   2.01146372e-01,\n",
       "          3.81169992e-01,   4.18536542e-01,   7.34495858e-01,\n",
       "          4.21220511e-01,   7.94128551e-01,   8.00589827e-01,\n",
       "          5.30001078e-01],\n",
       "       [  9.03641448e-02,   8.21095738e-01,   8.58277148e-01,\n",
       "          2.09670770e-01,   8.36635199e-01,   4.26804978e-01,\n",
       "          8.83811902e-01,   3.14907568e-01,   1.78838747e-01,\n",
       "          5.88455518e-02],\n",
       "       [  5.95351362e-01,   3.78524926e-01,   5.13680433e-01,\n",
       "          4.05578661e-01,   4.81817594e-01,   3.77262185e-01,\n",
       "          8.82578630e-01,   5.44603522e-01,   5.64561029e-01,\n",
       "          2.40253428e-01],\n",
       "       [  8.17957342e-01,   4.08456810e-01,   3.41162495e-01,\n",
       "          4.13197736e-01,   1.10214390e-01,   2.10702771e-01,\n",
       "          6.38738424e-01,   5.07683213e-01,   2.97577289e-01,\n",
       "          5.27376371e-01],\n",
       "       [  9.20120071e-01,   7.70767828e-01,   4.95916370e-01,\n",
       "          9.52126020e-01,   2.63232581e-01,   6.72062165e-01,\n",
       "          6.37686164e-01,   1.68418701e-01,   2.25997525e-01,\n",
       "          2.91456594e-01],\n",
       "       [  8.81660200e-01,   3.71653630e-01,   3.78299662e-01,\n",
       "          3.87387498e-01,   8.61258483e-02,   2.04965546e-01,\n",
       "          4.33640142e-02,   4.41469370e-01,   7.39817965e-01,\n",
       "          4.07086252e-01],\n",
       "       [  3.64876016e-01,   6.03054392e-01,   5.13727239e-01,\n",
       "          3.23923467e-01,   8.18240266e-01,   1.48350830e-01,\n",
       "          8.77277676e-01,   1.04159824e-01,   2.65363494e-01,\n",
       "          3.01421565e-01],\n",
       "       [  7.65035890e-01,   2.01214406e-01,   9.26662871e-01,\n",
       "          1.02235056e-01,   8.72891012e-01,   6.51874494e-01,\n",
       "          5.33658745e-01,   5.20516672e-01,   2.13374855e-01,\n",
       "          5.28841068e-01],\n",
       "       [  2.17824275e-01,   9.82769972e-01,   7.77431049e-01,\n",
       "          9.55730026e-02,   7.94902710e-01,   7.29636468e-01,\n",
       "          7.01183450e-01,   3.44121874e-01,   2.73529936e-01,\n",
       "          5.64793559e-02]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.random.rand(n_samples,\n",
    "                         n_variables)\n",
    "x_train.shape\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training target vectors \n",
    "\n",
    "Create `y_train_float` as matrix product of `x_train` and `x_gen`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.2845016 ],\n",
       "       [  7.69603426],\n",
       "       [  5.85885048],\n",
       "       [  8.93082292],\n",
       "       [  8.41955795],\n",
       "       [  8.98439173],\n",
       "       [  7.86055587],\n",
       "       [  7.78600442],\n",
       "       [ 11.06377639],\n",
       "       [ 11.38456717],\n",
       "       [ 12.79850907],\n",
       "       [  7.7806285 ],\n",
       "       [ 12.49035453],\n",
       "       [ 10.71713285],\n",
       "       [  8.5608099 ],\n",
       "       [  8.72831323],\n",
       "       [  6.42794255],\n",
       "       [  8.66311789],\n",
       "       [  4.31363617],\n",
       "       [  9.48677862],\n",
       "       [  7.75120353],\n",
       "       [  8.364427  ],\n",
       "       [  6.46659844],\n",
       "       [  7.35536092],\n",
       "       [ 10.83054008],\n",
       "       [ 12.534537  ],\n",
       "       [  7.89272838],\n",
       "       [  5.52914521],\n",
       "       [  6.80398009],\n",
       "       [  7.59286583],\n",
       "       [  8.11846129],\n",
       "       [ 10.8998635 ],\n",
       "       [  6.79214485],\n",
       "       [  6.19405345],\n",
       "       [  6.51915759],\n",
       "       [  6.1197742 ],\n",
       "       [ 10.28636731],\n",
       "       [  5.47465651],\n",
       "       [  7.65326836],\n",
       "       [  6.04213015],\n",
       "       [ 10.74011788],\n",
       "       [  7.29291095],\n",
       "       [  6.85720466],\n",
       "       [  6.74442367],\n",
       "       [ 10.41137868],\n",
       "       [ 12.45421162],\n",
       "       [  9.14913531],\n",
       "       [  6.04785477],\n",
       "       [ 10.147586  ],\n",
       "       [  7.04635287],\n",
       "       [  8.5787571 ],\n",
       "       [  7.2151263 ],\n",
       "       [  4.86879362],\n",
       "       [  4.76839935],\n",
       "       [  5.47628654],\n",
       "       [  8.00767076],\n",
       "       [  7.38076027],\n",
       "       [  5.11439477],\n",
       "       [  7.98244878],\n",
       "       [  6.33111379],\n",
       "       [  9.55417341],\n",
       "       [  8.23820438],\n",
       "       [  9.00871838],\n",
       "       [  8.31774461],\n",
       "       [  5.23045186],\n",
       "       [  7.05249851],\n",
       "       [  5.34043644],\n",
       "       [  7.40281033],\n",
       "       [  7.07886459],\n",
       "       [  8.04584392],\n",
       "       [  8.56252141],\n",
       "       [  8.72370154],\n",
       "       [  8.15639311],\n",
       "       [  8.34553458],\n",
       "       [  9.06172694],\n",
       "       [  9.58224469],\n",
       "       [  9.70255356],\n",
       "       [  5.45308592],\n",
       "       [ 10.18150417],\n",
       "       [  7.44253762],\n",
       "       [  7.72085137],\n",
       "       [  8.38977371],\n",
       "       [  5.98395759],\n",
       "       [  8.2453324 ],\n",
       "       [  7.38428748],\n",
       "       [ 10.56162012],\n",
       "       [  8.38255071],\n",
       "       [  8.7667176 ],\n",
       "       [  6.99263004],\n",
       "       [  5.66804739],\n",
       "       [  8.5703778 ],\n",
       "       [  7.92626755],\n",
       "       [  6.50273965],\n",
       "       [  8.19497917],\n",
       "       [  7.05600137],\n",
       "       [  8.85799775],\n",
       "       [  7.76805152],\n",
       "       [  6.24295186],\n",
       "       [  8.85166392],\n",
       "       [  7.46322803]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_float = x_train.dot(x_gen).reshape(n_samples,1) \n",
    "y_train_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `y_train_int` by rounding entries of `y_train_float` to the nearest integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [13],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [11],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [ 9],\n",
       "       [ 4],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [11],\n",
       "       [13],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 6],\n",
       "       [10],\n",
       "       [ 5],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [10],\n",
       "       [12],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 8],\n",
       "       [ 7],\n",
       "       [ 5],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 5],\n",
       "       [ 7],\n",
       "       [ 5],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [10],\n",
       "       [ 5],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 8],\n",
       "       [ 7],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [ 6],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 9],\n",
       "       [ 7]], dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_int = np.round(y_train_float).astype(np.int32)\n",
    "y_train_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `y_train_cat` from `y_train_int` using `to_categorical` by creating binary variables for each (integer) value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = np_utils.to_categorical(y_train_int.reshape(n_samples,\n",
    "                                                          1))\n",
    "y_train_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first column of `y_train_cat` contains only zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_cat[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the correspondence between the unique values in `y_train_int` and the unique rows is `y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique integer values: [ 4  5  6  7  8  9 10 11 12 13]\n",
      "unique rows below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    10   11   12   13\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "18  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "36  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "37  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"unique integer values:\",np.unique(y_train_int))\n",
    "print(\"unique rows below\")\n",
    "pd.DataFrame(y_train_cat).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "middle_layer_count = 64\n",
    "\n",
    "model.add(Dense(input_dim  = n_variables, \n",
    "                output_dim = middle_layer_count, \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(input_dim  = middle_layer_count, \n",
    "                output_dim = y_train_cat.shape[1], \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the loss function and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model \n",
    "\n",
    "Use the data in `x_train` and `y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127ed3518>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train_cat, \n",
    "          nb_epoch      = n_epoch, \n",
    "          batch_size    = n_samples, \n",
    "          verbose       = False, \n",
    "          show_accuracy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.956048071384\n",
      "accuracy:  0.680000007153\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_train, \n",
    "                                y_train_cat, \n",
    "                                show_accuracy = True, \n",
    "                                verbose       = False)\n",
    "print('loss: ', loss)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted values for the 3rd sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target value: [7]\n",
      "prediction  : [7]\n"
     ]
    }
   ],
   "source": [
    "arow = 34\n",
    "print(\"target value:\",y_train_int[arow])\n",
    "print(\"prediction  :\",model.predict_classes(np.array([x_train[arow]]), \n",
    "                                            verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted values for the first `10` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predicted\n",
       "0       7          7\n",
       "1       8          8\n",
       "2       6          6\n",
       "3       9         10\n",
       "4       8          8\n",
       "5       9          9\n",
       "6       8          8\n",
       "7       8          8\n",
       "8      11          9\n",
       "9      11         11"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"actual\"   : y_train_int.reshape(n_samples),\n",
    "              \"predicted\": model.predict_classes(x_train,\n",
    "                                                 verbose=False)}\n",
    "            )[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display frequency counts\n",
    "\n",
    "Display frequence counts for the absolute difference between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency counts: [68 30  2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_train, \n",
    "                               verbose=False\n",
    "                              ).reshape(n_samples,)\n",
    "\n",
    "y_init = y_train_int.reshape(n_samples,)\n",
    "\n",
    "y_freq = np.bincount(abs(y_pred - y_init))\n",
    "\n",
    "print(\"Frequency counts:\", y_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.0 percent\n"
     ]
    }
   ],
   "source": [
    "print  (\"Accuracy: %.1f percent\" % \n",
    "        np.round(100*y_freq[0] / sum(y_freq), \n",
    "                 decimals=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create regression model\n",
    "\n",
    "The training data consists of:\n",
    "- `x_train` (same as above)\n",
    "- `y_train_float` calculated directly from `x_train` and `x_gen` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "middle_layer_count = 64\n",
    "\n",
    "model.add(Dense(input_dim  = n_variables, \n",
    "                output_dim = middle_layer_count, \n",
    "                init       = \"glorot_uniform\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(input_dim  = middle_layer_count, \n",
    "                output_dim = y_train_float.shape[1])) \n",
    "\n",
    "model.compile(loss      = 'mean_absolute_error', \n",
    "              optimizer = 'rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12793f7f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train_float, \n",
    "          nb_epoch=n_epoch, \n",
    "          batch_size=n_samples, \n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the actual and predicted values side by side\n",
    "\n",
    "Include the square error for each row and the mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error: 0.01089013223843814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>sq_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.284502</td>\n",
       "      <td>7.340265</td>\n",
       "      <td>0.003110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.696034</td>\n",
       "      <td>7.733113</td>\n",
       "      <td>0.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.858850</td>\n",
       "      <td>5.907280</td>\n",
       "      <td>0.002345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.930823</td>\n",
       "      <td>9.081603</td>\n",
       "      <td>0.022735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.419558</td>\n",
       "      <td>8.573089</td>\n",
       "      <td>0.023572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.984392</td>\n",
       "      <td>9.072179</td>\n",
       "      <td>0.007707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.860556</td>\n",
       "      <td>7.941057</td>\n",
       "      <td>0.006480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.786004</td>\n",
       "      <td>7.898627</td>\n",
       "      <td>0.012684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.063776</td>\n",
       "      <td>11.087074</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.384567</td>\n",
       "      <td>11.388608</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  predicted    sq_err\n",
       "0   7.284502   7.340265  0.003110\n",
       "1   7.696034   7.733113  0.001375\n",
       "2   5.858850   5.907280  0.002345\n",
       "3   8.930823   9.081603  0.022735\n",
       "4   8.419558   8.573089  0.023572\n",
       "5   8.984392   9.072179  0.007707\n",
       "6   7.860556   7.941057  0.006480\n",
       "7   7.786004   7.898627  0.012684\n",
       "8  11.063776  11.087074  0.000543\n",
       "9  11.384567  11.388608  0.000016"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_err = pd.DataFrame({\n",
    "        \"actual\"   : y_train_float         .reshape(n_samples),\n",
    "        \"predicted\": model.predict(x_train).reshape(n_samples),\n",
    "        \"sq_err\"   : 0\n",
    "    })\n",
    "pred_err['sq_err'] = (pred_err['actual'] - pred_err['predicted'])**2\n",
    "print('Mean square error:', np.mean(pred_err['sq_err']))\n",
    "pred_err[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
