{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read parts of the MSD into tables\n",
    "\n",
    "This notebook creates a pandas dataframe from the `/metadata/songs` and `/analysis/songs` tables in the HDF5 files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` module requires code from the _PyTables_ package. To load this package into Python from a console:\n",
    "\n",
    "> `$ conda install --name python3 PyTables`\n",
    "\n",
    "This only needs to happen once on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools as it\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define utility functions\n",
    "\n",
    "The `get_filenames` function recursively gets the names of all files in a given directory `path` and all of its subdirectories. The function returns a multi-level list if `path` contains subdirectories. The `unlist` function flattens the list by removing one level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filenames(path):\n",
    "    return([get_filenames(path+\"/\"+entry.name)\n",
    "            if entry.is_dir() \n",
    "            else path+\"/\"+entry.name \n",
    "            for entry \n",
    "            in os.scandir(path)\n",
    "           ])\n",
    "\n",
    "def unlist(alist):\n",
    "    return(list(it.chain.from_iterable(alist)\n",
    "               )\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `make_1row_df` function returns a single row dataframe and takes the following input:\n",
    "\n",
    "- `filename`: full path file name of an MSD HDF5 file containing data for a single song\n",
    "- `metadata_vars`: list of variable names from `/metadata/songs`\n",
    "- `analysis_vars`: list of variable names from `/analysis/songs`\n",
    "- `remove`: \n",
    "    - if `False` the variables listed in the last two parameters are retrieved from the input file\n",
    "    - if `True` all variables except those listed are retrieved from the input file\n",
    "\n",
    "See comments in the code for further details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_1row_df(filename='', metadata_vars=[], analysis_vars=[], remove=False):\n",
    "    # open `filename` as a HDF5 file\n",
    "    store = pd.HDFStore(filename,\"r\")\n",
    "    if remove==False:\n",
    "        # lists `metadata_vars` and `analysis_vars` contain the variables to keep\n",
    "        metadata_var_list = metadata_vars\n",
    "        analysis_var_list = analysis_vars\n",
    "    else: # these lists contain the variables to remove\n",
    "        metadata_var_list = list({item for item \n",
    "                                  in list(store.root.metadata.songs.read().dtype.names) \n",
    "                                  if item not in metadata_remove})\n",
    "        analysis_var_list = list({item for item \n",
    "                                  in list(store.root.analysis.songs.read().dtype.names) \n",
    "                                  if item not in analysis_remove})\n",
    "    # retrieve a single row dataframe from `/metadata/songs`\n",
    "    ret_metadata = pd.DataFrame(store.root.metadata.songs.read(), \n",
    "                                columns=metadata_var_list)\n",
    "    # retrieve a single row dataframe from `/analysis/songs`\n",
    "    ret_analysis = pd.DataFrame(store.root.analysis.songs.read(), \n",
    "                                columns=analysis_var_list)\n",
    "    # merge these two dataframes by adding their columns together\n",
    "    ret = pd.concat([ret_analysis, \n",
    "                     ret_metadata], \n",
    "                    axis=1)\n",
    "    # close the open HDF5 file\n",
    "    store.close()\n",
    "    # return the merged dataframe\n",
    "    return(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of (10,000) files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `path` variable stores the root of the directory tree containing all of the song files. The function `get_filenames` returns a multi-level list, which is flattened using `unlist` and stored in variable `filenames` as a list of full-path filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/David/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " '/Users/David/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAABD128F429CF47.h5']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/David/Dropbox/Data/MillionSongSubset/data\"\n",
    "filenames = unlist(unlist(unlist(get_filenames(path))))\n",
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store in `filenames` only the files with extension `.h5` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/David/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " '/Users/David/Dropbox/Data/MillionSongSubset/data/A/A/A/TRAAABD128F429CF47.h5']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"\\.h5$\")\n",
    "filenames = [filename for filename \n",
    "             in filenames if p.search(filename)]\n",
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get lists of variables from `/metadata/songs` and `/analysis/songs`\n",
    "\n",
    "The two tables `/metadata/songs` and `/analysis/songs` provide data that is easy to load into a dataframe. Their variables are displayed below so we know which to choose or omit when creating the corresponding dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `/metadata/songs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('analyzer_version', 'S32'), ('artist_7digitalid', '<i4'), ('artist_familiarity', '<f8'), ('artist_hotttnesss', '<f8'), ('artist_id', 'S32'), ('artist_latitude', '<f8'), ('artist_location', 'S1024'), ('artist_longitude', '<f8'), ('artist_mbid', 'S40'), ('artist_name', 'S1024'), ('artist_playmeid', '<i4'), ('genre', 'S1024'), ('idx_artist_terms', '<i4'), ('idx_similar_artists', '<i4'), ('release', 'S1024'), ('release_7digitalid', '<i4'), ('song_hotttnesss', '<f8'), ('song_id', 'S32'), ('title', 'S1024'), ('track_7digitalid', '<i4')]\n"
     ]
    }
   ],
   "source": [
    "tmp=pd.HDFStore(filenames[1])\n",
    "print(tmp.root.metadata.songs.read().dtype)\n",
    "tmp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `/analysis/songs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('analysis_sample_rate', '<i4'), ('audio_md5', 'S32'), ('danceability', '<f8'), ('duration', '<f8'), ('end_of_fade_in', '<f8'), ('energy', '<f8'), ('idx_bars_confidence', '<i4'), ('idx_bars_start', '<i4'), ('idx_beats_confidence', '<i4'), ('idx_beats_start', '<i4'), ('idx_sections_confidence', '<i4'), ('idx_sections_start', '<i4'), ('idx_segments_confidence', '<i4'), ('idx_segments_loudness_max', '<i4'), ('idx_segments_loudness_max_time', '<i4'), ('idx_segments_loudness_start', '<i4'), ('idx_segments_pitches', '<i4'), ('idx_segments_start', '<i4'), ('idx_segments_timbre', '<i4'), ('idx_tatums_confidence', '<i4'), ('idx_tatums_start', '<i4'), ('key', '<i4'), ('key_confidence', '<f8'), ('loudness', '<f8'), ('mode', '<i4'), ('mode_confidence', '<f8'), ('start_of_fade_out', '<f8'), ('tempo', '<f8'), ('time_signature', '<i4'), ('time_signature_confidence', '<f8'), ('track_id', 'S32')]\n"
     ]
    }
   ],
   "source": [
    "tmp=pd.HDFStore(filenames[1])\n",
    "print(tmp.root.analysis.songs.read().dtype)\n",
    "tmp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a single table from the 10,000 files\n",
    "\n",
    "Because `remove=False` is specified the two lists of variables are retrieved from the two `Tables` displayed above. The result of this command is a list of 10,000 single row dataframes with columns indicated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, (1, 16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_df_list = [make_1row_df(filename=filename,\n",
    "                            metadata_vars=['artist_familiarity','artist_hotttnesss',\n",
    "                                           'song_hotttnesss','genre','title',\n",
    "                                           'artist_location','release'\n",
    "                                           'artist_longitude','artist_latitude'],\n",
    "                            analysis_vars=['danceability','duration','energy','key',\n",
    "                                           'loudness','mode','tempo','time_signature'],\n",
    "                            remove=False\n",
    "                           )\n",
    "                for filename in filenames[0:10000] # get data from all 10,000 files\n",
    "              ]\n",
    "len(mss_df_list), mss_df_list[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all dataframes of `mss_df_list` into a single dataframe stored in `mss_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_df = pd.concat(mss_df_list,axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check its dimensions (shape) and its variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10000, 16)\n",
      "columns: ['danceability' 'duration' 'energy' 'key' 'loudness' 'mode' 'tempo'\n",
      " 'time_signature' 'artist_familiarity' 'artist_hotttnesss'\n",
      " 'song_hotttnesss' 'genre' 'title' 'artist_location'\n",
      " 'releaseartist_longitude' 'artist_latitude']\n"
     ]
    }
   ],
   "source": [
    "print('shape:',mss_df.shape)\n",
    "print('columns:',mss_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save-load the table `mss_df`\n",
    "\n",
    "First set the folder to save to and load from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_load_path = '/Users/David/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `mss_df` to a _pickle_ file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_df.to_pickle(save_load_path+'/mss_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `mss_df` from the _pickle_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_df = pd.read_pickle(save_load_path+'/mss_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10000, 16)\n",
      "columns: ['danceability' 'duration' 'energy' 'key' 'loudness' 'mode' 'tempo'\n",
      " 'time_signature' 'artist_familiarity' 'artist_hotttnesss'\n",
      " 'song_hotttnesss' 'genre' 'title' 'artist_location'\n",
      " 'releaseartist_longitude' 'artist_latitude']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "danceability               float64\n",
       "duration                   float64\n",
       "energy                     float64\n",
       "key                          int32\n",
       "loudness                   float64\n",
       "mode                         int32\n",
       "tempo                      float64\n",
       "time_signature               int32\n",
       "artist_familiarity         float64\n",
       "artist_hotttnesss          float64\n",
       "song_hotttnesss            float64\n",
       "genre                       object\n",
       "title                       object\n",
       "artist_location             object\n",
       "releaseartist_longitude     object\n",
       "artist_latitude            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape:',mss_df.shape)\n",
    "print('columns:',mss_df.columns.values)\n",
    "mss_df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
